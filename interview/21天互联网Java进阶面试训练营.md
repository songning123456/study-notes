[JAVA核心面试知识整理](/interview/link/JAVA核心面试知识整理.pdf)

#### 你们公司用的Dubbo?那你再额外说说Spring Cloud的核...

#### 基于Dubbo和Spring Cloud分别搭建一个电商系统来快速体...

#### 你们的系统使用了哪种服务框架?为什么要这样技术...

```
* Spring Cloud & Dubbo对比
    (1) 并发性能
        Spring Cloud: 使用的是http协议，性能与dubbo对比稍微差点
        Dubbo: 是一款优秀的RPC框架，并发能力比springcloud强
    (2) 注册中心
        Spring Cloud: 有全家桶配置中心。eurake nacos,亦可以选择zookeeper
        Dubbo: 一般选择zookeeper	
    (3) 分布式配置中心
        Spring Cloud: nacos/ spring cloud config
        Dubbo: 阿波罗
    (4) 网关
        Spring Cloud: zuul / srping cloud gateway
        Dubbo: 需引入其他网关组件
    (5) 负载均衡
        Spring Cloud: ribbon
        Dubbo: 自带负载均衡
    (6) 熔断功能
        Spring Cloud: hystrix
        Dubbo: 需引入其他熔断框架
    (7) 社区活跃度
        Spring Cloud: 活跃、版本更新快
        Dubbo: 不活跃
* Tips
    所以现在一般都会选择spring cloud 全家桶做微服务，因为spring cloud胜在功能更全，有一些列可以开箱即用的组件，满足服务化后的各种场
景需求。或者说dubbo就是一个纯正的RPC框架，对于服务之间远程调用，性能非常优秀，并发高，响应快，但是也仅仅是一个RPC框架，如果需要其他的
功能，则需要引入其他 的组件，因此在引入其他组件的过程中，可能会带来更多的问题。所以对于易用性这一块，spring cloud已经集成了各方面微服
务所需要的组件，上手更快，拆坑更少，团队上手更容易，学习成本更低。可以开箱即用，快速上手。
```

#### 看过Dubbo源码吗?说说Dubbo的底层架构原理?...
    
```
* 简介
    Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合(或者最大限度地松耦合)。
从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方
(Provider)和服务消费方(Consumer)两个角色。

* 是什么
    简单说呢，Dubbo用起来就和EJB、WebService差不多，调用一个远程的服务(或者JavaBean)的时候在本地有一个接口，就像调用本地的方法一样
去调用，它底层帮你实现好你的方法参数传输和远程服务运行结果传回之后的返回，就是RPC的一种封装啦~

* 特点
    (1) 它主要是使用高效的网络框架和序列化框架，让分布式服务之间调用效率更高。
    (2) 采用注册中心管理众多的服务接口地址，当你想调用服务的时候只需要跟注册中心询问即可，不用像使用WebService一样每个服务都得记录好接口
    调用方式。注册中心主要就是负责dubbo的所有服务地址列表维护，并且可以通过在ZooKeeper节点中设置相应的值来实现对这个服务的权重、优先级、
    是否可用、路由、权限等的控制。之后在Dubbo的管理控制台对服务的一堆治理策略设置和调整，实际上就是修改了注册中心中的服务对应的配置数据
    (即修改了zookeeper中服务对应的节点的配置数据)。之后Consumer从注册中心请求到服务的数据时就能根据这些配置数据进行相应的治理配置参数的
    代码执行生效。
    (3) 监控中心实现对服务方和调用方之间运行状态的监控，还能控制服务的优先级、权限、权重、上下线等，让整个庞大的分布式服务系统的维护和治理
    比较方便。
    (4) 高可用有个服务宕机了?注册中心就会从服务列表去掉该节点。还是调用到了?客户端会向注册中心请求另一台可用的服务节点重新调用。注册中心宕
    机?注册中心也能实现高可用(ZooKeeper)。
    (5) 负载均衡：采用软负载均衡算法实现对多个相同服务的节点的请求负载均衡。

* RPC之Dubbo实现
    主要为三点，动态代理、反射、socket网络编程
    (1) 客户端使用动态代理的方式，“假装”实现了createOrder方法。
    (2) 方法相关的数据通过序列化，进入到socket服务器。dubbo的socket实现为Netty。
    (3) 服务端从socket服务器取出数据，通过反射的方式找到“真实”的服务实现。
    (4) 服务端的方法在服务启动时已注入。
    (5) 服务发现层，可用zookeeper。zookeeper保证了CP(一致性，分区容错性)。缺点：master节点挂掉时，需要时间重新选择master，这段时间内注册
    中心将不可用。
    注意：服务端可消费端注册成功后，通讯只走socket服务器，不会经过注册中心。

* 核心技术简介
    (1) 客户端发起接口调用
    (2) 服务中间件进行路由选址：找到具体接口实现的服务地址
    (3) 客户端将请求信息进行编码(序列化: 方法名，接口名，参数，版本号等)
    (4) 建立与服务端的通讯(不是调度中心，而是客户端与服务端直连)
    (5) 服务端将接收到的信息进行反编码(反序列化)
    (6) 根据信息找到服务端的接口实现类
    (7) 将执行结果反馈给客户端

```

#### 咱们来聊点深入的,说说Dubbo底层的网络通信机制原...

    <https://blog.csdn.net/Internation985/article/details/103432187>
```
* 基本信息
    (1) 连接个数: 单连接
    (2) 连接方式: 长连接
    (3) 传输协议: TCP
    (4) 传输方式: NIO异步传输
    (5) 序列化: Hessian二进制序列化
    (6) 适用范围： 传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件
        或超大字符串。
    (7) 适用场景: 常规远程服务方法调用
* 同步远程调用
    (1) 客户端线程调用远程接口，向服务端发送请求，同时当前线程应该处于“暂停“状态，即线程不能向后执行了，必需要拿到服务端给自己的结果后
    才能向后执行
    (2) 服务端接到客户端请求后，处理请求，将结果给客户端
    (3) 客户端收到结果，然后当前线程继续往后执行
* 基本原理
    (1) client一个线程调用远程接口，生成一个唯一的ID（比如一段随机字符串，UUID等），Dubbo是使用AtomicLong从0开始累计数字的
    (2) 将打包的方法调用信息（如调用的接口名称，方法名称，参数值列表等），和处理结果的回调对象callback，全部封装在一起，组成一个对象object
    (3) 向专门存放调用信息的全局ConcurrentHashMap里面put(ID, object)
    (4) 将ID和打包的方法调用信息封装成一对象connRequest，使用IoSession.write(connRequest)异步发送出去
    (5) 当前线程再使用callback的get()方法试图获取远程返回的结果，在get()内部，则使用synchronized获取回调对象callback的锁， 再先检
    测是否已经获取到结果，如果没有，然后调用callback的wait()方法，释放callback上的锁，让当前线程处于等待状态。   
    (6) 服务端接收到请求并处理后，将结果（此结果中包含了前面的ID，即回传）发送给客户端，客户端socket连接上专门监听消息的线程收到消息，
    分析结果，取到ID，再从前面的ConcurrentHashMap里面get(ID)，从而找到callback，将方法调用结果设置到callback对象里。
    (7) 监听线程接着使用synchronized获取回调对象callback的锁（因为前面调用过wait()，那个线程已释放callback的锁了），再notifyAll()，
    唤醒前面处于等待状态的线程继续执行（callback的get()方法继续执行就能拿到调用结果了,这里的callback对象是每次调用产生一个新的，不能共享，
    否则会有问题；另外ID必需至少保证在一个Socket连接里面是唯一的。），至此，整个过程结束。

* 当前线程怎么让它“暂停”，等结果回来后，再向后执行？
    答: 先生成一个对象obj，在一个全局map里put(ID,obj)存放起来，再用synchronized获取obj锁，再调用obj.wait()让当前线程处于等待状态，然
后另一消息监听线程等到服务端结果来了后，再map.get(ID)找到obj，再用synchronized获取obj锁，再调用obj.notifyAll()唤醒前面处于等待状态
的线程。
* 正如前面所说，Socket通信是一个全双工的方式，如果有多个线程同时进行远程方法调用，这时建立在client server之间的socket连接上会有很
  多双方发送的消息传递，前后顺序也可能是乱七八糟的，server处理完结果后，将结果消息发送给client，client收到很多消息，怎么知道哪个消息结
  果是原先哪个线程调用的？
    答: 使用一个ID，让其唯一，然后传递给服务端，再服务端又回传回来，这样就知道结果是原先哪个线程的了。

```

#### Dubbo框架从架构设计角度,是怎么保证极高的可扩展性...

    <https://blog.csdn.net/maoreyou/article/details/80570230>
```
* Dubbo SPI 特点
    (1) 对Dubbo进行扩展，不需要改动Dubbo的源码
    (2) 自定义的Dubbo的扩展点实现，是一个普通的Java类，Dubbo没有引入任何Dubbo特有的元素，对代码侵入性几乎为零。
    (3) 将扩展注册到Dubbo中，只需要在ClassPath中添加配置文件。使用简单。而且不会对现有代码造成影响。符合开闭原则。
    (4) Dubbo的扩展机制支持IoC,AoP等高级功能
    (5) Dubbo的扩展机制能很好的支持第三方IoC容器，默认支持Spring Bean，可自己扩展来支持其他容器，比如Google的Guice。
    (6) 切换扩展点的实现，只需要在配置文件中修改具体的实现，不需要改代码。使用方便。

```

#### 自己独立画出Dubbo的底层架构原理图

    [](/interview/link/Dubbo原理图.jpg)

#### 如果让你设计一个RPC框架,网络通信 代理机制 负载...

    <https://blog.csdn.net/u012422829/article/details/78375839?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1>
```
* 什么是RPC
    RPC的全称是Remote Procedure Call，远程过程调用。RPC框架有很多，比如hsf、dubbo等等。借助RPC框架，我们在写业务代码的时候可以不需
要去考虑服务之间的通信等问题，在调用远程服务的时候就像调用本地的方法那么简单。
* 组成部分
    (1) 简化本地调用流程
        既然我们要像调用本地方法那样调用远程服务， 那么就应该生成代理来隐藏调用远程服务的细节。 这些细节包括但不限于以下所列出的关注点。
    (2) 服务发现与服务注册
        (a) 如果我们想在Service A中调用Service B，那么我们首先得知道Service B的地址。 所以，我们需要有一个服务注册中心，通过这个中心，
    服务可以把自己的信息注册进来，也可以获取到别的服务的信息。
        (b) 客户端也需要watch服务注册中心的目标服务的地址的变化。
    (3) 网络通信
        (a) 服务和服务之间的网络通信模型， NIO/IO等等
        (b) 客户端如何复用与服务端的连接， 而不是每次请求都重新创建一个新连接？
        (c) 客户端收到返回后，如何知道是哪个请求的返回并且做出正确处理？
    (4) 消息的序列化
        服务间通信的消息通过什么方式进行序列化？ hessian，XML、JSON、Protobuf、……, 甚至Java原生的序列化方式， 你总得选择一个。
    (5) 负载均衡
        客户端通过服务注册中心拿到一堆地址，该调哪个呢？最简单的方式，可以通过RR、WRR的方式去做LB。
        (a) 根据服务实例的metrics做出动态调整, 比如响应时间等
        (b) 利用一致性哈希， 提高本地缓存利用率
    (6) 容灾
        (a) 康监测： 在某一个服务节点挂掉的时候， 如何在服务注册中心删去这个服务地址？
        (b) 服务调用超时与重试： 在调用一个服务实例的时候，如果超时或者报错，怎么处理？
        (c) 服务限流：如何限制最大并发数？这个又可以从客户端和服务端两个角度分析。
```

#### 平时除了使用外,有研究过Spring Cloud的底层架构原理...
    
    <https://blog.csdn.net/niugang0920/article/details/84294365>
    [](/interview/link/SpringCloud架构原理.png)
    
```
* Spring Cloud核心组件
    (1) Eureka
        各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而
    知道其他服务在哪里
    (2) Ribbon
        服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台
    (3) Feign
        基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求
    (4) Hystrix
        发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题
    (5) Zuul
        如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务    
```

#### 从底层实现原理的角度,对比一下Dubbo和Spring Cloud的...

    [](/interview/link/Dubbo&SpringCloud.png)
```
* 相同点
    都需要 服务提供方，注册中心，服务消费方
* Dubbo
    (1) Provider: 暴露服务的提供方，可以通过jar或者容器的方式启动服务
    (2) Consumer: 调用远程服务的服务消费方。
    (3) Registry: 服务注册中心和发现中心。
    (4) Monitor: 统计服务和调用次数，调用时间监控中心。(dubbo的控制台页面中可以显示，目前只有一个简单版本)
    (5) Container: 服务运行的容器。
* Spring Cloud
    (1) Service Provider: 暴露服务的提供方。
    (2) Service Consumer: 调用远程服务的服务消费方。
    (3) EureKa Server: 服务注册中心和服务发现中心。
* 比较
    (1) 从核心要素来看
    Spring Cloud 更胜一筹，在开发过程中只要整合Spring Cloud的子项目就可以顺利的完成各种组件的融合，而Dubbo缺需要通过实现各种Filter
来做定制，开发成本以及技术难度略高。Dubbo只是实现了服务治理，而Spring Cloud子项目分别覆盖了微服务架构下的众多部件，而服务治理只是其中
的一个方面。Dubbo提供了各种Filter，对于上述中“无”的要素，可以通过扩展Filter来完善。
    e.g
        (a) 分布式配置：可以使用淘宝的diamond、百度的disconf来实现分布式配置管理
        (b) 服务跟踪：可以使用京东开源的Hydra，或者扩展Filter用Zippin来做服务跟踪
        (c) 批量任务：可以使用当当开源的Elastic-Job、tbschedule
    (2) 从协议上看
    Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况，二进
制的传输，占用带宽会更少。Spring Cloud 使用HTTP协议的REST APIdubbo支持各种通信协议，而且消费方和服务方使用长链接方式交互，http协议
传输，消耗带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大。通信速度上Dubbo略胜Spring Cloud，如果对于系统的响应时间有严
格要求，长链接更合适。
    (3) 从服务依赖方式看
    Dubbo服务依赖略重，需要有完善的版本管理机制，但是程序入侵少。而Spring Cloud通过Json交互，省略了版本管理的问题，但是具体字段含义需
要统一管理，自身Rest API方式交互，为跨平台调用奠定了基础。
    (4) 从组件运行流程看
    Dubbo每个组件都是需要部署在单独的服务器上，gateway用来接受前端请求、聚合服务，并批量调用后台原子服务。每个service层和单独的DB交互。
    SpringCloud所有请求都统一通过 API 网关（Zuul）来访问内部服务。网关接收到请求后，从注册中心（Eureka）获取可用服务。由 Ribbon 进行
均衡负载后，分发到后端的具体实例。微服务之间通过 Feign 进行通信处理业务。业务部署方式相同，都需要前置一个网关来隔绝外部直接调用原子服务
的风险。Dubbo需要自己开发一套API 网关，而Spring Cloud则可以通过Zuul配置即可完成网关定制。使用方式上Spring Cloud略胜一筹。
```

#### 自己独立画出Spring Cloud的架构原理图,RPC框架...

    [](/interview/link/RPC&SpringCloud.PNG)

#### 你们的服务注册中心进行过选型调研吗?对比一...

[](/interview/link/Eureka&Zookeeper.png)
```
* Eureka (AP)
    peer-to-peer，部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例服务注册和服务发现，集群里任何一个
Eureka实例接收到写请求之后，会自动同步给其他所有的Eureka实例。Eureka是peer模式，可能还没同步数据过去，结果自己就死了，此时还是可以继
续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性。
    (1) 单点问题
        eureka需要部署服务，服务自身需要做集群，增加了系统部署的复杂性。
    (2) 数据同步
        各服务之间数据同步是异步的，定时的，这会导致节点间一定时间内，数据不一致；并且，在数据复制的过程中，如果持有新实例注册信息的
    注册中心自身挂掉了，这个实例就无法得到注册；
    (3) 自我保护机制
        注册中心自身如果监测到某个实例的心跳成功比例一定时间内小于一定的阈值，这个实例注册信息会被保护起来，不会注销掉，等到这个心跳
    成功比例大于阈值时，退出自我保护机制。在这个保护期内，如果服务挂了，那这个实例信息其实时有问题的，应该被剔除。
    (4) 心跳压力
        如果注册中心注册的实例过多，比如500个，每个间隔30s发出一次续约心跳，那30s内，就是15000个心跳连接，这个心跳的请求可能大于实际
    业务发出的请求。
    (5) 健康检查机制
        健康检查比较单一，仅仅检查心跳是不够的，心跳还在，说明服务进程没死，那服务所在的硬件问题如内存满载，关联的db挂了等，这些都无
    法得到反应，所以服务可能并不能提供服务了，但是服务还在注册中心的列表中。
    (6) 维护风险
        官方宣布2.0的开源工作停止了，继续使用的责任自负。
* Zookeeper (CP)
    Leader + Follower两种角色，只有Leader可以负责写也就是服务注册，他可以把数据同步给Follower，读的时候leader/follower都可以读。
ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲了A，不可
用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性。
    (1) 重
        java开发，引入依赖多，对于服务器而言太重，部署复杂，不支持多数据中心。对服务侵入大。
    (2) 健康检查
        检查方式单一，需要消费者自己实现，也是靠心跳连接保活，连接断开，就是服务挂了，服务就会被剔除。
    (3) 更新
        非常稳定，更新少，微服务架构下，对于做专业的注册中心而言，功能匮乏，丧失了快速迭代的能力，不够与时俱进，不够灵活。
    (4) 算法
        paxos算法，复杂难懂。
* etcd
    未使用过，资料了解，其本质上是一个比zk轻量的分布式键值对存储系统，但是需要搭配其他小工具才能较好较易用的实现注册中心功能。但是，
为了实现A功能，又额外引入了B和C工具，不是一个优雅的实现方案，而且不支持多数据中心,无web管理页面。
* consul (CP)
    (1) 数据一致性
        raft算法，实现思路从源头上避免了数据不一致性。注册时，超过半数没有拿到信息，那就注册失败。
    (2) 开箱即用
        集成简单，不依赖其他工具，使用也简单，支持2种服务注册方式：配置文件，http api。
    (3) kv存储
        支持和zk和etcd一样的kv存储，可做配置中心。
    (4) 健康检查
        健康检查支持好，提供多种健康检查功能，比如服务返回的状态码，内存利用率等。
    (5) 心跳
        服务状态的检查，不是直接向注册中心发心跳，而是agent向服务发出健康监测。
    (6) web管理页面
        官方提供良好的web管理页面。
    (7) 活跃
        社区很活跃，更新频繁。
* Nacos
    这个最近也挺火，待了解。
* Tips
    一致性保障: CP or AP
    CAP: C是一致性，A是可用性，P是分区容错性。
        ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲
    了A，不可用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性。Eureka是peer模式，可能还没同步数据过去，结果自
    己就死了，此时还是可以继续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性。
```

#### 画图阐述一下你们的服务注册中心部署架构,生产环境下怎么保证高可用?

```
    Eureka高可用，至少2台做集群。两个分支内相互配置另一台的ip和端口号。
```

#### 你们系统遇到过服务发现过慢的问题吗?怎么优化和解决的?

```
eureka，必须进行优化参数:
* 客户端的有效负载缓存应该更新的时间间隔，默认为30 * 1000ms
    eureka.server.responseCacheUpdateIntervalMs = 30000(30s) -> 3000(3s)
* 从eureka服务器注册表中获取注册信息的时间间隔(s)，默认为30s
    eureka.client.registryFetchIntervalSeconds = 30000 -> 3000
* 客户端多长时间发送心跳给eureka服务器，表明它仍然活着，默认为30s
    eureka.client.leaseRenewalIntervalInSeconds = 30 -> 3
* 过期实例应该剔除的时间间隔，单位为毫秒，默认为60 * 1000
    eureka.server.evictionIntervalTimerInMs = 60000 -> 6000(6s)
* Eureka服务器在接收到实例的最后一次发出的心跳后，需要等待多久才可以将此实例删除，默认为90s
    eureka.instance.leaseExpirationDurationInSeconds = 90 -> 9(s)
服务发现的时效性变成秒级，几秒钟可以感知服务的上线和下线
```

#### 说一下自己公司的服务注册中心怎么技术选型的?生产环境中应该怎么优化?

```
* 服务注册、故障 和发现的时效性是多长时间?注册中心最大能支撑多少服务实例?
    如何部署的，几台机器，每台机器的配置如何，会用比较高配置的机器来做，8核16G，16核32G的高配置机器来搞，基本上可以做到每台机器每秒钟
的请求支撑几千绝对没问题。
* 可用性如何来保证?
    有没有做过一些优化，服务注册、故障以及发现的时效性，是否可以优化一下，用eureka的话，可以尝试一下，配合我们讲解的那些参数，优化一下
时效性，服务上线、故障到发现是几秒钟的时效性。zk，一旦服务挂掉，zk感知到以及通知其他服务的时效性，服务注册到zk之后通知到其他服务的时效
性，leader挂掉之后可用性是否会出现短暂的问题，为了去换取一致性。
```

#### 你们对网关的技术选型是怎么考虑的?能对比一下各种网关的优劣吗?

```
* 网关的核心功能
    (1) 动态路由：新开发某个服务，动态把请求路径和服务的映射关系热加载到网关里去；服务增减机器，网关自动热感知
    (2) 灰度发布
    (3) 授权认证
    (4) 性能监控：每个API接口的耗时、成功率、QPS
    (5) 系统日志
    (6) 数据缓存
    (7) 限流熔断
* Zuul & Spring Cloud Gateway
    (1) zuul是Netflix的产品，gateway是spring全家桶的亲儿子。zuul 更新维护不积极，所以gateway自己做了网关，就是为了替代zuul
    (2) zuul 1.0和 2.0差别很大，1.0版本是基于servlet的同步阻塞io，2.0是基于netty通信的异步io，并发能力2.0版本大大提升。但是2.0文档
    相对不友好。gateway本身是基于netty通信的异步io，并发能力很强。
    (3) gateway文档齐全，架构清晰简单。容易上手，团队学习成本低，gateway有很多可以开箱即用的功能，非常方便。
    (4) gateway功能性更强，有非常多的predicate实现和filter，直接配置化就可以使用。同时还可以基于Redis记性流量控制。
```

#### 说说生产环境下,你们是怎么实现网关对服务的动态路由的?
```
* 方案一: 数据库
    如果映射关系写死，每次路由关系更改，就需要重启网关，影响会非常大，因此需要实现网关动态的更新路由关系。 可以使用第三方组件保存路由
关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，
再由网关去定时查询db更新路由表，实现动态效果。Nginx（Kong、Nginx+Lua）：Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高
的并发，精通Nginx源码，很难，c语言，很难说从Nginx内核层面去做一些二次开发和源码定制。
* 方案二: Config配置
    将 Spring Cloud Zuul的路由信息，配置在 Config Server 的 env.yml 中，将网关服务注册为 Config Client，从 Config Server 获取
路由信息。微服务架构的系统中，我们通常会使用轻量级的消息代理来构建一个共用的消息主题让系统中所有微服务实例都连接上来，由于该主题中产生
的消息会被所有实例监听和消费，所以我们称它为消息总线。在总线上的各个实例都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息，
例如配置信息的变更或者其他一些管理操作等。Bus 就是 Spring Cloud 中的消息总线。
* 其他方案: Apollo, Redis...
```

#### 如果网关需要抗每秒10万的高并发访问,你应该怎么对网关进行生产优化?

```
    Zuul网关部署的是什么配置的机器，部署32核64G，对网关路由转发的请求，每秒抗个小几万请求是不成问题的，几台Zuul网关机器。每秒是1万请
求，8核16G的机器部署Zuul网关，5台机器就够了。
```

#### 你们公司的网关是怎么技术选型的,假设有高并发场...

```
    实际压测经验，gateway包含鉴权、日志等业务操作。2C4G的机器两台。500TPS CPU才30% 左右。一般的系统，妥妥的没压力。如果需要更高并发。
直接加机器配置即可。
```

#### 如果需要部署上万服务实例,现有的服务注册中心能否抗住?如何优化?

[](/interview/link/服务注册中心.png)
````
* 核心思想
    注册中心主从架构，分片存储服务注册表，服务按需主动拉取注册表，不用全量拉取/推送，避免反向通知瞬时高并发。
* 自研注意点
    (1) 客户端
        (a) 服务拉取: 不用全量拉取，按需拉取(有疑问，怎么设计按需拉取)。还需要一个用于校验拉取增量数据之后数据是否完整的过程。
        (b) 心跳发送
        (c) 服务下线
    (2) 服务端
        (a) 服务注册: 服务注册表注意读写高并发控制，保证线程安全，也要降低锁的争用。
        (b) 健康检查: 单位时间内，如果所注册服务没有续约，则要将其下线。
        (c) 集群同步: 根据具体业务需求，制定合适的集群架构方案，保证吞吐量。
````

#### 你们是如何基于网关实现灰度发布的?说说你们的灰度发布方案?

```
* 定义
    通过网关(Zuul, ZuulFilter)的发布开关，把少量流量导入到一两台部署了新版本的服务器上，进行测试，这个就叫灰度发布。
* 开发流程
    (1) 准备一个数据库和一个表（也可以用Apollo配置中心、Redis、ZooKeeper，其实都可以），放一个灰度发布启用表，存入具体uri以及是否灰
    度发布的一些信息，然后搞一张映射表。
    (2) 启动1个线程每隔多少时间就去刷新灰度发布表的数据写到ConcurrentHashMap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，
    其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，
    就自定义一些分发逻辑，这里用的时通过version去判断和分发。
* 发布流程
    首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new的服务上，然后监控和
对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。
```

#### 说说你们一个服务从开发到上线, 服务注册 网关路由 服务调用的流程?

```
    开发了一个新的服务，线上部署，配合网关动态路由的功能，在网关里配置一下路径和新服务的映射关系，此时请求过来直接就可以走到新的服务里
去。对已有服务进行迭代和开发，新版本，灰度发布，新版本部署少数几台机器，通过一个界面，开启这个服务的灰度发布，此时zuul filter启用，按
照你的规则，把少量的流量打入到新版本部署的机器上去。观察一下少量流量在新版本的机器上运行是否正常。版本改成current，全量机器部署，关闭
灰度发布功能，网关就会把流量均匀分发给那个服务了。
```

#### 看看你们公司的服务注册中心能否支撑上万服务实例...

#### 画一下你们系统架构的整体架构图?说说各个服务在生产环境怎么部署的?

```
* 核心
    服务框架,注册中心,网关
* 部署
    中小型系统，拆分10-20个微服务。大型互联网公司，一般几百个，几千个微服务。
    中小型，一般2-3台机器足够，把服务上线，服务发现优化到极致。
    服务上线：注册表多级缓存同步至1秒，拉取频率降低至1秒。
    服务心跳：1秒报1次。
    故障发现：1秒检查一次，2，3秒没有认为没有故障等。
    服务注册中心没有压力，服务注册中心部署2台机器，每台4C8G，高可用，每秒轻松几百请求，甚至上千。前提是数据库SQL别写的太烂。
    网关机器配置稍微高一些，4C8G，一台扛每秒几百个请求，部署3~4台，保证每台网关机器压力较小，进一步保证可靠性。
```

#### 你们系统每天有多大的访问量?每个服务高峰QPS多少?压测过服务最大QPS吗?

```
    每天服务多少请求量，高峰每秒qps，在代码里稍微加一些metrics代码，对自己运行过程中各种请求量，每秒请求量，成功次数，失败次数，在内
存里直接做一些计数。在负责的核心服务里，核心接口，开发一个简单的metric统计机制，AtomicLong，保证原则性，并发数据统计准确。每个接口被
调用时，可以对每个接口每分钟做一个metric统计，每个接口每天统计计数。再通过Log4j, logback等日志组件，把次数直接打印到日志文件，统计出
高峰期每秒系统被访问的次数，每条每个接口访问量。
* 响应延时
    计算一下每个接口从请求到执行完毕，需要耗费多长时间，算一下每个接口平均的请求延时，TP99，TP95，TP90，TP50，TP99，99%的请求耗费的
时间在100ms以内，但是1%的请求可能耗费的时间在100ms以上TP99 = 100ms TP95 = 50ms，95%的请求耗费的时间多在50ms以内，但是5%的请求耗费
的时间在50ms以上压测工具，java压测工具，开源的可以用的，模拟出来同时有多少用户发起多少请求，每秒发起1000请求能抗住吗？每秒钟发起2000
请求能抗住吗？假设你的系统每秒钟最多抗800请求，如果你的压测工具每秒发起了1000个请求，此时会发现最多只有800个请求同时可以被处理，剩余
200个请求需要进行排队被阻塞住了，表示你这个系统每秒钟最多抗800个请求。
```

#### 如果系统访问量比现在增加10倍,你们考虑过系统的扩容方案吗?

```
    网关直接多部署10倍的机器即可，前面的Nginx做会负载均衡，把流量均匀分发给各个网关机器。服务扩容，都很简单的，多加机器，部署启动，
自动注册到注册中心去，此时其他服务会自动感知到你的服务多加了一些机器。服务实例变多了10倍，此时几十个服务实例，几百个服务实例，对eureka
机器会造成每秒几百请求，没问题，eureka机器，8核16G的配置，单机抗上千请求，很轻松。数据库本来是每秒几百请求，10倍，每秒高峰期是三四千
请求，横向扩容很麻烦，此时可以考虑给单个数据库部署的机器提高配置，32核128G高配物理机，每秒钟抗几千请求问题不大。

* 总结(最基本的操作就是扩容)
    网关: 横向加机器。
    注册中心: 纵向升配置。
    数据库: 纵向升配置。

    当然还有很多其他专门针对分布式，高并发的优化和操作，不过加机器都是最简单直接的。
```

#### 独立画出自己系统的生产环境部署架构图,梳理系统和服务...

#### 你们生产环境的服务是怎么配置超时和重试参数的?为什么要这样配置?

```
* 背景
    Spring Cloud生产优化，系统第一次启动的时候，调用请求经常出现timeout。
* 原因
    每个服务第一次被请求的时候，他会去初始化一个Ribbon的组件，初始化这些组件需要耗费一定的时间，所以很容易会导致超时。
* 解决方案
    让每个服务启动的时候就直接初始化Ribbon相关的组件，避免第一次请求的时候初始化。
    ribbon:
      eager-load:
        enabled: true
    zuul:
      ribbon:
        eager-load:
          enabled: true
    feign:
      hystrix:
         enabled: false
```

#### 如果出现服务请求重试,会不会出现类似重复下单的问题?

```
* 答案
    可能会
* 场景
    订单服务 -> 创建订单 -> 库存服务 -> 扣减库存 -> wms服务 -> 通知发货 -> 积分服务 -> 增加积分
* 原因
    订单服务调用库存服务的时候，因为网络抖动，请求超时了，超过了秒钟，此时订单服务会重试，再次调用一下库存服务，发送一模一样的请求过去。
比如说，订单服务第一次请求库存服务，库存服务其实是把扣减库存的业务逻辑执行成功了，只不过网络问题，导致响应迟迟没有返回给订单服务，可能
在1.2s之后返回了响应给订单服务。订单服务就认为请求超时了，他就再次发送了一个一模一样的请求给库存服务，库存服务可能会再次对库存进行扣减。
```

#### 对于核心接口的防重幂等性,你们是怎么设计的?怎么防止重复下单问题?

```
* 方案
    数据库唯一索引
    基于Redis实现幂等性防重
* 原因
    核心接口，幂等性都是自己保证，对应Create操作，通过DB唯一索引来保证；对于Update操作，建议在核心接口基于业务逻辑，配合Redis，来保
证幂等性。比如库存，定制化的针对接口开发幂等性的机制，比如说一旦库存扣减成功之后，就立马要写一条数据到redis里去，order_id_11356_stock_deduct，
写入redis中，如果写入成功，就说明之前这个订单的库存扣减，没人执行过。但是如果此时有一些重试的请求过来了，调用了你的库存扣减接口，他同时
也进行了库存的扣减，但是他用同样的一个key，order_id_11356_stock_deduct，写入redis中，此时会发现已经有人写过key，key已经存在了。此时
你就应该直接对刚才的库存扣减逻辑做一个反向的回滚逻辑，update product_stock set stock = stock - 100，update product_stock set stock = stock + 100，
反向逻辑，回滚自己，避免重复扣减库存。
```

#### 看看自己系统的接口有没有设计幂等性方案?如...

#### 画一下你们电商系统的核心交易链路图,说说分布式架构下存在什么问题?

```
* 问题
    分布式事务，分布式锁
*原因
    分布式系统，事务 -> 分布式事务，锁 -> 分布式锁
* 电商核心流程
    订单服务 -> 创建订单 -> 库存服务 -> 扣减库存 -> 积分服务 -> 增加积分 -> 仓储服务 -> 通知发货
```

#### 针对电商核心交易链路,你们是怎么设计分布式事务技术方案的?

```
* 方案
    (1) TCC
        订单服务、库存服务、积分服务 -> 绑定为一个TCC事务
        撤销刚才创建订单时，回滚刚才扣减库存和增加积分
    (2) 可靠消息最终一致性 
        可以去发送一个请求给消息中间件，由中间件保证一定会把消息交给下游的库存服务去扣减库存，仓储服务去通知发货等，如果这个过程中有
    消息发送失败，则可靠消息中间件应该保证不停的重试投递消息。
* 原因
    一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最
终一致性，也可以业务解耦。
```

#### 对于TCC事务,最终一致性事务的技术选型,你们是怎么做的?如何调研的?
```
* TCC
    阿里开源了分布式事务框架，fescar，seata。seata类似TCC事务，经历过阿里生产环境大量考验的框架。支持Dubbo，Spring Cloud。
* 可靠消息最终一致性
    基于ActiveMQ，RabbitMQ, RocketMQ等，自己开发一个可靠消息服务，收到消息之后，尝试投递到MQ，如果投递失败，重试投递。现在大量用
RocketMQ，作为MQ中间件，提供了分布式事务支持，已经把可靠消息服务需要实现的功能逻辑已经做好了。
```

#### 你们公司的核心链路是否有事务问题?分布式事务方...

#### 在搭建的电商系统里,落地开发对交易链路的TCC分布式事务方案?

[](/interview/link/TCC分布式事务方案.png)
```
* 方案
    seata (https://github.com/seata/seata-samples.git)
* 特点 
    自动回滚数据库事务
* 原因
    把seata所有的示例代码拷贝下来，里面提供的例子就是跟我们说的电商的核心例子是类似的.然后先要下载一个seata-server到本地，在这里下载：
https://github.com/seata/seata/releases，然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交
和回滚。
```

#### 你能说说一个TCC分布式事务框架的核心架构原理吗?

```
* Seata架构原理
    https://github.com/seata/seata
* Seata中角色
    Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。
    Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务）
    Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。
* 整个使用seata进行分布式事务管理的生命周期
    (1)TM向TC发起全局事务，TC返回XID作为标识。
    (2)XID通过调用链传播。
    (3)RM将本地的事务注册到TC中表示为XID的全局事务中，成为一个分支事务。
    (4)再由TM向TC请求标识为XID的全局事务提交/回滚。
    (5)最终，由TC去驱动所有的分支事务提交/回滚。
```

#### 现有的TCC事务方案的性能瓶颈在哪里?能支撑高并发交易场景吗?如何优化?
```
    使用分布式事务主要是保证核心链路要么全部成功，要么全部失败。当然也会带来一些性能的开销。seata模型里面频繁的网络通信，以及对应事务
的状态持久化的IO等等。如果需要支撑高并发，那么TC服务也需要横向扩容。相应的，对于TC背后的DB也需要进行优化。
```

#### 如果对自己的系统核心链路落地TCC事物,应该如何...

#### 你了解RocketMQ对分布式事务支持的底层实现原理吗?
    
[](/interview/link/RocketMQ分布式事务.png)
```
    核心链路使用seata这种类似于TCC的事务，而像wms这种相当于是分支链路，可以通过MQ进行解耦。但是通过MQ解耦也会带来一些问题，例如消息
丢失，消息重复等等问题，因此也需要进行最终一致性的保证。
结合整个订单接口服务，分为两个支付链路，一个是核心链路（订单业务），一个是非核心链路（wms） 整个流程。先向RocketMQ发送half msg，然后
调用核心链路。核心链路要是返回失败，就会走失败的逻辑：退款，更改订单状态为取消，再给rocketmq发送callback废弃掉刚才的消息。如果成功，
就commit msg让消费者可以消费。如果在等待期间，一直没有callback/commit那么mq就会走回调查询具体的状态。最终消费者接收到消息后，消费完
成就回复mq一个ack， 如果消费失败了，mq就会重新投递或者换一个服务投递。使用rocketmq的half msg机制，可以实现这一套固定模式的最终一致性，
很完善。 这个将wms的操作放在核心链路前面的这个问题，是为了提升整个订单接口服务的效率，因为需要保证最终一致性，那么必然会有消息生产者对
MQ的一些操作，包括重试，ack等等，如果将这些逻辑全部都放在核心链路执行完成后再去一一完成，那么可能会耗费一些时间。而通过rocketmq这个模式，
可以通过half msg的支持，来将整个与mq的交互过程拆解掉，从而提升效率。
```

#### 在搭建好的电商系统里,如何基于RocketMQ最终一致性事务?

#### 如果公司没有RocketMQ中间件,那你们如何实现最终一致性事务?

```
    基于数据库自己开发一个可靠消息服务。接受上游Producer发送的haf msg, 存入DB，返回响应。本地可靠消息服务启动定时扫描本地DB的half msg，
超过一定时间没有commit/rollback就回调Producer接口，确认本地事务是否成功，获取commit/rollback。如果消息commit就发送消息给下游服务或者
发给RabbitMQ/Kafka/ActiveMQ，下游服务消费后，回调可靠消息服务接口进行ack，如果没有收到ack，重发消息给下游服务。
```

#### 如果对自己的系统落地最终一致性事务,如何落地实...

#### 你们生产系统中有哪个业务场景是需要使用分布式锁的?为什...

#### 你们是用哪个开源框架实现的Redis分布式锁?说说其核...

#### 如果Redis是集群部署的,那么集群故障时分布式锁还有效...

#### 自己梳理出来Redis分布式锁的生产环境问题解决方案！

#### 如果要实现Zookeeper分布式锁,一般用哪个开源框架?核...

#### 对于ZooKeeper的羊群效应,分布式锁实现应该如何优...

#### 如果遇到Zookeeper脑裂问题,分布式锁应该如何保证健壮...

#### 自己梳理出来ZooKeeper分布式锁的生产问题...

#### 在搭建好的电商系统中,落地开发分布式保证库存数据准...

#### 你们的分布式锁做过高并发优化吗?能扛下每秒上万并发...

#### 淘宝和京东的库存是怎么实现的?能不能不用分布式锁实现...

#### 自己系统的分布式锁在高并发场景下应该如何优化?

#### 为什么在Java面试中一定会深入考察HashMap?

    <https://blog.csdn.net/qq116165600/article/details/103361385>
```
    HashMap作为一个键值对(key-value)的常见集合，在整个java的使用过程中都起着举足轻重的作用。
比如从DB中取值、数据的加工、数据回传给前端、数据转换为json等都可能使用到HashMap；且HashMap
作为一个可以允许空键值对的集合，也能实现自动的扩容，扩容的参数值为0.75，达到后自动扩容一倍，
这样给一些处理未知数据量大小的数据来说，是很方便的。虽然HashMap是线程不安全的，主要体现在
1.7和1.8上。1.7的hashMap在扩容的时候回形成循环链，导致死循环而报错，或者数据的丢失情况，
在1.8上，虽然对这方面做了改进，但是仍然是线程不安全的，主要是体现在，若多线程操作数据，
如线程A  B同时进行数据的put操作，在put操作前，会进行key的hash碰撞，但是线程A  B有可能同时
碰撞且碰撞的值相同，那么就会发生线程A先插入到了碰撞的地方值，然后B也随后插入到同样的地方，导
致线程B会覆盖线程A所插入的值，导致数据丢失。所以，在面试的时候，都很喜欢问HashMap。
```

#### 你知道HashMap底层的数据结构是什么吗?

```
    (数组 + 链表 + 红黑树)
    HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫Entry，这些个键值对（Entry）
分散存储在一个数组之中，这个数组就是hashMap的主干，HashMap数组每一个元素的初始值都是null
```

#### JDK1.8中对hash算法和寻址算法是如何优化的?

```
// JDK1.8以后的HashMap里面的一段源码
static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

* 高低16位参与运算:
    比如有一个key的hash值
    原值: 1111 1111 1111 1111     1111 1010 0111 1100
    右移16位:  0000 0000 0000 0000  1111 1111 1111 1111
    异或运算:   1111 1111 1111 1111     0000 0101 1000 0011 -> 转换成int值表示hash值
    寻址算法优化: (n - 1) & hash  -> 算出数组里的一个位置下标
        取模运算性能差一些，为了优化数组寻址过程，数组长度2的n次方，hash & (n – 1)效果跟hash对n取模效果一样，与运算性能更高。核心在
    于低16的与运算。
* hash算法的优化: 
        对每个hash值，在他的低16位中，让高低16位进行了异或，让他的低16位同时保持了高低16位的特征，尽量避免一些hash值后续出现冲突，大
    家可能会进入数组的同一个位置。
```

#### 你知道HashMap是如何解决hash碰撞问题的吗?

```
    链表+红黑树: O(n)和O(logn)
    利用“拉链法”处理HashCode的碰撞问题；当我们将键值对传递给put方法时，他调用键对象的hashCode()方法来
计算hashCode，然后找到bucket（哈希桶）位置来存储对象；当用get方法获取对象时，通过键对象的equals()方
法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当碰撞发生了，对象将会存储在链表的
下一个节点中。hashMap在每个链表节点存储键值对对象。当两个不同的键却有相同的hashCode时，他们会存储在同
一个bucket位置的链表中。键对象的equals()来找到键值对。
```

#### 说说HashMap是如何进行扩容的可以吗?

```
    2的N次方扩容: 16,32,64...
    rehash:如果数组的长度扩容之后 = 32，重新对每个hash值进行寻址，也就是用每个hash值跟新数组的length - 1进行与操作。
    n-1         0000 0000 0000 0000  0000 0000 0001 1111
    hash1       1111 1111 1111 1111     0000 1111 0000 0101
    &结果       0000 0000 0000 0000  0000 0000 0000 0101 = 5(index = 5的位置)
    n-1         0000 0000 0000 0000 0000 0000 0001 1111
    hash2       1111 1111 1111 1111     0000 1111 0001 0101
    &结果       0000 0000 0000 0000   0000 0000 0001 0101 = 21(index = 21的位置)
    判断二进制结果中是否多出一个bit的1，如果没多，那么就是原来的index，如果多了出来，那么就是index + oldCap，通过这个方式，就避免了
rehash的时候，用每个hash对新数组.length取模，取模性能不高，位运算的性能比较高。
```

#### HashMap默认的初始长度是多少？为什么这么规定？[补充]

```
    HaspMap的默认初始长度是16，并且每次扩展长度或者手动初始化时，长度必须是2的次幂。之所以是16，是为了服务于从Key
值映射到index的hash算法。前面说到了，从Key值映射到数组中所对应的位置需要用到一个hash函数：index = hash("Java");
那么为了实现一个尽量分布均匀的hash函数，利用的是Key值的HashCode来做某种运算。因此问题来了，如何进行计算，才能让这
个hash函数尽量分布均匀呢？一种简单的方法是将Key值的HashCode值与HashMap的长度进行取模运算，即 index = HashCode(Key)
% hashMap.length，但是，但是！这种取模方式运算固然简单，然而它的效率是很低的， 而且，如果使用了取模%， 那么HashMap在
容量变为2倍时， 需要再次rehash确定每个链表元素的位置，浪费了性能。因此为了实现高效的hash函数算法，HashMap的发明者采用
了位运算的方式。那么如何进行位运算呢？可以按照下面的公式：index = HashCode(Key) & (hashMap.length - 1);
```

#### 高并发情况下，HashMap会出现死锁吗？[补充]

    <https://coolshell.cn/articles/9606.html>
```
    由于HashMap的容量是有限的，如果HashMap中的数组的容量很小，假如只有2个，那么如果要放进10个keys的话，碰撞就会非常频繁，
此时一个O(1)的查找算法，就变成了链表遍历，性能变成了O(n)，这是Hash表的缺陷。为了解决这个问题,HashMap设计了一个阈值，
其值为容量的0.75，当HashMap所用容量超过了阈值后，就会自动扩充其容量。在多线程的情况下，当重新调整HashMap大小的时候，
就会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在
链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了
避免尾部遍历。如果条件竞争发生了，那么就会产生死循环了。
```

#### BAT面试官为什么都喜欢问并发编程的问题?

#### 说说synchronized的关键字的底层原理是什么?

```
synchronized(myObject) {
    // code...
    synchronized(myObject) {
        // code...
     }
}
    用于线程同步，加锁。可用于类，对象，块。一般是对一个对象进行加锁。synchronize底层原理与JVM指令和monitor有关系。深入涉及CPU硬件
原理，原则性、可见性、有序性、指令重排、偏向锁、JDK的对其进行的优化。synchronized关键字，底层编译后的JVM指令中，使用monitorenter和
monitorexit指令。monitorenter：加锁,monitorexit：解锁。如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，
计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2。这个时
候，其他的线程在第一次synchronized那里，会发现说myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入
block阻塞状态，什么都干不了，就是等着获取锁。接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit的指令，在底层。此
时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后，计数器是0。
```

#### 深入讲解synchronized,CAS的说明[深入到硬件级别]

#### 能聊聊你对CAS的理解以及其底层原理可以吗?

[](/interview/link/CAS.png)
```
    CAS会操作3个数字，当前内存中的值，旧的预期值，新的修改值，只有当旧的预期值跟内存中的值一样的时候，才会将内存中的值修改为新的修
改值。举个例子吧，比如int a = 3，这是内存中的当前值，然后你CAS（3, 5），第一个是旧的预期值，如果3和a是一样的，那么就将a修改为5。
其实吧，这里比较关键的一点就是cpu的compareAndSwap操作的原理是啥，以CPU（Intel X86）来举个例子。这块底层指令，会根据当前处理器
类型，来决定要不要对一个cmpxchg指令加lock前缀，如果是单处理器，就不要加，因为自动保证顺序；但是如果是多处理器，就加个lock。intel
对lock的定义，就是说加了lock之后，就会自动锁掉一块内存区域，然后同一时间只有一个处理器可以读写这块内存区域，其他处理器就不行了。

    * CAS其实有3个缺点:

    (1) ABA问题：如果某个值一开始是A，后来变成了B，然后又变成了A，你本来期望的是值如果是第一个A才会设置新值，结果第二个A一比较也ok，
也设置了新值，跟期望是不符合的。所以atomic包里有AtomicStampedReference类，就是会比较两个值的引用是否一致，如果一致，才会设置新值
假设一开始变量i = 1，你先获取这个i的值是1，然后累加了1，变成了2。但是在此期间，别的线程将i -> 1 -> 2 -> 3 -> 1这个期间，这个值是
被人改过的，只不过最后将这个值改成了跟你最早看到的值一样的值。结果你后来去compareAndSet的时候，会发现这个i还是1，就将它设置成了2，
就设置成功了。说实话，用AtomicInteger，常见的是计数，所以说一般是不断累加的，所以ABA问题比较少见
    (2) 无限循环问题：大家看源码就知道Atomic类设置值的时候会进入一个无限循环，只要不成功，就不停循环再次尝试，这个在高并发修改一个值
的时候其实挺常见的，比如你用AtomicInteger在内存里搞一个原子变量，然后高并发下，多线程频繁修改，其实可能会导致这个compareAndSet()里
要循环N次才设置成功，所以还是要考虑到的。
    (3) 多变量原子问题：一般的AtomicInteger，只能保证一个变量的原子性，但是如果多个变量呢？你可以用AtomicReference，这个是封装自定
义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是一个。

```

#### ConcurrentHashMap实现线程安全的底层原理到底是什么?

```
    在ConcurrentHashMap没有出现以前，jdk使用hashtable来实现线程安全，但是hashtable是将整个hash表锁住，所以效率很低下。
ConcurrentHashMap将数据分别放到多个Segment中，默认16个，每一个Segment中又包含了多个HashEntry列表数组，对于一个key，
需要经过三次hash操作，才能最终定位这个元素的位置，这三次hash分别为:
    对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)；
    将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment；
    将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。
每一个Segment都拥有一个锁，当进行写操作时，只需要锁定一个Segment，而其它Segment中的数据是可以访问的。
    JDK1.8之前，多个数组，分段加锁，一个数组一个锁。JDK1.8之后，优化细粒度，一个数组，每个元素进行CAS，如果失败，则有线程已经用synchronized
对元素加锁。链表+红黑树处理，对数组每个元素加锁。多个线程要访问同一个数据，synchronized加锁，CAS去进行安全的累加，去实现多线程场景下
的安全的更新一个数据的效果。JDK1.8 [一个大的数组]，数组里每个元素进行put操作，都是有一个不同的锁，刚开始进行put的时候，如果两个线程都
是在数组[5]这个位置进行put，这个时候，对数组[5]这个位置进行put的时候，采取的是CAS的策略，同一个时间，只有一个线程能成功执行这个CAS，
就是说他刚开始先获取一下数组[5]这个位置的值，是null，然后执行CAS，线程1，比较一下，put进去我的这条数据，同时间，其他的线程执行CAS，都
会失败。通过对数组每个元素执行CAS的策略，如果是很多线程对数组里不同的元素执行put，大家是没有关系的，可以并行。如果其他线程失败了，其他
线程此时会发现数组[5]这位置，已经给刚才有线程放进去值了，就需要在这个位置基于链表+红黑树来进行处理，synchronized(数组[5])，加锁，基于
链表或者是红黑树在这个位置插进去自己的数据，如果你是对数组里同一个位置的元素进行操作，才会加锁串行化处理；如果是对数组不同位置的元素操
作，此时大家可以并发执行的。
```

#### 你对JDK中的AQS理解吗?AQS的实现原理是什么?

```
ReentrantLock
state变量 -> CAS -> 失败后进入队列等待 -> 释放锁之后唤醒
非公平锁 公平锁
AQS=Abstract Queue Synchronizer 抽象队列同步器
```


#### 说说线程池的底层工作原理可以吗?

```
ExecutorService threadPool = Executors.newFixedThreadPool(3);
threadPool.submit(new Callable() {
       public void run() {}
});

(1) 在创建了线程池后，等待提交过来的任务请求。
(2) 在调用execute()方法添加一个请求任务时，线程池会做如下判断:
    (a) 如果正在运行的线程数量小于corePoolSize=3，那么马上创建线程运行这个任务；
    (b) 如果正在运行的线程数量大于或等于corePoolSize=3，那么将这个任务放入队列；
    (c) 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务：
    (d) 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize,那么线程池会启动饱和拒绝策略来执行。
(3) 当一个线程完成任务时，它会从队列中去下一个任务来执行。
(4) 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断：
如果当前运行的线程数大于corePoolSize=3，那么这个线程就被停掉。所以线程池的所有任务完成后它最终会收缩到corePoolSize=3的大小。
```

#### 那你再说说线程池的核心配置参数都是干什么的?平时我们应该怎么用?

```
    我们创建线程的常见方式一般有继承Thread类以及实现Runnable接口，其实Thread类也是实现了Runnable接口。通过这两种方式创建的线程，
在执行完毕之后都会被销毁，这样频繁的创建和销毁线程是一件很浪费资源到的事情。那么，有没有什么办法解决这个问题呢?通过创建线程池就
可以解决这个问题。通过线程池创建的线程执行完毕之后并不会销毁，而是会回到线程池继续重复利用，执行其他任务。

* 核心参数
    (1) corePoolSize(核心线程数)
        (a) 核心线程会一直存在，即使没有任务执行；
        (b) 当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数；
        (c) 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。
    (2) queueCapacity(任务队列容量)
    也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。
    (3) maxPoolSize(最大线程数)
        (a) 线程池里允许存在的最大线程数量；
        (b) 当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务；
        (c) 线程池里允许存在的最大线程数量。当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务。
    (4) keepAliveTime(线程空闲时间)
        (a) 当线程空闲时间达到keepAliveTime时，线程会退出（关闭），直到线程数等于核心线程数；
        (b) 如果设置了allowCoreThreadTimeout=true，则线程会退出直到线程数等于零。
    (5) allowCoreThreadTimeout(允许核心线程超时)
    (6) rejectedExecutionHandler(任务拒绝处理器)
        (a) 当线程数量达到最大线程数，且任务队列已满时，会拒绝任务；
        (b) 调用线程池shutdown()方法后，会等待执行完线程池的任务之后，再shutdown()。如果在调用了shutdown()方法和线程池真正shutdown()之间提交任务，会拒绝新任务。

* 线程池参数默认值
    corePoolSize = 1
    queueCapacity = Integer.MAX_VALUE
    maxPoolSize = Integer.MAX_VALUE
    keepAliveTime = 60秒
    allowCoreThreadTimeout = false
    rejectedExecutionHandler = AbortPolicy()

* ThreadPoolExecutor(线程池)执行顺序
    当线程数小于核心线程数时，会一直创建线程直到线程数等于核心线程数；
    当线程数等于核心线程数时，新加入的任务会被放到任务队列等待执行；
    当任务队列已满，又有新的任务时，会创建线程直到线程数量等于最大线程数；
    当线程数等于最大线程数，且任务队列已满时，新加入任务会被拒绝。

* ThreadPoolExecutor已经实现4个拒绝策略
    (1) AbortPolicy: 直接抛异常
    (2) DiscardPolicy: 当前任务会强制调用run先执行，任务将由调用者线程(可能是主线程)去执行。缺点可能会阻塞主线程。
    (3) DiscardOldestPolicy: 抛弃任务队列中最旧任务
    (4) CallerRunsPolicy: 抛弃当前将要加入队列的任务
    (5)自定义: 如果后续慢慢的队列里没任务了，线程空闲了，超过corePoolSize的线程会自动释放掉，在keepAliveTime之后就会释放。
```

#### 如果在线程中使用无界阻塞队列会发生什么问题?

```
    因为调用异常，会调用超时，线程处理任务时间是超时时间，线程池等待队列，会变得越来越大，
此时会导致内存飙升起来，而且还可能导致OOM，内存溢出或者频繁的GC.
```

#### 你知道如果线程池的队列满了之后,会发生什么事情吗?

```
* 使用线程池的好处
    (1) 降低资源消耗 —— 可以重复利用已创建的线程降低线程创建和销毁造成的消耗。
    (2) 提高响应速度 —— 当任务到达时，任务可以不需要等到线程创建就能立即执行。
    (3) 提高线程的可管理性 —— 线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控

* 线程池的工作原理
    (1) 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则执行第二步。
    (2) 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里进行等待。如果工作队列满了，则执行第三步
    (3) 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务

* 线程池饱和策略
    (1) AbortPolicy
    为Java线程池默认的阻塞策略，不执行此任务，而且直接抛出一个运行时异常，切记ThreadPoolExecutor.execute需要try catch，否则程序会直接退出。
    (2) DiscardPolicy
    直接抛弃，任务不执行，空方法。
    (3) DiscardOldestPolicy
    从队列里面抛弃head的一个任务，并再次execute 此task。
    (4) CallerRunsPolicy
    在调用execute的线程里面执行此command，会阻塞入口。
    (5) 用户自定义拒绝策略（最常用）
    实现RejectedExecutionHandler，并自己定义策略模式。

如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。
如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。
如果无法将任务加入BlockingQueue（队列已满），则在非corePool中创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。
如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。
ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。
```

#### 如果线上机器突然宕机,线程池的阻塞队列中的请求怎么办?

```
机器宕机，必然会导致线程池里的积压的任务丢失

如何解决？
    在提交一个任务到线程池里去，提交之前，将这个任务信息持久化到数据库里，此时的状态为 未提交，提交成功之后，更新任务信息的状态为 
提交成功，当任务完成的时候，更新任务信息的状态为 已完成当宕机的机器重启的时候，可以开启一个后台线程，扫描数据库里 未提交和已提交
的任务，可以把任务读取出来，重新提交到线程池中，继续进行执行，被调用的方法一定做好幂等操作，防止请求重复执行。
```

#### 谈谈你对Java内存模型的理解可以吗?

```
Java内存模型8个指令: lock、unlock、read、load、use、assign、store、write
两个线程同时执行data++;操作时，Java内存工作流程: 
```

#### 你知道Java内存模型中的原子性,有序性,可见性是什么?

```
* 可见性:是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的，也就是一个线程修改的结果。另一个线程马上就能看到。线程1操作i++
后，强制线程2操作i时，必须从主内存中刷新更新后的i的值。
    e.g: 用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其
他线程是可见的volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。在 Java 中 volatile、synchronized 和 
final 实现可见性

* 原子性:原子是世界上的最小单位，具有不可分割性
    在 Java 中 synchronized 和在 lock、unlock 中操作保证原子性。线程1对i++时，线程2不能对i++同时进行。同时刻只有一个线程对一个值
进行操作。i++必须独立执行，但默认时线程不安全的。

* 有序性:Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性
    volatile 是因为其本身包含“禁止指令重排序”的语义，synchronized 是由“一个变量在同一个时刻只允许一条线程对其进行 lock操作”这条规则
获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。对于代码，还有一个问题时指令重排序，编译器和指令器，有时候为了提高代码执行
效率，会将指令重排序。具备有序性，不会发生指令重排导致代码异常；不具有有序性，会发生指令重排，导致代码可能会出现一些问题。

volatile关键字用法
public class Counter { 
    public volatile static int count = 0; 
    public static void inc() { 
        //这里延迟1毫秒，使得结果明显 
        try { 
            Thread.sleep(1); 
        } catch (InterruptedException e) { 
        } 
        count++; 
    } 
    public static void main(String[] args) { 
        //同时启动1000个线程，去进行i++计算，看看实际结果 
        for (int i = 0; i < 1000; i++) { 
            new Thread(new Runnable() { 
                @Override
                public void run() { 
                    Counter.inc(); 
                } 
            }).start(); 
        } 
        //这里每次运行的值都有可能不同,可能为1000 
        System.out.println("运行结果:Counter.count=" + Counter.count); 
    } 
}

由于volatile具有可见性，在不并发的情况下是1000，实际输出只有994，由于并发原因
```

#### 能能从Java底层角度聊聊volatile关键字的原理吗?

```
volatile用来解决可见性和有序性，在有些罕见条件下，可以有限保证原则性，但主要不是保证原则性的。讲volatile要从内存模型开始讲起，还有原
子性，可见性，有序性。使其他工作线程内存中的值缓存失效，强制从主内存中读取新值，即可见性。在很多开源中间件系统源码里都有多线程并发，大
量使用volatile关键字。
```

#### 深入讲解volatile关键字的说明[深入到硬件级别]

#### 你知道指令重排以及happens-before原则是什么吗?

```
* 指令重排
    (1) 定义:
    Java 语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序
化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重
排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器
指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。
    (2) 背景:
    我们知道现代CPU的主频越来越高，与cache的交互次数也越来越多。当CPU的计算速度远远超过访问cache时，
会产生cache wait，过多的cache wait就会造成性能瓶颈。针对这种情况，多数架构（包括X86）采用了一种将
cache分片的解决方案，即将一块cache划分成互不关联地多个 slots (逻辑存储单元，又名 Memory Bank 或 
Cache Bank)，CPU可以自行选择在多个 idle bank 中进行存取。这种 SMP 的设计，显著提高了CPU的并行处
理能力，也回避了cache访问瓶颈。
    一般 Memory bank 是按cache address来划分的。比如 偶数adress 0×12345000 分到 bank 0, 奇数address 0×12345100 分到 bank1
    (3) 种类:
    (a) 编译期重排。编译源代码时，编译器依据对上下文的分析，对指令进行重排序，以之更适合于CPU的并行执行。
    (b) 运行期重排，CPU在执行过程中，动态分析依赖部件的效能，对指令做重排序优化。
    
* happens-before原则
    (1) 定义:
    Java存储模型有一个happens-before原则，就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程里面执行），
那么A/B就需要满足happens-before关系。
    (2) 要求:
    (a) 同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。
    (b) 对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。
    (c) 对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。
    (d) Thread.start()的调用会happens-before于启动线程里面的动作。
    (e) Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。
    (f) 一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。
    (g) 一个对象构造函数的结束happens-before与该对象的finalizer的开始
    (h) 如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。
    (3) 理解:
    happens-before规则是用来判断一个动作对另一个动作是否可见的法则，它只是用来判断可见性的，而不是决定执行顺序的，就是说动作A
和动作B 的执行顺序是可以通过指令重排发生变化的，而如果你要保证A和B的可见性关系，就必须采用其他控制手段（比如volatile修饰属性）
来保证AB的执行顺序不被打乱，这样就能用happens-before规则来判断AB两个动作的可见性。
```

#### volatile底层是如何基于内存屏障保证可见性和有序性的?

#### 说说你对Spring的IOC机制的理解可以吗?

```
* 没有Spring之前
    写一套系统，web服务器，tomcat，一旦启动之后，他就可以监听一个端口号的http请求，然后可以把请求转交给你的servlet，jsp，配合起来使用
的，servlet处理请求。比如在我们的一个tomcat + servlet的这样的一个系统里，有几十个地方，都是直接用MyService myService = new MyServiceImpl()，
直接创建、引用和依赖了一个MyServiceImpl这样的一个类的对象。这个系统里，有几十个地方，都跟MyServiceImpl类直接耦合在一起了。如果我现在不想要
用MyServiceImpl了，我们希望用的是NewServiceManagerImpl，implements MyService这个接口的，所有的实现逻辑都不同了，此时我们很麻烦，我们需要
在系统里，几十个地方，都去修改对应的MyServiceImpl这个类，切换为NewServiceManagerImpl这个类。改动代码成本很大，改动完以后的测试的成本很大，
改动的过程中可能很复杂，出现一些bug，此时就会很痛苦。归根结底，代码里，各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，
重新测试，可能还会有bug。

* 有Spring之后
    Spring IoC, Spring容器，根据XML配置或注解，去实例化你的一些bean对象，然后根据XML或注解，去对bean对象之间的引用关系，去进行依赖注入。
底层核心技术是反射。通过反射技术，直接根据你的类去自己构建对应的对象出来。
```

#### 说说你对Spring的AOP机制的理解可以吗?

```
    AOP（Aspect Orient Programming），一般称为面向切面编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务
管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态
代理则以Spring AOP为代表。静态代理是编译期实现，动态代理是运行期实现，可想而知前者拥有更好的性能。
    静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对
象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。
    Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个
接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB
(Code Generation Library)，是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某
个类被标记为final，那么它是无法使用CGLIB做动态代理的，诸如private的方法也是不可以作为切面的。
```

#### 了解过cglib动态代理吗?他和jdk动态代理的区别什么?

```
* jdk动态代理
    需要有顶层接口才能使用，但是在只有顶层接口的时候也可以使用，常见是mybatis的mapper文件是代理。使用反射完成。使用了动态生成字节码技术。
* cglib动态代理
    可以直接代理类，使用字节码技术，不能对 final 类进行继承。使用了动态生成字节码技术。

    动态代理就是动态的创建一个代理类出来，创建这个代理类的实例对象，在这个里面引用你真正自己写的类，所有的方法的调用，都是先走代理类的对
象，他负责做一些代码上的增强，再去调用你写的那个类。Spring里使用aop，比如说你对一批类和他们的方法做了一个切面，定义好了要在这些类的方法
里增强的代码，Spring必然要对那些类生成动态代理，在动态代理中去执行你定义的一些增强代码。如果你的类是实现了某个接口的，spring aop会使用
jdk动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，jdk动态代理，他其实是在你的类有接口的时候，就会来使用。很多时候
我们可能某个类是没有实现接口的，spring aop会改用cglib来生成动态代理，他是生成你的类的一个子类，他可以动态生成字节码，覆盖你的一些方法，
在方法里加入增强的代码。
```

#### 能说说Spring中的Bean是线程安全的吗?

```
* singleton(默认)
    单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例。
* prototype
    原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例，一般来说下面几种作用域，在开发的时候一般都
不会用，99.99%的时候都是用singleton单例作用域。
* request
    对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作
用域才有效，在请求完成以后，bean会失效并被垃圾回收器回收。
* session
    对于每次HTTP Session，使用session定义的Bean豆浆产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效，在session过期后，
bean会随之失效。
* globalsession
    每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中
使用Spring时，该作用域才有效。

    其中比较常用的是singleton和prototype两种作用域。对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护
Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring
容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。如果不指定Bean的作用域，Spring默认使用singleton作用域。
Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。
而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。

    spring 管理的 bean 的线程安全跟 bean 的创建作用域和 bean 所在的使用环境是否存在竞态条件有关，spring 并不能保证 bean 的线程安全。

```

#### Spring的事务实现原理是什么?能聊聊你对事物传播机制的...

[测试用例]<https://blog.csdn.net/qq_26323323/article/details/81908955>
```
* 实现原理
    加一个@Transactional注解，Spring会使用AOP，对这个方法在执行前，先开启事务，在执行完毕后，根据方法是否报错，来决定是回滚还是提交事务。
* 传播机制
    (1) @Transactional(propagation=Propagation.REQUIRED) (默认)
        如果有事务则加入事务，如果没有事务，则创建一个新的(默认值)
    (2) @Transactional(propagation=Propagation.NOT_SUPPORTED)
        Spring不为当前方法开启事务，相当于没有事务,每条执行语句单独执行，单独提交
    (3) @Transactional(propagation=Propagation.REQUIRES_NEW)
        不管是否存在事务，都创建一个新的事务，原来的方法挂起，新的方法执行完毕后，继续执行老的事务
    (4) @Transactional(propagation=Propagation.MANDATORY)
        MANDATORY必须在已有事务下被调用，否则报错;NOT_SUPPORTED执行数据库层面的事务操作，故当前测试中，insert方法成功执行，delete方
    法的抛错并不影响insert方法的执行
    (5) @Transactional(propagation=Propagation.SUPPORTS)
        SUPPORTS类型的事务传播机制，是否使用事务取决于调用方法是否有事务，如果有则直接用，如果没有则不使用事务
    (6) @Transactional(propagation=Propagation.NESTED)
        如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与REQUIRED类似的操作
```

#### 能画一张图说说Spring Boot的核心架构吗?

[](/interview/link/SpringBoot的核心架构.png)
```
(1) 独立运行Spring项目
    Spring boot 可以以jar包形式独立运行，运行一个Spring Boot项目只需要通过java -jar xx.jar来运行。
(2) 内嵌servlet容器
    Spring Boot可以选择内嵌Tomcat、jetty或者Undertow,这样我们无须以war包形式部署项目。
(3) 提供starter简化Maven配置
    spring提供了一系列的start pom来简化Maven的依赖加载，例如，当你使用了spring-boot-starter-web，会自动加入依赖包。
(4) 自动装配Spring 
    SpringBoot会根据在类路径中的jar包，类、为jar包里面的类自动配置Bean，这样会极大地减少我们要使用的配置。当然，SpringBoot只考虑大多数的开发场景，
并不是所有的场景，若在实际开发中我们需要配置Bean，而SpringBoot灭有提供支持，则可以自定义自动配置。
(5) 准生产的应用监控
    SpringBoot提供基于http ssh telnet对运行时的项目进行监控。
(6) 无代码生产和xml配置
    SpringBoot不是借助与代码生成来实现的，而是通过条件注解来实现的，这是Spring4.x提供的新特性。
```

#### 能画一张图说说Spring的核心架构吗?

```
* Spring生命周期: 创建 -> 使用 -> 销毁
* 用xml或注解，定义一堆bean
* 流程
    (1) 实例化bean
        通过反射创建bean对象实例。
    (2) 设置对象属性(依赖注入)
        实例化后的对象被封装在BeanWrapper对象中，Spring根据BeanDefinition中的信息以及通过BeanWrapper提供的设置属性接口完成依赖注入。
    这个bean依赖了谁，把依赖的bean也创建出阿里，给你进行一个注入，比如通过构造函数或setter方法。
    (3) 处理Aware接口
        Spring检查该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean。
        如果这个Bean实现了BeanNameAware接口，则调用它的实现setBeanName(String beanid)方法，传递就是Spring配置文件中的Bean的id值；
        如果这个Bean实现了BeanFactoryAware接口，则调用它实现的setBeanFactory()方法，传递的是Spring工厂自身；
        如果这个Bean实现了ApplicationContextAware接口，则调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；
    (4) BeanPostProcessor
        如果想在bean实例构建之后，在这个时间点对bean进行自定义处理，则可以让bean实现BeanPostProcessor接口，会调用
    postProcessBeforeInitialiazation(Object obj, String s)方法。
    (5) InitalizingBean与init-method
        如果bean在Spring配置文件中配置了init-method属性，则会自动调用其配置的初始化方法。
    (6) BeanPostProcessor
        在bean初始化完成后，如果这个bean实现了BeanPostProcessor接口，会调用postProcessAfterInitialization(Object obj, String s)方法。
    (7) DisposableBean
        当bean不再需要时，如果bean实现了DisposableBean接口，会调用其他实现的destroy()方法。
    (8) destroy-method
        如果配置了destroy-method属性，会调用配置的销毁方法。
```

#### 能说说Spring中都使用了哪些设计模式吗?

```
* 工厂模式(把一个对象的创建过程放入一个具体工厂类中,当需要使用时通过工厂把这个对象实例取出来)
    Spring ioc核心的设计模式的思想提现，他自己就是一个大的工厂，把所有的bean实例都给放在了spring容器里（大工厂），如果你要使用bean，
就找spring容器就可以了，你自己不用创建对象了。
* 单例模式
    Spring默认来说，对每个bean走的都是一个单例模式，确保说你的一个类在系统运行期间只有一个实例对象，只有一个bean，用到了一个单例模式的
思想，保证了每个bean都是单例的。
* 代理模式
    如果说你要对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先
做一些增强的代码，调用你的目标对象。
```

#### 能画一张图说说Spring Web MVC的核心架构吗?

[](/interview/link/SpringWebMVC的核心架构.png)
```
(1) Tomcat的工作线程将请求转交给spring mvc框架的DispatcherServlet
(2) DispatcherServlet查找@Controller注解的controller，我们一般会给controller加上你@RequestMapping的注解，标注说哪些controller
用来处理哪些请求，此时根据请求的uri，去定位到哪个controller来进行处理。
(3) 根据@RequestMapping去查找，使用这个controller内的哪个方法来进行请求的处理，对每个方法一般也会加@RequestMapping的注解。
(4) 会直接调用我们的controller里面的某个方法来进行请求的处理。
(5) 我们的controller的方法会有一个返回值，以前的时候，一般来说还是走jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面
模板的名字，spring mvc的框架使用模板技术，对html页面做一个渲染(现在一般返回一个json串，前后端分离，可能前端发送一个请求过来，我们只要
返回json数据。)
```

#### 能画一张图说说Spring Cloud的核心架构吗?

[](/interview/link/SpringCloud微服务系统图.png)
[](/interview/link/SpringCloud基本流程图.jpg)
```
* 基本组件
    (1) Eureka
        首先，我们需要一个注册中心 Eureka ，主要负责每个服务的注册和发现。每个微服务中都有一个Euraka client组件，专门负责将这个服务
的服务id（serviceId）、ip、端口等信息注册到Eureka server中。Euraka Server是一个注册中心，该组件内部维护了一个注册表，保存了各个服
务所在的机器ip和端口号等信息。
    (2) Feign
        其次每个服务还需要一个远程服务调用的组件 Feign ，他主要负责与其他服务建立连接，构造请求，然后发起请求来调用其他服务来获取数据。
    (3) Ribbon
        然后我们一个服务可能会部署很多台机器，那么我们使用Feign 去调用这个服务的时候，到底把请求发送到哪台机器上去呢？此时我们就需要
    一个组件来根据一定的策略来选择一台机器。不管怎么选的，总之得选一台机器给 Feign 去调用就好了。这个组件就是 Ribbon，Ribbon 主要负
    责就是负载均衡。Ribbon 会定期去从Eureka 注册中心拉取注册中心，缓存到本地，每次发起远程调用的时候，Ribbon 就会从 Eureka 注册表拉
    取下来的数据中挑选一个机器让 Feign 来发起远程调用。
    (3) Zuul
        我们这么多的微服务，如果一个服务一个IP，使用方都需要进行调用的话，是不是得知道每一个服务的IP地址才行呢？那得记住多少才行呀，
    多不好管理。如果有一个统一的地址，然后根据不同的请求路径来跟我进行转发多少是不，比如 /user/* 是转发到用户服务 ，/product/* 是转
    向到商品服务等等。我使用的时候，只需要访问同一个IP ，只是路径不一样，就行了。Spring Cloud 也给我们提供了一个组件，那就是 Zuul ，
    他是一个网关，就是负责网络的路由的。每个请求都经过这个网关，我们还可以做统一鉴权等等很多事情。
    (4) Hystrix
        还有一个东西也得说一下，就是 Hystrix，它是一个隔离、熔断以及降级的一个框架 。在微服务的相互调用过程中，可能会出现被调用服务错
    误或者超时的情况，从而导致整个系统崩溃不可用，也就是我们常说的服务雪崩问题，Hystrix 的存在就是为了解决这种问题的。
* 调用流程
    (1) 首先每个服务启动的时候都需要往注册中心进行注册。
    (2) 用户先对网关发起下单请求，网关收到请求后发现呃，是下单操作，要到订单系统，然后把请求路由到订单系统。
    (3) 订单系统啪啦啪啦一顿操作，然后通过 Feign 去调用 库存系统减库存，通知仓储服务发货，调用积分系统加积分。
    (4) 在发起调用之前，订单系统还得通过Ribbon 去注册中心去拉取各系统的注册表信息，并且挑一台机器给 Feign 来发起网络调用。
```

#### JVM中有哪几块内存区域?Java8之后对内存做了什么改进?

[](/interview/link/JVM内存区域.png)
```
* 物理内存Metaspace(除jvm占用的内存,剩余的内存空间都可以被Metaspace占用)
* 方法区(常量,即时编译后的代码)
* 年轻代(eden space, from survivor, to survivor)
* 老年代
* 程序计数器PC
* 虚拟机栈(局部变量表, 操作数栈, 方法返回地址, 动态链接, 额外附加信息)
* 本地方法栈

    Java 8以后的内存分代的改进，永久代里放了一些常量池+类信息，常量池 -> 堆里面，类信息 -> metaspace（元区域）。

```

#### 你知道JVM是如何运行起来的吗?我们的对象是如何分配的?

[](/interview/link/JVM运行.png)
```
    有一个类里面包含了一个main方法，你去执行这个main方法，此时会启动一个jvm进程，他会默认就会有一个main线程，这个main线程就负责执行
这个main方法的代码，进而创建各种对象。一般tomcat，类都会加载到jvm里去，spring容器而言都会对我们的类进行实例化成bean，有工作线程会来
执行我们的bean实例对象里的方法和代码，进而也会创建其他的各种对象，实现业务逻辑。
```

#### 说说JVM在哪些情况下会触发垃圾回收可以吗?

[](/interview/link/JVM在哪些情况下会触发垃圾回收.png)
```
(1) 对象没有引用
(2) 作用域发生未捕获异常
(3) 程序在作用域正常执行完毕
(4) 程序执行了System.exit()
(5) 程序发生意外终止(被杀进程等)

    JVM的内存其实是有限制的，不可能是无限的，昂贵的资源，2核4G的机器，堆内存也就2GB左右，4核8G的机器，堆内存可能也就4G左右，栈内存也
需要空间，metaspace区域放类信息也需要空间。在jvm里必然是有一个内存分代模型，年轻代和老年代。给年轻代一共是2GB内存，给老年代是2GB内存，
默认情况下eden和2个s的比例：8:1:1，eden是1.6GB，S是0.2GB。如果说eden区域满了，此时必然触发垃圾回收，young gc(ygc)，没有人引用的对
象就是垃圾对象。
```

#### 说说JVM的年轻代垃圾回收算法?对象什么时候转移到老年代?

[](/interview/link/年轻代垃圾回收.png)
```
    年轻代，大部分情况下，对象生存周期是很短的，可能在0.01ms之内，线程执行了3个方法，创建了几个对象，0.01ms之后就方法都执行结束了，
此时那几个对象就会在0.01ms之内变成垃圾，可以回收的100个对象，可能90个对象都是垃圾对象，10个对象是存活的对象，5个复制算法，一次young 
gc，年轻代的垃圾回收。有的对象在年轻代里熬过了很多次垃圾回收，15次垃圾回收，此时会认为这个对象是要长期存活的对象，移到老年代。
```

#### 说说老年代的垃圾回收算法?常用的垃圾回收器都有什么?

```
对老年代而言，他里面垃圾对象可能是没有那么多的。
* 标记-清理: 找出来那些垃圾对象，然后直接把垃圾对象在老年代里清理掉。
* 标记-整理: 把老年代里的存活对象标记出来，移动到一起，存活对象压缩到一片内存空间里去。剩余的空间都是垃圾对象整个给清理掉，剩余的都是
连续的可用的内存空间，解决了内存碎片的一个问题。
* parnew+cms的组合: g1直接分代回收，新版本，慢慢的就是主推g1垃圾回收器了，以后会淘汰掉parnew+cms的组合，jdk 8~jdk 9比较居多一些，
parnew+cms的组合比较多一些。
* CMS: 分成好几个阶段，刚开始用标记-清理，标记出垃圾对象，并发清理一些垃圾对象，整理，把存活的对象压缩到一起，避免内存碎片的产生。
执行一个比较慢的垃圾回收，会stop the world，需要100mb，此时会导致系统停顿100ms，不能处理任何请求，应该尽可能垃圾回收和工作线程的运行，并发执行。
```

#### 你们生产环境中的Tomcat是如何设置JVM参数的?如何检查JVM运行情况?

```
* 你们线上系统jvm参数是怎么配置的，为什么要这样配置，在这个配置参数之下，线上系统jvm运行情况如何?
    一般web系统部署到tomcat，系统仅仅在tomcat的jvm进程来执行。tomcat有一个配置脚本，catalina对应有启动的一些jvm参数设置。主要是内存
区域大小的分配，每个线程的栈大小，metaspace的大小，堆内存大小，年轻代和老年代分别大小，eden和survivor区域的大小分别是多少，如果没有设
置，会有一个默认值。垃圾回收器，年轻代，老年代分别使用哪种垃圾回收器，每种垃圾回收器是否有对应的一些特殊参数设置，这些设置都是用来干什么的。

* 为什么要这样设置?jvm表现如何?
    在一定业务背景下，进行系统运行时的对象数量的预估，对内存压力进行预估，对整个jvm运行状况进行预估，预估完毕之后，根据预估情况，可以
去设置一些jvm参数，然后进行压测，压测时候，需要观察Jvm运行情况，jstat工具去分析jvm运行情况，年轻代的eden区域的对象增长情况，ygc的频
率，每次ygc过后多少对象存活，survivor区能否放的下，老年代对象增加速率，老年代多久会触发一次fgc。可以根据压测的情况进行一定的jvm参数
的调优。压测主要两点：一个系统QPS，一个是系统的接口性能。压测到一定程度时，了解机器的cpu, 内存，io, 磁盘的负载情况，jvm的表现等，由
此需要对一些代码进行优化，比如优化性能，或减轻cpu, io磁盘负担等，如果发现jvm的gc过于频繁，内存泄漏，需要对jvm各内存区域的大小以及一
些参数进行调优。在线上生产环境时，也需要基于一些监控工具，或者jstat，观察系统的QPS和性能，接口可用性，调用成功率，机器负载，jvm表现，
gc频率，耗时，内存消耗等等。
```
#### 你在实际项目中是否做过JVM GC优化,怎么做的?

```
上一讲是如何通过预估+压测，做一份生产环境的jvm参数，去观察jvm运行情况。
如果jvm出频繁full gc，有没有尝试过生产环境的系统去进行gc优化，对于这个问题，需要结合具体业务来分析。
如何一步一步去分析系统的jvm的性能问题，如何去进行jvm gc调优?
分不同情况：
(1) 自己做过jvm gc的生产调优，恭喜你了，直接实话实说，你当时怎么调优，你们的问题如何暴露出来的，你如何一步一步定位问题的，如何进行调优，
最后的结果是什么?
(2) 你看了jvm专栏，在过程中，或者看完以后，在自己生产环境中根据专栏学习到的知识，去调优过jvm，这个时候，你可以专栏里学习到的知识，去讲。
最好对自己系统的生产环境的jvm，进行一个分析，gc频繁的问题，尽可能的去调优一下参数。
(3) 发现分析了一下生产环境的jvm的运行情况，非常好，并发量很低，几十分钟才一次young gc，存活的对象特别少，几乎都在s区域，老年代几乎没
什么对象，几天或者几周才发生一次full gc，在自己本地单机部署，测试环境里，去压测，每秒单机有500并发请求，去观察jvm的运行情况，这个时候他
会不会存在频繁gc的问题，你就去调优一下，你就可以基于这个压测的例子去讲解。
```

#### 你知道发生OOM之后,应该如何排查和处理线上系统的OO...

```
* 年老代堆空间被占满
    异常: java.lang.OutOfMemoryError：java  heap space
    说明: 这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机再也无法分配新空间
    解决: 这种方式解决起来比较简单，一般就是根据垃圾回收前后的情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。

* 持久代被占满
    异常: java.lang.OutOfMemoryError：PermGen space
    说明: Perm 空间被占满，无法为新的 class 分配存储空间而引发的异常。这个异常以前是没有的，但是在 java 大量使用反射的今天这个异常就比较常见了。
主要原因是大量动态反射生成的类不断被加载，最终导致 Perm 区被占满。更可怕的是，不同的 classLoader 即便使用相同的类，但是都会对其进行加载，相当于
同一个东西，如果有 N 个classLoader 那么它将会被加载 N 次。因此，在某些情况下，这个问题基本视为无解，当然，存在大量 classLoader 和大量反射类的情
况并不多
    解决: 增加持久代内存 ，例如：-XX：MaxPermSize=16M

    思考oom可能发生在哪几个区域。解决思路，在jvm里设置几个参数，一旦发生oom之后，就会导出一份内存快照，就会有当时线上内存里对象的一个情况，
可以用MAT（eclipse的一个插件(MAT也可以单独使用)）这样的工具进行分析。无非就是找出来当时占用内存最大的对象，找出来这些对象在代码中哪些地方
创建出来的，一般来说就是可能会对内存做一个调优。从业务背景出发，一步一步的说明，在什么样的业务背景下，为什么会产生oom的问题？当某个系统崩溃
时，找到自动导出的内存快照，分析XX 对象，直接定位代码，修改代码。你一定要把案例的业务、背景和思想给吸收了，就得融入到自己的业务里去，我负责
的业务系统，在什么样的情况下，可能说会出现一大批的对象卡在内存里，无法回收，导致我系统没法放更多的对象了。oom不是你自己的代码，可能是你依赖
的第三方的组件，结合自己的项目去一步一步的分析，oom问题的产生，和解决的过程。
```

#### 你能聊聊TCP/IP四种网络模型吗?OSI七层网络模型也说一下!

[](/interview/link/网络模型.png)
```
* 数据链路层(以太网协议)
    一堆0/1电路信号，封装成数据包，包含头(head)和数据(data)，head里包含从哪儿来到哪儿去，从一台电脑的一个网卡，发送到另外一台电脑的
一个网卡，以太网发送的数据包指定目标电脑网卡的mac地址。
* 网络层(IP协议)
    IPv4和IPv6，IPv4由32个二进制组成，一般用4个十进制数字表示，从0.0.0.0到255.255.255.255之间。IP地址前24位(前3个十进制数字)代表
网络，后8位(最后一个十进制数字)代表主机。前3个十进制数字相同表示同一个子网的。子网掩码：用于判断两个IP地址是不是同一个子网。判断方法
就是分别把两个IP地址和自己的子网掩码进行二进制与运算，比较代表网络那部分是否相同。
    (1) 路由器
        负载将多个子网进行连接，实际就是配置了多个网卡的设备，可以通过不同网卡接入不同的网络。网关，其实是路由器的一种，运作在网络层。
    可以就把路由器上的ip地址认为是网关，路由器上每个网卡都有mac地址和对应的ip地址。路由器虽然有mac地址，但是不能通过mac地址寻址的，
    必须通过ip地址寻址，所以路由器其实是工作在网络层的设备。
    (2) 网络交换机
        通过mac地址来寻址和传输数据包的；但是路由器是通过ip地址寻址和传输数据包的。网络交换机主要用在局域网的通信，一般你架设一个局域
    网，里面的电脑通信是通过数据链路层发送数据包，通过mac地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其
    他机器上去的。
    一个子网内的机器之间通信，就是在数据包里写上对方的mac地址，然后交换机广播出去ok了；但是如果是跨子网的通信，就是写上对方的ip地址，
然后先通过mac地址广播到路由器，让路由器再根据另外一个子网的ip地址转换为mac地址，通过另外一个子网的交换机广播过去。
* 传输层(TCP协议)
    端口，发送数据包到某个机器的一个网卡的某个端口上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的
数据。端口号是0~65536的范围内，0~1023被系统占用了，别的应用程序就用1024以上的端口。网络层，是基于ip协议，进行主机和主机间的寻址和通信
的，然后传输层，其实是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。这个通信，就是通过socket来实现的，通过socket就可
以基于tcp/ip协议完成刚才上面说的一系列的比如基于ip地址和mac地址转换和寻址啊，通过路由器通信啊之类的，而且会建立一个端口到另外一个端口
的连接。
* 应用层(HTTP协议)
    针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。比如最常见的，应用层的协议就是http协议，进行网络通信。电子邮件协
议，SMTP、POP3、IMAP4等。GET http://localhost:8080/   http/1.1    key:value
```

#### 浏览器请求www.baidu.com的全过程大概是怎样的?...

[](/interview/link/浏览器请求过程.png)
```
* 假设我们电脑设置了几个东西如下:
    ip地址：192.168.31.37
    子网掩码：255.255.255.0
    网关地址：192.168.31.1
    DNS地址：8.8.8.8
(1) 请求www.baidu.com地址，这个时候找DNS服务器，DNS服务器解析域名之后，返回一个ip地址，比如172.194.26.108。
(2) 判断本机和访问的IP是不是同一个子网，用子网掩码坐与运算。通常不在一个子网，就发送数据包给网关，也就是路由器。 通过浏览器访问网站，
走应用层的http协议，把浏览器发出的请求打包为数据包。把http协议请求，有请求头，空行，请求数据，就构成http请求报文，封装到一个应用
层数据包里。
(3) 接下来走到传输层，按照TCP协议，TCP协议会让你设置端口，发送方端口随机选择，接收端一般默认80端口。这时会把应用层数据包封装到TCP数
据包，再加一个TCP头，TCP头放了端口信息。
(4) 走网络层，会把TCP头和TCP数据包，放到IP数据包里，再做了一个IP头，IP头包括本机和目标机器的IP地址。通过IP 协议，判断两个IP不在一个
子网内，则将数据包通过以太网协议广播到网关，通过网关在发生出去。
(5) 最后走到数据链路层，把IP头和IP数据包封装到以太网数据包，再增加一个以太网数据包头，头里放了本机网卡MAC地址和网关MAC地址。但以太网
数据包有1500字节的限制，超过要切分为多个数据包，每个数据包包含以太网头、IP头和切割后的IP数据包。以太网数据包通过交换机发送到网关，然
后通过路由器转发到别的子网或者别的路由器，以此类推，通过N个路由器或网关转发，最终到达目标服务器，比如172.194.26.108。目标服务器接收到
以太网数据包后，从IP数据包，拿出TCP数据包，再从TCP数据包取出HTTP数据包，读取出HTTP数据包里各种协议内容，比如html页面，或者业务处理，
然后再把响应结果封装成http响应报文，封装到http数据包里，再封装TCP数据包，封装IP数据包，封装以太网数据包，再通过网关发送回去，完成整个
请求过程。
```

#### 画一下TCP三次握手流程图?为啥是三次而不是二次或者四次呢?

[](/interview/link/TCP三次握手流程图.png)
```
* 三次握手
    建立三次握手的时候，TCP报头用到了下面几个东西，ACK、SYN、FIN。第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，这就是说这是
个连接请求，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1，
SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1
* 二次握手
    假设两次握手就ok了，要是客户端第一次握手过去，结果卡在某个地方了，没到服务端；完了客户端再次重试发送了第一次握手过去，服务端收到了，
ok了，大家来回来去，三次握手建立了连接。结果，尴尬的是，后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手，
这个时候服务器开辟了资源准备客户端发送数据啥的，结果呢？客户端根本就不会理睬这个发回去的二次握手，因为之前都通信过了。但是如果是三次握手，
那个二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器撤销开辟的资源，别等着了。
* 四次挥手
    第一次挥手，客户端发送报文，FIN=1，seq=u，此时进入FIN-WAIT-1状态。第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文，
ACK=1，ack=u+1，seq=v。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。第三次挥手，服务端发送连接释放报
文，FIN=1，ack=u+1，seq=w，服务端进入LAST-ACK状态。第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，seq=u+1，进入
TIME_WAIT状态，等待一会儿客户端进入CLOSED状态，服务端收到报文之后就进入CLOSED状态。
```

#### 聊聊HTTP协议的工作原理!

```
* http的工作流程
    http请求封装到应用层数据包，封装在tcp数据包，封装在ip数据包，封装在以太网数据包，如果过大，可能会拆成几个包，走以太网协议+交换机 
-> 广播 -> 网关 -> 多个网关 -> 目标的机器 -> 一层一层拆包 -> http请求报文 -> 传递给tomcat -> spring mvc -> http响应 -> 一样的路
径会去。浏览器 -> 网站，互相之间是先要通过tcp三次握手，建立一个连接，浏览器和网站互相都给对方留出一份资源，浏览器发起http请求 -> tcp 
-> ip -> 以太网，网站上面去，网站返回一个响应，连接关闭，tcp四次挥手。释放掉浏览器和网站各自给对方保持的一份资源。

* http1.0、http1.1、http2.0具体有哪些区别?
    http 1.0要指定keep-alive来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次tcp连接，完事儿了就释放tcp连接。早期的
网页都很low，没啥东西，就一点文字，就用这个没问题。2000年之前，那个时候网页，都很low，当时你打开一个网页，就是说现场底层tcp三次握手，
跟网站建立一个tcp连接，然后通过这个tcp连接，发送一次http请求，网站返回一个http响应（网页的html，里面有一大段文字），浏览器收到html渲
染成网页，浏览器就走tcp四次挥手，跟网站断开连接了。2000之后，2010之后更不用说了，网页发展很迅猛，一个网页包含着大量的css、js、图片等
资源。比如你请求一个网页，这个网页的html先过来，过来之后，浏览器再次发起大量的请求去加载css、js、图片，打开一个网页可能浏览器要对网站
服务器发送几十次请求。再频繁建立和释放tcp连接，会很慢很慢。
    http 1.1默认支持长连接，就是说，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于
这个tcp连接来走。http 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。浏览器，第一次请求去一个网站的一个页面的时候，就会
打开一个tcp连接，接着就在一段时间内都不关闭了，然后接下来这个网页加载css、js、图片大量的请求全部走同一个tcp连接，频繁的发送请求获取响
应，最后过了一段时间，这些事儿都完了，然后才会去释放那一个tcp连接。大幅度的提升复杂网页的打开的速度，性能。
    未来http 2.0，支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。
二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐。
```

#### 聊聊HTTPS的工作原理?为啥用HTTPS就可以加密通信?

[](/interview/link/HTTPS的工作原理.png)
```
* 浏览器把自己支持的加密规则发送给网站。
* 网站从这套加密规则里选出来一套加密算法和hash算法，然后把自己的身份信息用证书的方式发回给浏览器，证书里有网站地址、加密公钥、证书颁发机构。
* 浏览器验证证书的合法性，然后浏览器地址栏上会出现一把小锁；浏览器接着生成一串随机数密码，然后用证书里的公钥进行加密，这块走的非对称加密；
用约定好的hash算法生成握手消息的hash值，然后用密码对消息进行加密，然后把所有东西都发给网站，这块走的是对称加密。
* 网站，从消息里面可以取出来公钥加密后的随机密码，用本地的私钥对消息解密取出来密码，然后用密码解密浏览器发来的握手消息，计算消息的hash值，
并验证与浏览器发送过来的hash值是否一致，最后用密码加密一段握手消息，发给浏览器。
* 浏览器解密握手消息，然后计算消息的hash值，如果跟网站发来的hash一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，然后用
对称加密来进行进行加密。(常用的非对称加密是RSA算法，对称加密是AES、RC4等，hash算法就是MD5。)
```

#### 聊聊http的长连接的工作原理到底是啥?

```
    http本身没什么所谓的长连接短连接之说，其实说白了都是http下层的tcp连接是长连接还是短连接，tcp连接保持长连接，那么多个http请求和
响应都可以通过一个链接来走。其实http 1.1之后，默认都是走长连接了，就是底层都是一个网页一个tcp连接，一个网页的所有图片、css、js的资源
加载，都走底层一个tcp连接，来多次http请求即可。http 1.0的时候，底层的tcp是短连接，一个网页发起的请求，每个请求都是先tcp三次握手，然
后发送请求，获取响应，然后tcp四次挥手断开连接；每个请求，都会先连接再断开。短连接，建立连接之后，发送个请求，直接连接就给断开了。http 1.1，
tcp长连接，tcp三次握手，建立了连接，无论有多少次请求都是走一个tcp连接的，走了n多次请求之后，然后tcp连接被释放掉了。
```

#### MYSQL,MyISAM和InnoDB存储引擎的区别是啥?

#### 聊聊MySQL的索引实现原理?各种索引你们平时都怎么用...

#### 你能说说事务的几个特性是啥?有哪几种隔离级别?

#### 你能说说MySQL数据库锁的实现原理吗?如果死锁了咋办?

#### MySQL的SQL调优一般都有哪些手段?你们一般怎么做?

    <https://blog.csdn.net/zhangbijun1230/article/details/81608252>

#### 聊聊Socket的工作原理?Socket和TCP IP之间是啥关系?

```
socket属于传输层的一个编程规范。socket就是在传输层把tcp/ip协议给封装了，Java原生支持socket网络编程。一般都是面试socket来编程。
```

#### 进程之间是如何通信的?线程间又如何切换的?

#### 你能聊聊BIO,NIO,AIO分别都是啥?有什么区别?

[](/interview/link/BIO.png)
[](/interview/link/NIO.png)
```
* BIO: 同步阻塞式IO
    服务端创建一个ServerSocket，客户端用一个Socket去连接那个ServerSocket，然后ServerSocket接收到Socket连接请求就创建一个Socket和
一个线程去和客户端Socket通信。
    缺陷: 客户端socket发送一个请求，服务端socket进行处理后返回响应，响应必须是等处理完成之后才能返回，这期间不能做其他事，只能等待(卡
住)...而且每一个客户端接入，服务端就需要创建一个线程来服务，会导致客户端大量增加时，服务端线程会负责过高(可能几千几万个线程。。)，最
后服务端崩溃。
    优化: 可以用线程池，固定线程来处理客户端请求，但是高并发时，会导致大量排队和延时。
* NIO: 同步非阻塞IO,基于Reactor模型
    (1) Channel
        表示为一个已经建立好的支持I/O操作的实体（如文件和网络）的连接，在此连接上进行数据的读写操作，使用的是缓冲区来实现读写。
    (2) Buffer
        在内存中预留指定大小的存储空间用来对输入/输出(I/O)的数据作临时存储。
        好处:  减少实际的物理读写次数缓冲区在创建时就被分配内存，这块内存区域一直被重用，可以减少动态分配和回收内存的次数好比从A工地搬
        1w块砖到B工地，路途远(IO性能消耗大)，没有工具时(缓冲区)，一次搬1块，要搬1w次(IO读写1w次)。用卡车(缓冲区)，一次运送5K块，2次
        就运完了，性能大大提高了。
    (3) Selector(多路复用器)
        selector会不断轮询注册的channel，如果某个channel上发生了读写事件，selector就会将这些channel获取出来，我们通过SelectionKey
        获取有读写事件的channel，就可以进行IO操作。一个Selector就通过一个线程，就可以轮询成千上万的channel，这就意味着你的服务端可以
        接入成千上万的客户端。
    核心就是非阻塞，selector一个线程可以不停轮询channel，所有客户端都不会阻塞，最多排队。只有某个客户端发送了一个请求，才会启动一个线
程来处理。客户端接入不会耗费一个线程，只会创建一个channel连接，然后注册到selector上，一个selector线程不断轮询所有的socket连接(channel)，
发现有事件就通知，启动工作线程处理一个请求。工作线程，从channel-buffer读数据，如果数据没有读完卡住，等待，然后处理后往buffer-channel里
写数据，也是自己做，写数据时数据没有写完，也卡住等待，是同步的。
* AIO(基于Proactor模型的,就是异步非阻塞模型)
    每个请求会绑定一个buffer，通知操作系统去异步完成读写，此时工作线程可以做别的事情（异步），等操作系统完成之后，回调接口，把操作系统
完成的数据给工作线程。
```

#### 线上服务CPU100%了!该怎么排查,定位和解决?

    <https://blog.csdn.net/weixin_38827340/article/details/85311247>

#### 线上机器的一个进程用kill命令杀不死该怎么办?磁盘空间快...

#### 关于后续深入硬件级讲解volatile,synchronized,CAS底...

#### 再谈原子性: Java规范规定所有变量写操作都是原子的

#### 32位Java虚拟机中的long和double变量写操作为何不是原子...

#### volatile原来还可以保证long和double变量写操作的原子性

#### 到底有哪些操作在Java规范中是不保证原子性的呢?

#### 可见性涉及的底层硬件概念: 寄存器,高速缓存,写缓存...

#### 深入探秘有序性: Java程序运行过程中发生指令重排的几个...

#### JIT编译器对创建对象的指令重排以及double check单例实践

#### 现代处理器为了提升性能的指令乱序和猜测执行的机制!

#### 高速缓存和写缓存器的内存重排造成的视觉假象

#### synchronized锁同时对原子性,可见性，以及有序性的保证

#### 深入分析synchronized是如何通过加锁保证原子性的?

#### synchronized是如何使用内存屏障保证可见性和有序性的?

#### 再看volatile关键字对原子性,可见性以及有序性的保证

#### 高速缓存的数据结构: 拉链散列表,缓存条目以及地址解码...

#### 结合硬件级别的缓存数据结构深入分析缓存一致性协议...

#### 采用写缓冲器和无效队列优化MESI协议的实现性能

#### 硬件层面的MESI协议会如何引发有序性和可见性的问题?

#### 内存屏障在硬件层面的实现原理以及如何解决各种问题

#### 在复杂的硬件模型之上的Java内存模型是如何大幅简化...

#### 面试的时候是如何从内存屏障,硬件层面的原理来震慑面试...

#### Java虚拟机对锁的优化: 锁消除,锁粗化,偏向锁,自旋锁...

#### 再来看看CAS是如何基于MESI协议在底层硬件层面实现...

#### 能不能说说一般黑客常用的XSS网络攻击的原理是什么?

#### 能不能说说我们经常听到的SQL注入攻击背后的原理是什...

#### 听说过CSRF攻击吗?你知道他背后的原理是什么吗?

#### 如果你们的系统允许用户上传文件,可能会遭到什么样的黑...

#### 让所有工程师闻风色变的DDoS攻击到底是什么东西?

```
    DDoS(英文Distributed Denial of Service，即分布式拒绝服务)，这是一种网络攻击方式，主要目的是以分布式攻击来让指定目标无法提供正
常服务，甚至从互联网上消失。说白了就是一定时间内增大访问量，使其无法正常提供服务。看过最形象也最好笑的比喻是，春运抢火车票导致12306网
站瘫痪，就是DDOS攻击。DDOS只不过是一个概称，其下有各种攻击方式，比如“CC攻击、SYN攻击、NTP攻击、TCP攻击、DNS攻击等等”
    攻击者利用大量“肉鸡”对攻击目标发动大量的正常或非正常请求、耗尽目标主机资源或网络资源，从而使被攻击的主机不能为合法用户提供服务。大
家应该还听过DoS攻击。DoS（拒绝服务，Denial of Service）就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。
这是早期非常基本的网络攻击方式。
```

#### 基于SYN Flood模式的DDoS攻击,背后的原理是什么呢?

#### 再来看看基于DNS Query Flood和HTTP Flood的DDoS攻击

#### 在分布式架构中, Zuul网关是如何防止网络攻击的?

#### 一个对技术有追求的面试官,是怎么深挖网络与IO的面试...

#### Netty的架构原理图能画一下吗,他是如何体现Reactor架...

#### 能说说你对堆外内存的理解吗?堆外内存的优势在哪里?

#### JDK是如何对堆外内存进行分配和回收的?会发生堆外内存...

#### 如何不使用零拷贝技术,普通的IO操作在OS层面是如何执...

#### 听说过mmap吗?内存映射技术为什么可以提升IO性能?

#### 零拷贝技术到底是什么,他是如何提升IO性能的?

#### 你们的分布式系统是如何进行链路监控的?都监控什么?

#### 对分布式系统进行核心链路追踪的时候,链路id是怎么管理...

```
* 背景
    通过增加应用层的标记对服务化中的请求和响应建立联系，例如通过HTTP协议头携带标记信息，标记信息包括标示调用链的唯一ID，这里叫作TraceID，
以及标示调用层次和顺序的SpanID和ParentSpanID。
* 调用信息
    调用端或者被调用端的ID、系统ID；本次请求的TraceID、SpanID和ParentSpanID；时间戳、调用的方法名称及远程调用信息的类型，等等。
* 过程
    前端接收用户请求后会为用户分配一个TraceID，在内部服务调用时，会通过应用层的协议将TraceID传递到下层服务，直到整个调用链的每个节点
都拥有TraceID，这样在系统出现问题时，可以使用这个唯一TraceID迅速问题发生的节点。
    TraceID解决了系统串联的问题，但是我们无法标识和恢复这些请求和响应调用时的顺序和层级关系。因此我们需要附加的信息在系统之间的请求和
响应消息中传递，它就是SpanID，这里SpanID包含SpanID和ParentSpanIDSpanID和ParentSpanID组合在一起就可以表示一个树形的调用关系，SpanID
表示当前为一个调用节点，ParentSpanID表示这个调用节点的父节点。
* 当系统出现故障时
    (1) 通过TraceID把一整条调用链的所有调用信息收集到一个集合中，包括请求和响应
    (2) 通过SpanID和ParentSpanID恢复树形的调用树，ParentSpanID为-1的节点为根节点
    (3) 识别调用链中出错或超时的节点，做出标记
    (4) 把恢复的调用树和出错的节点信息通过某种图形显示到UI界面上。
* 如何产生SpanID
    (1) 使用随机数产生SpanID，理论上有可能重复，但是由于64位长整型，重复的可能性微乎其微，并且本地生成随机数的效率高于其他方法。
    (2) 使用分布式的全局唯一的流水号生成方式，可参考互联网发好器Vesta。
    (3) 每个SpanID包含所有父亲及前辈节点的SpanID，使用圆点符号作为分隔符，不再需要ParentSpanID字段，如下图，这种方案实现起来简单，
    但是如果调用链有太多的节点和层次时，SpanID会携带太多的冗余信息，导致服务间调用的性能下降。
```

#### 聊过两阶段提交了,那么分布式事务三阶段提交的思想能说...

#### 唯一id生成机制中的snowflake算法的时钟回拨问题...

```
* 定义
    SnowFlake算法生成id的结果是一个64bit大小的整数, 其中的41位时间戳部分依赖服务器的时间, 当服务器发生时钟回拨时, 在开源的实现中不
可避免的会出现报错. 关于解决时钟回拨的问题, 网上已有各种方案, 比如适当等待直到时间被追回, 在内存中保存一段时间内使用过的最大序列号
* 方案
    首先, SnowFlake的末尾12位是序列号, 用来记录同一毫秒内产生的不同id, 同一毫秒总共可以产生4096个id, 每一毫秒的序列号都是从0这个基
础序列号开始递增假设我们的业务系统在单机上的QPS为3w/s, 那么其实平均每毫秒只需要产生30个id即可, 远没有达到设计的4096, 也就是说通常情况
下序列号的使用都是处在一个低水位, 当发生时钟回拨的时候, 这些尚未被使用的序号就可以派上用场了.因此, 可以对给定的基础序列号稍加修改, 后
面每发生一次时钟回拨就将基础序列号加上指定的步长, 例如开始时是从0递增, 发生一次时钟回拨后从1024开始递增, 再发生一次时钟回拨则从2048递
增, 这样还能够满足3次的时钟回拨到同一时间点(发生这种操作就有点扯了)。
```

#### 实现灰度发布的时候,网关是可以灰度了,可是Dubbo服务...

```
    Dubbo提供的Router，在进行负载均衡前，根据路由规则对服务提供者列表进行筛选。
```

```
* 定义
    灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，
一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，
在初始灰度的时候就可以发现、调整问题，以保证其影响度。
```

#### 除了常见服务注册中心之外,你觉得Redis能作为服务注...

```
    redis 作为dubbo的注册中心，实现的功能跟 zk相同，但是内部的实现机制大相径庭，因为zk 有临时节点，服务端在zk 中创建临时节点会一直
保持连接，如果服务器出现崩溃，自动断连，而redis 则要靠主服务器进行定时轮询
```

#### 我们一般到底用Zookeeper来干什么事儿?

```
* 数据发布与订阅
    (1) 典型场景描述
        发布与订阅即所谓的配置管理，顾名思义就是将数据发布到zk节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如
    全局的配置信息，地址列表等就非常适合使用。
    (2) 应用中的具体使用
        (a) 索引信息和集群中机器节点状态存放在zk的一些指定节点，供各个客户端订阅使用。
        (b) 系统日志（经过处理后的）存储，这些日志通常2-3天后被清除。
        (c) 应用中用到的一些配置信息集中管理，在应用启动的时候主动来获取一次，并且在节点上注册一个Watcher，以后每次配置有更新，实时
        通知到应用，获取最新配置信息。
        (d) 业务逻辑中需要用到的一些全局变量，比如一些消息中间件的消息队列通常有个offset，这个offset存放在zk上，这样集群中每个发送
        者都能知道当前的发送进度。
        (e) 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息。以前通常是暴露出接口，例如JMX接口，有了zk后，只要将这些
        信息存放到zk节点上即可。
* Name Service(命名服务)
    (1) 典型场景描述
        这个主要是作为分布式命名服务，通过调用zk的create node api，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。
* 分布通知/协调
    (1) 典型场景描述
        ZooKeeper 中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使
    用方法通常是不同系统都对 ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那
    么另一个系统能 够收到通知，并作出相应处理。
    (2) 应用中的具体使用
        (a) 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。
        (b) 另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作
        的一些操作，实际上是修改 了ZK上某些节点的状态，而zk就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。
        (c) 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写
        回这个临时节点），这样任务管理者就能够实时知道任务进度。总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合。
* 分布式锁
    (1) 典型场景描述
        分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk集群中任意节点（一个zk server）
    上的相同znode的数据是一定是相同的。锁服务可以分为两类，一个是保持独占，另一个是控制时序。所谓保持独占，就是所有试图来获取这个锁的客户
    端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 
    /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，
    只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属
    性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指 定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也
    形成了每个客户端的全局时序。
* 分布式队列
    (1) 典型场景描述
        队列方面，我目前感觉有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第二种先进先出队列，和分
    布式锁服务中的控制时序场景基本原理一致，这里不再赘述。第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预
    先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，
    决定是否可以开始执行 了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个
    时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 
    发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。
* 集群管理
    (1) 典型场景描述
        (a) 集群机器监控：这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，
        往往有一个监控系统，实时检测集群 机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机
        器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：1. 集群中机器有变动的时候，牵连修改的东西比较
        多。2. 有一定的延时。利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：a. 客户端在节点 x 上注册一个Watcher，
        那么如果 x 的子节点变化了，会通知该客户端。b. 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。
        例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类
        型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。
        (b) Master选举(zookeeper中最为经典的使用场景)
        在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某
        一台机器进行执行， 其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要
        问题。利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 
        节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。另外，这种场景演化一下，
        就是动态Master选举。这就要用到 EPHEMERAL_SEQUENTIAL类型节点的特性了。上文中提到，所有客户端创建请求，最终只有一个能够创建成功。
        在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终 在ZK上创建结果的一种可能情况是这样： 
        /currentMaster/{sessionId}-1 , /currentMaster/{sessionId}-2 , /currentMaster/{sessionId}-3 ….. 每次选取序列号最小的
        那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。
    (2) 应用中的具体使用
        (a) 在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行
        全量索引的生成， 然后同步到集群中其它机器。
        (b) 另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向
        一个地方获取master。
```

#### 有哪些开源的分布式系统中使用了Zookeeper?

```
    Hadoop、HBase、Kafka
```

#### 为什么我们在分布式系统架构中需要使用Zookeeper集群?

```
* 单点问题
    单点问题是分布式环境中最常见也是最经典的问题之一，在很多分布式系统中都会存在这样的单点问题。具体地说，单点问题是指在一个分布式系统
中，如果某一个组件出现故障就会引起整个系统的可用性大大下降甚至是处于瘫痪状态，那么我们就认为该组件存在单点问题。ZooKeeper 确实已经很好
地解决了单点问题。我们已经了解到，基于“过半”设计原则，ZooKeeper 在运行期间，集群中至少有过半的机器保存了最新的数据。因此，只要集群中超
过半数的机器还能够正常工作，整个集群就能够对外提供服务。
* 容灾
    在进行 ZooKeeper 的容灾方案设计过程中，我们要充分考虑到“过半原则”。也就是说，无论发生什么情况，我们必须保证 ZooKeeper 集群中有超
过半数的机器能够正常工作。
```

#### Zookeeper为了满足分布式系统的需求要有哪些特点?

```
* 构造高可用集群
    zookeeper的选举模式保证了集群的相对稳定性，从而使得集群是高可用的。

* 集群全局配置文件管理
    即统一资源配置，在一个偌大的集群环境中，假设你需要对该集群的配置文件作修改，假设集群很庞大，手动去修改是一件不太现实的事，不但费
时费力，还极有可能造成差错，zookeeper可以自动帮我们完成配置文件的分发，既高效又准确。

* 发布与订阅
     支持服务发布与状态监听。

* 分布式锁
    在集群环境下，同样会存在对资源的竞争，zookeeper提供了分布式锁实现了同步。

* 保证数据强一致性
    在集群环境下，对集群中某个节点的数据的改变，会被zookeeper同步到其他机器上。

* 额外补充
    cversion: 子节点版本号 
    ephemeralOwner: 用于判断节点是持久的还是临时的
```

#### 为了满足分布式系统的需求,Zookeeper的架构设计有哪...

#### Zookeeper集群的三种角色: Leader,Follower,Observer

```
* Zookeeper服务器的三种节点类型
    群首(leader)，追随者(follower)，观察者(observer)
* Leader
     Leader作为整个ZooKeeper集群的主节点，负责响应所有对ZooKeeper状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个
集群内部消息处理的FIFO。
* Follower
      Follower的逻辑就比较简单了。除了响应本服务器上的读请求外，follower还要处理leader的提议，并在leader提交该提议时在本地也进行提交。
* Observer
    如果ZooKeeper集群的读取负载很高，或者客户端多到跨机房，可以设置一些observer服务器，以提高读取的吞吐量。Observer和Follower比较相
似，只有一些小区别：首先observer不属于法定人数，即不参加选举也不响应提议；其次是observer不需要将事务持久化到磁盘，一旦observer被重启，
需要从leader重新同步整个名字空间。
```

#### 客户端与Zookeeper之间的长连接和会话是什么?

```
* 会话概述
    在ZooKeeper中，客户端和服务端建立连接后，会话随之建立，生成一个全局唯一的会话ID(Session ID)。服务器和客户端之间维持的是一个长连接，
在SESSION_TIMEOUT时间内，服务器会确定客户端是否正常连接(客户端会定时向服务器发送heart_beat，服务器重置下次SESSION_TIMEOUT时间)。因此，
在正常情况下，Session一直有效，并且ZK集群所有机器上都保存这个Session信息。在出现网络或其它问题情况下（例如客户端所连接的那台ZK机器挂了，
或是其它原因的网络闪断），客户端与当前连接的那台服务器之间连接断了，这个时候客户端会主动在地址列表（实例化ZK对象的时候传入构造方法的那个
参数connectString）中选择新的地址进行连接。
```


