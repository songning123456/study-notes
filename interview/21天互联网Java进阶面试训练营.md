[JAVA核心面试知识整理](/interview/link/JAVA核心面试知识整理.pdf)

#### 第二季

* 你们公司用的Dubbo?那你再额外说说Spring Cloud的核...

* 基于Dubbo和Spring Cloud分别搭建一个电商系统来快速体...

* 你们的系统使用了哪种服务框架?为什么要这样技术...

* 看过Dubbo源码吗?说说Dubbo的底层架构原理?...
    
```
* 简介
    Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合(或者最大限度地松耦合)。
从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方
(Provider)和服务消费方(Consumer)两个角色。

* 是什么
    简单说呢，Dubbo用起来就和EJB、WebService差不多，调用一个远程的服务(或者JavaBean)的时候在本地有一个接口，就像调用本地的方法一样
去调用，它底层帮你实现好你的方法参数传输和远程服务运行结果传回之后的返回，就是RPC的一种封装啦~

* 特点
    (1) 它主要是使用高效的网络框架和序列化框架，让分布式服务之间调用效率更高。
    (2) 采用注册中心管理众多的服务接口地址，当你想调用服务的时候只需要跟注册中心询问即可，不用像使用WebService一样每个服务都得记录好接口
    调用方式。注册中心主要就是负责dubbo的所有服务地址列表维护，并且可以通过在ZooKeeper节点中设置相应的值来实现对这个服务的权重、优先级、
    是否可用、路由、权限等的控制。之后在Dubbo的管理控制台对服务的一堆治理策略设置和调整，实际上就是修改了注册中心中的服务对应的配置数据
    (即修改了zookeeper中服务对应的节点的配置数据)。之后Consumer从注册中心请求到服务的数据时就能根据这些配置数据进行相应的治理配置参数的
    代码执行生效。
    (3) 监控中心实现对服务方和调用方之间运行状态的监控，还能控制服务的优先级、权限、权重、上下线等，让整个庞大的分布式服务系统的维护和治理
    比较方便。
    (4) 高可用有个服务宕机了?注册中心就会从服务列表去掉该节点。还是调用到了?客户端会向注册中心请求另一台可用的服务节点重新调用。注册中心宕
    机?注册中心也能实现高可用(ZooKeeper)。
    (5) 负载均衡：采用软负载均衡算法实现对多个相同服务的节点的请求负载均衡。

* RPC之Dubbo实现
    主要为三点，动态代理、反射、socket网络编程
    (1) 客户端使用动态代理的方式，“假装”实现了createOrder方法。
    (2) 方法相关的数据通过序列化，进入到socket服务器。dubbo的socket实现为Netty。
    (3) 服务端从socket服务器取出数据，通过反射的方式找到“真实”的服务实现。
    (4) 服务端的方法在服务启动时已注入。
    (5) 服务发现层，可用zookeeper。zookeeper保证了CP(一致性，分区容错性)。缺点：master节点挂掉时，需要时间重新选择master，这段时间内注册
    中心将不可用。
    注意：服务端可消费端注册成功后，通讯只走socket服务器，不会经过注册中心。

* 核心技术简介
    (1) 客户端发起接口调用
    (2) 服务中间件进行路由选址：找到具体接口实现的服务地址
    (3) 客户端将请求信息进行编码(序列化: 方法名，接口名，参数，版本号等)
    (4) 建立与服务端的通讯(不是调度中心，而是客户端与服务端直连)
    (5) 服务端将接收到的信息进行反编码(反序列化)
    (6) 根据信息找到服务端的接口实现类
    (7) 将执行结果反馈给客户端

```

* 咱们来聊点深入的,说说Dubbo底层的网络通信机制原...

    <https://blog.csdn.net/Internation985/article/details/103432187>
```
* 基本信息
    (1) 连接个数: 单连接
    (2) 连接方式: 长连接
    (3) 传输协议: TCP
    (4) 传输方式: NIO异步传输
    (5) 序列化: Hessian二进制序列化
    (6) 适用范围： 传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件
        或超大字符串。
    (7) 适用场景: 常规远程服务方法调用
* 同步远程调用
    (1) 客户端线程调用远程接口，向服务端发送请求，同时当前线程应该处于“暂停“状态，即线程不能向后执行了，必需要拿到服务端给自己的结果后
    才能向后执行
    (2) 服务端接到客户端请求后，处理请求，将结果给客户端
    (3) 客户端收到结果，然后当前线程继续往后执行
* 基本原理
    (1) client一个线程调用远程接口，生成一个唯一的ID（比如一段随机字符串，UUID等），Dubbo是使用AtomicLong从0开始累计数字的
    (2) 将打包的方法调用信息（如调用的接口名称，方法名称，参数值列表等），和处理结果的回调对象callback，全部封装在一起，组成一个对象object
    (3) 向专门存放调用信息的全局ConcurrentHashMap里面put(ID, object)
    (4) 将ID和打包的方法调用信息封装成一对象connRequest，使用IoSession.write(connRequest)异步发送出去
    (5) 当前线程再使用callback的get()方法试图获取远程返回的结果，在get()内部，则使用synchronized获取回调对象callback的锁， 再先检
    测是否已经获取到结果，如果没有，然后调用callback的wait()方法，释放callback上的锁，让当前线程处于等待状态。   
    (6) 服务端接收到请求并处理后，将结果（此结果中包含了前面的ID，即回传）发送给客户端，客户端socket连接上专门监听消息的线程收到消息，
    分析结果，取到ID，再从前面的ConcurrentHashMap里面get(ID)，从而找到callback，将方法调用结果设置到callback对象里。
    (7) 监听线程接着使用synchronized获取回调对象callback的锁（因为前面调用过wait()，那个线程已释放callback的锁了），再notifyAll()，
    唤醒前面处于等待状态的线程继续执行（callback的get()方法继续执行就能拿到调用结果了,这里的callback对象是每次调用产生一个新的，不能共享，
    否则会有问题；另外ID必需至少保证在一个Socket连接里面是唯一的。），至此，整个过程结束。

* 当前线程怎么让它“暂停”，等结果回来后，再向后执行？
    答: 先生成一个对象obj，在一个全局map里put(ID,obj)存放起来，再用synchronized获取obj锁，再调用obj.wait()让当前线程处于等待状态，然
后另一消息监听线程等到服务端结果来了后，再map.get(ID)找到obj，再用synchronized获取obj锁，再调用obj.notifyAll()唤醒前面处于等待状态
的线程。
* 正如前面所说，Socket通信是一个全双工的方式，如果有多个线程同时进行远程方法调用，这时建立在client server之间的socket连接上会有很
  多双方发送的消息传递，前后顺序也可能是乱七八糟的，server处理完结果后，将结果消息发送给client，client收到很多消息，怎么知道哪个消息结
  果是原先哪个线程调用的？
    答: 使用一个ID，让其唯一，然后传递给服务端，再服务端又回传回来，这样就知道结果是原先哪个线程的了。

```

* Dubbo框架从架构设计角度,是怎么保证极高的可扩展性...

    <https://blog.csdn.net/maoreyou/article/details/80570230>
```
* Dubbo SPI 特点
    (1) 对Dubbo进行扩展，不需要改动Dubbo的源码
    (2) 自定义的Dubbo的扩展点实现，是一个普通的Java类，Dubbo没有引入任何Dubbo特有的元素，对代码侵入性几乎为零。
    (3) 将扩展注册到Dubbo中，只需要在ClassPath中添加配置文件。使用简单。而且不会对现有代码造成影响。符合开闭原则。
    (4) Dubbo的扩展机制支持IoC,AoP等高级功能
    (5) Dubbo的扩展机制能很好的支持第三方IoC容器，默认支持Spring Bean，可自己扩展来支持其他容器，比如Google的Guice。
    (6) 切换扩展点的实现，只需要在配置文件中修改具体的实现，不需要改代码。使用方便。

```

* 自己独立画出Dubbo的底层架构原理图

    [](/interview/link/Dubbo原理图.jpg)

* 如果让你设计一个RPC框架,网络通信 代理机制 负载...

    <https://blog.csdn.net/u012422829/article/details/78375839?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1>
```
* 什么是RPC
    RPC的全称是Remote Procedure Call，远程过程调用。RPC框架有很多，比如hsf、dubbo等等。借助RPC框架，我们在写业务代码的时候可以不需
要去考虑服务之间的通信等问题，在调用远程服务的时候就像调用本地的方法那么简单。
* 组成部分
    (1) 简化本地调用流程
        既然我们要像调用本地方法那样调用远程服务， 那么就应该生成代理来隐藏调用远程服务的细节。 这些细节包括但不限于以下所列出的关注点。
    (2) 服务发现与服务注册
        (a) 如果我们想在Service A中调用Service B，那么我们首先得知道Service B的地址。 所以，我们需要有一个服务注册中心，通过这个中心，
    服务可以把自己的信息注册进来，也可以获取到别的服务的信息。
        (b) 客户端也需要watch服务注册中心的目标服务的地址的变化。
    (3) 网络通信
        (a) 服务和服务之间的网络通信模型， NIO/IO等等
        (b) 客户端如何复用与服务端的连接， 而不是每次请求都重新创建一个新连接？
        (c) 客户端收到返回后，如何知道是哪个请求的返回并且做出正确处理？
    (4) 消息的序列化
        服务间通信的消息通过什么方式进行序列化？ hessian，XML、JSON、Protobuf、……, 甚至Java原生的序列化方式， 你总得选择一个。
    (5) 负载均衡
        客户端通过服务注册中心拿到一堆地址，该调哪个呢？最简单的方式，可以通过RR、WRR的方式去做LB。
        (a) 根据服务实例的metrics做出动态调整, 比如响应时间等
        (b) 利用一致性哈希， 提高本地缓存利用率
    (6) 容灾
        (a) 康监测： 在某一个服务节点挂掉的时候， 如何在服务注册中心删去这个服务地址？
        (b) 服务调用超时与重试： 在调用一个服务实例的时候，如果超时或者报错，怎么处理？
        (c) 服务限流：如何限制最大并发数？这个又可以从客户端和服务端两个角度分析。
```

* 平时除了使用外,有研究过Spring Cloud的底层架构原理...
    
    <https://blog.csdn.net/niugang0920/article/details/84294365>
    [](/interview/link/SpringCloud架构原理.png)
    
```
* Spring Cloud核心组件
    (1) Eureka
        各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而
    知道其他服务在哪里
    (2) Ribbon
        服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台
    (3) Feign
        基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求
    (4) Hystrix
        发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题
    (5) Zuul
        如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务    
```

* 从底层实现原理的角度,对比一下Dubbo和Spring Cloud的...

    [](/interview/link/Dubbo&SpringCloud.png)
```
* 相同点
    都需要 服务提供方，注册中心，服务消费方
* Dubbo
    (1) Provider: 暴露服务的提供方，可以通过jar或者容器的方式启动服务
    (2) Consumer: 调用远程服务的服务消费方。
    (3) Registry: 服务注册中心和发现中心。
    (4) Monitor: 统计服务和调用次数，调用时间监控中心。(dubbo的控制台页面中可以显示，目前只有一个简单版本)
    (5) Container: 服务运行的容器。
* Spring Cloud
    (1) Service Provider: 暴露服务的提供方。
    (2) Service Consumer: 调用远程服务的服务消费方。
    (3) EureKa Server: 服务注册中心和服务发现中心。
* 比较
    (1) 从核心要素来看
    Spring Cloud 更胜一筹，在开发过程中只要整合Spring Cloud的子项目就可以顺利的完成各种组件的融合，而Dubbo缺需要通过实现各种Filter
来做定制，开发成本以及技术难度略高。Dubbo只是实现了服务治理，而Spring Cloud子项目分别覆盖了微服务架构下的众多部件，而服务治理只是其中
的一个方面。Dubbo提供了各种Filter，对于上述中“无”的要素，可以通过扩展Filter来完善。
    e.g
        (a) 分布式配置：可以使用淘宝的diamond、百度的disconf来实现分布式配置管理
        (b) 服务跟踪：可以使用京东开源的Hydra，或者扩展Filter用Zippin来做服务跟踪
        (c) 批量任务：可以使用当当开源的Elastic-Job、tbschedule
    (2) 从协议上看
    Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况，二进
制的传输，占用带宽会更少。Spring Cloud 使用HTTP协议的REST APIdubbo支持各种通信协议，而且消费方和服务方使用长链接方式交互，http协议
传输，消耗带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大。通信速度上Dubbo略胜Spring Cloud，如果对于系统的响应时间有严
格要求，长链接更合适。
    (3) 从服务依赖方式看
    Dubbo服务依赖略重，需要有完善的版本管理机制，但是程序入侵少。而Spring Cloud通过Json交互，省略了版本管理的问题，但是具体字段含义需
要统一管理，自身Rest API方式交互，为跨平台调用奠定了基础。
    (4) 从组件运行流程看
    Dubbo每个组件都是需要部署在单独的服务器上，gateway用来接受前端请求、聚合服务，并批量调用后台原子服务。每个service层和单独的DB交互。
    SpringCloud所有请求都统一通过 API 网关（Zuul）来访问内部服务。网关接收到请求后，从注册中心（Eureka）获取可用服务。由 Ribbon 进行
均衡负载后，分发到后端的具体实例。微服务之间通过 Feign 进行通信处理业务。业务部署方式相同，都需要前置一个网关来隔绝外部直接调用原子服务
的风险。Dubbo需要自己开发一套API 网关，而Spring Cloud则可以通过Zuul配置即可完成网关定制。使用方式上Spring Cloud略胜一筹。
```

* 自己独立画出Spring Cloud的架构原理图,RPC框架...

* 你们的服务注册中心进行过选型调研吗?对比一...

* 画图阐述一下你们的服务注册中心部署架构,生产环境下怎...

* 你们系统遇到过服务发现过慢的问题吗?怎么优化和解决...

* 说一下自己公司的服务注册中心怎么技术选型的?生...

* 你们对网关的技术选型是怎么考虑的?能对比一下各种网关...

* 说说生产环境下,你们是怎么实现网关对服务的动态路由...

* 如果网关需要抗每秒10万的高并发访问,你应该怎么对网关...

* 你们公司的网关是怎么技术选型的,假设有高并发场...

* 如果需要部署上万服务实例,现有的服务注册中心能否抗...

* 你们是如何基于网关实现灰度发布的?说说你们的灰度发布...

    <https://www.jianshu.com/p/25f194bdb63b>

* 说说你们一个服务从开发到上线, 服务注册 网关路由 服...

* 看看你们公司的服务注册中心能否支撑上万服务实例...

* 画一下你们系统架构的整体架构图?说说各个服务在生产环境怎...

* 你们系统每天有多大的访问量?每个服务高峰QPS多少?压...

* 如果系统访问量比现在增加10倍,你们考虑过系统的扩容...

* 独立画出自己系统的生产环境部署架构图,梳理系统和服务...

* 你们生产环境的服务是怎么配置超时和重试参数的?为什...

* 如果出现服务请求重试,会不会出现类似重复下单的问题?

* 对于核心接口的防重幂等性,你们是怎么设计的?怎么防...

* 看看自己系统的接口有没有设计幂等性方案?如...

* 画一下你们电商系统的核心交易链路图,说说分布式架构下...

* 针对电商核心交易链路,你们是怎么设计分布式事务技术方...

* 对于TCC事务,最终一致性事务的技术选型,你们是怎么做...

* 你们公司的核心链路是否有事务问题?分布式事务方...

* 在搭建的电商系统里,落地开发对交易链路的TCC分布式...

* 你能说说一个TCC分布式事务框架的核心架构原理吗?

* 现有的TCC事务方案的性能瓶颈在哪里?能支撑高并发交易...

* 如果对自己的系统核心链路落地TCC事物,应该如何...

* 你了解RocketMQ对分布式事务支持的底层实现原理吗?...

* 在搭建好的电商系统里,如何基于RocketMQ最终一致性事...

* 如果公司没有RocketMQ中间件,那你们如何实现最终一致性...

* 如果对自己的系统落地最终一致性事务,如何落地实...

* 你们生产系统中有哪个业务场景是需要使用分布式锁的?为什...

* 你们是用哪个开源框架实现的Redis分布式锁?说说其核...

* 如果Redis是集群部署的,那么集群故障时分布式锁还有效...

* 自己梳理出来Redis分布式锁的生产环境问题解决方案！

* 如果要实现Zookeeper分布式锁,一般用哪个开源框架?核...

* 对于ZooKeeper的羊群效应,分布式锁实现应该如何优...

* 如果遇到Zookeeper脑裂问题,分布式锁应该如何保证健壮...

* 自己梳理出来ZooKeeper分布式锁的生产问题...

* 在搭建好的电商系统中,落地开发分布式保证库存数据准...

* 你们的分布式锁做过高并发优化吗?能扛下每秒上万并发...

* 淘宝和京东的库存是怎么实现的?能不能不用分布式锁实现...

* 自己系统的分布式锁在高并发场景下应该如何优化?


#### 第三季

* 为什么在Java面试中一定会深入考察HashMap?

    <https://blog.csdn.net/qq116165600/article/details/103361385>
```
    HashMap作为一个键值对(key-value)的常见集合，在整个java的使用过程中都起着举足轻重的作用。
比如从DB中取值、数据的加工、数据回传给前端、数据转换为json等都可能使用到HashMap；且HashMap
作为一个可以允许空键值对的集合，也能实现自动的扩容，扩容的参数值为0.75，达到后自动扩容一倍，
这样给一些处理未知数据量大小的数据来说，是很方便的。虽然HashMap是线程不安全的，主要体现在
1.7和1.8上。1.7的hashMap在扩容的时候回形成循环链，导致死循环而报错，或者数据的丢失情况，
在1.8上，虽然对这方面做了改进，但是仍然是线程不安全的，主要是体现在，若多线程操作数据，
如线程A  B同时进行数据的put操作，在put操作前，会进行key的hash碰撞，但是线程A  B有可能同时
碰撞且碰撞的值相同，那么就会发生线程A先插入到了碰撞的地方值，然后B也随后插入到同样的地方，导
致线程B会覆盖线程A所插入的值，导致数据丢失。所以，在面试的时候，都很喜欢问HashMap。
```

* 你知道HashMap底层的数据结构是什么吗?

```
    (数组 + 链表 + 红黑树)
    HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫Entry，这些个键值对（Entry）
分散存储在一个数组之中，这个数组就是hashMap的主干，HashMap数组每一个元素的初始值都是null
```

* JDK1.8中对hash算法和寻址算法是如何优化的?

    <https://www.cnblogs.com/Edward-Wang/p/12362922.html>
```
static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
    h = key.hashCode() 表示 h 是 key 对象的 hashCode 返回值；
    h >>> 16 是 h 右移 16 位，因为 int 是 4 字节，32 位，所以右移 16 位后变成：左边 16 个 0 + 
右边原 h 的高 16 位；最后把这两个进行异或返回。
    异或：二进制位运算。如果一样返回 0，不一样则返回 1
    hash算法的优化：对每个hash值，在它的低16位中，让高低16位进行异或，让它的低16位同时保持了高低16
位的特征，尽量避免一些hash值后续出现冲突，大家可能会进入数组的同一位置。
    寻址算法的优化：用与运算替代取模，提升性能。(由于计算机对比取模，与运算会更快)
```

* 你知道HashMap是如何解决hash碰撞问题的吗?

```
    利用“拉链法”处理HashCode的碰撞问题；当我们将键值对传递给put方法时，他调用键对象的hashCode()方法来
计算hashCode，然后找到bucket（哈希桶）位置来存储对象；当用get方法获取对象时，通过键对象的equals()方
法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当碰撞发生了，对象将会存储在链表的
下一个节点中。hashMap在每个链表节点存储键值对对象。当两个不同的键却有相同的hashCode时，他们会存储在同
一个bucket位置的链表中。键对象的equals()来找到键值对。
```

* 说说HashMap是如何进行扩容的可以吗?

```
    jdk1.7扩容是重新计算hash；jdk1.8是要看看原来的hash值新增的那个bit是1还是0好了，如果是0则索引没变，如果
是1则索引变成"原索引+oldCap".这是jdk1.8的亮点，设计的确实非常的巧妙，即省去了重新计算hash值得时间，又均匀
的把之前的冲突的节点分散到新的数组bucket上jdk1.7在rehash的时候，旧链表迁移到新链表的时候，如果在新表的数组
索引位置相同，则链表元素会倒置，但是jdk1.8不会倒置
```

* HashMap默认的初始长度是多少？为什么这么规定？[补充]

```
    HaspMap的默认初始长度是16，并且每次扩展长度或者手动初始化时，长度必须是2的次幂。之所以是16，是为了服务于从Key
值映射到index的hash算法。前面说到了，从Key值映射到数组中所对应的位置需要用到一个hash函数：index = hash("Java");
那么为了实现一个尽量分布均匀的hash函数，利用的是Key值的HashCode来做某种运算。因此问题来了，如何进行计算，才能让这
个hash函数尽量分布均匀呢？一种简单的方法是将Key值的HashCode值与HashMap的长度进行取模运算，即 index = HashCode(Key)
% hashMap.length，但是，但是！这种取模方式运算固然简单，然而它的效率是很低的， 而且，如果使用了取模%， 那么HashMap在
容量变为2倍时， 需要再次rehash确定每个链表元素的位置，浪费了性能。因此为了实现高效的hash函数算法，HashMap的发明者采用
了位运算的方式。那么如何进行位运算呢？可以按照下面的公式：index = HashCode(Key) & (hashMap.length - 1);
```

* 高并发情况下，HashMap会出现死锁吗？[补充]

    <https://coolshell.cn/articles/9606.html>
```
    由于HashMap的容量是有限的，如果HashMap中的数组的容量很小，假如只有2个，那么如果要放进10个keys的话，碰撞就会非常频繁，
此时一个O(1)的查找算法，就变成了链表遍历，性能变成了O(n)，这是Hash表的缺陷。为了解决这个问题,HashMap设计了一个阈值，
其值为容量的0.75，当HashMap所用容量超过了阈值后，就会自动扩充其容量。在多线程的情况下，当重新调整HashMap大小的时候，
就会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在
链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了
避免尾部遍历。如果条件竞争发生了，那么就会产生死循环了。
```

* BAT面试官为什么都喜欢问并发编程的问题?

* 说说synchronized的关键字的底层原理是什么?

* 深入讲解synchronized,CAS的说明[深入到硬件级别]

* 能聊聊你对CAS的理解以及其底层原理可以吗?

    <https://blog.csdn.net/hanjungua8144/article/details/87881987>
```
    CAS会操作3个数字，当前内存中的值，旧的预期值，新的修改值，只有当旧的预期值跟内存中的值一样的时候，才会将内存中的值修改为新的修
改值。举个例子吧，比如int a = 3，这是内存中的当前值，然后你CAS（3, 5），第一个是旧的预期值，如果3和a是一样的，那么就将a修改为5。
其实吧，这里比较关键的一点就是cpu的compareAndSwap操作的原理是啥，以CPU（Intel X86）来举个例子。这块底层指令，会根据当前处理器
类型，来决定要不要对一个cmpxchg指令加lock前缀，如果是单处理器，就不要加，因为自动保证顺序；但是如果是多处理器，就加个lock。intel
对lock的定义，就是说加了lock之后，就会自动锁掉一块内存区域，然后同一时间只有一个处理器可以读写这块内存区域，其他处理器就不行了。

    * CAS其实有3个缺点:

    (1) ABA问题：如果某个值一开始是A，后来变成了B，然后又变成了A，你本来期望的是值如果是第一个A才会设置新值，结果第二个A一比较也ok，
也设置了新值，跟期望是不符合的。所以atomic包里有AtomicStampedReference类，就是会比较两个值的引用是否一致，如果一致，才会设置新值
假设一开始变量i = 1，你先获取这个i的值是1，然后累加了1，变成了2。但是在此期间，别的线程将i -> 1 -> 2 -> 3 -> 1这个期间，这个值是
被人改过的，只不过最后将这个值改成了跟你最早看到的值一样的值。结果你后来去compareAndSet的时候，会发现这个i还是1，就将它设置成了2，
就设置成功了。说实话，用AtomicInteger，常见的是计数，所以说一般是不断累加的，所以ABA问题比较少见
    (2) 无限循环问题：大家看源码就知道Atomic类设置值的时候会进入一个无限循环，只要不成功，就不停循环再次尝试，这个在高并发修改一个值
的时候其实挺常见的，比如你用AtomicInteger在内存里搞一个原子变量，然后高并发下，多线程频繁修改，其实可能会导致这个compareAndSet()里
要循环N次才设置成功，所以还是要考虑到的。
    (3) 多变量原子问题：一般的AtomicInteger，只能保证一个变量的原子性，但是如果多个变量呢？你可以用AtomicReference，这个是封装自定
义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是一个。

```

* ConcurrentHashMap实现线程安全的底层原理到底是什么?

```
    在ConcurrentHashMap没有出现以前，jdk使用hashtable来实现线程安全，但是hashtable是将整个hash表锁住，所以效率很低下。
ConcurrentHashMap将数据分别放到多个Segment中，默认16个，每一个Segment中又包含了多个HashEntry列表数组，对于一个key，
需要经过三次hash操作，才能最终定位这个元素的位置，这三次hash分别为:
    对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)；
    将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment；
    将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。
每一个Segment都拥有一个锁，当进行写操作时，只需要锁定一个Segment，而其它Segment中的数据是可以访问的。
```

* 你对JDK中的AQS理解吗?AQS的实现原理是什么?


* 说说线程池的底层工作原理可以吗?

```
(1) 在创建了线程池后，等待提交过来的任务请求。
(2) 在调用execute（）方法添加一个请求任务时，线程池会做如下判断：
    (a) 如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务；
    (b) 如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列；
    (c) 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务：
    (d) 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize,那么线程池会启动饱和拒绝策略来执行。
(3) 当一个线程完成任务时，它会从队列中去下一个任务来执行。
(4) 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断：
如果当前运行的线程数大于corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后它最终会收缩到corePoolSize的大小。
```

* 那你再说说线程池的核心配置参数都是干什么的?平时我们...

```
    我们创建线程的常见方式一般有继承Thread类以及实现Runnable接口，其实Thread类也是实现了Runnable接口。通过这两种方式创建的线程，
在执行完毕之后都会被销毁，这样频繁的创建和销毁线程是一件很浪费资源到的事情。那么，有没有什么办法解决这个问题呢?通过创建线程池就
可以解决这个问题。通过线程池创建的线程执行完毕之后并不会销毁，而是会回到线程池继续重复利用，执行其他任务。

* 核心参数
    (1) corePoolSize(核心线程数)
        (a) 核心线程会一直存在，即使没有任务执行；
        (b) 当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数；
        (c) 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。
    (2) queueCapacity(任务队列容量)
    也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。
    (3) maxPoolSize(最大线程数)
        (a) 线程池里允许存在的最大线程数量；
        (b) 当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务；
        (c) 线程池里允许存在的最大线程数量。当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务。
    (4) keepAliveTime(线程空闲时间)
        (a) 当线程空闲时间达到keepAliveTime时，线程会退出（关闭），直到线程数等于核心线程数；
        (b) 如果设置了allowCoreThreadTimeout=true，则线程会退出直到线程数等于零。
    (5) allowCoreThreadTimeout(允许核心线程超时)
    (6) rejectedExecutionHandler(任务拒绝处理器)
        (a) 当线程数量达到最大线程数，且任务队列已满时，会拒绝任务；
        (b) 调用线程池shutdown()方法后，会等待执行完线程池的任务之后，再shutdown()。如果在调用了shutdown()方法和线程池真正shutdown()之间提交任务，会拒绝新任务。

* 线程池参数默认值
    corePoolSize = 1
    queueCapacity = Integer.MAX_VALUE
    maxPoolSize = Integer.MAX_VALUE
    keepAliveTime = 60秒
    allowCoreThreadTimeout = false
    rejectedExecutionHandler = AbortPolicy()

* ThreadPoolExecutor(线程池)执行顺序
    当线程数小于核心线程数时，会一直创建线程直到线程数等于核心线程数；
    当线程数等于核心线程数时，新加入的任务会被放到任务队列等待执行；
    当任务队列已满，又有新的任务时，会创建线程直到线程数量等于最大线程数；
    当线程数等于最大线程数，且任务队列已满时，新加入任务会被拒绝。
```

* 如果在线程中使用无界阻塞队列会发生什么问题?

```
    因为调用异常，会调用超时，线程处理任务时间是超时时间，线程池等待队列，会变得越来越大，
此时会导致内存飙升起来，而且还可能导致OOM，内存溢出或者频繁的GC.
```

* 你知道如果线程池的队列满了之后,会发生什么事情吗?

```
* 使用线程池的好处
    (1) 降低资源消耗 —— 可以重复利用已创建的线程降低线程创建和销毁造成的消耗。
    (2) 提高响应速度 —— 当任务到达时，任务可以不需要等到线程创建就能立即执行。
    (3) 提高线程的可管理性 —— 线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控

* 线程池的工作原理
    (1) 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则执行第二步。
    (2) 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里进行等待。如果工作队列满了，则执行第三步
    (3) 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务

* 线程池饱和策略
    (1) AbortPolicy
    为Java线程池默认的阻塞策略，不执行此任务，而且直接抛出一个运行时异常，切记ThreadPoolExecutor.execute需要try catch，否则程序会直接退出。
    (2) DiscardPolicy
    直接抛弃，任务不执行，空方法。
    (3) DiscardOldestPolicy
    从队列里面抛弃head的一个任务，并再次execute 此task。
    (4) CallerRunsPolicy
    在调用execute的线程里面执行此command，会阻塞入口。
    (5) 用户自定义拒绝策略（最常用）
    实现RejectedExecutionHandler，并自己定义策略模式。

如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。
如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。
如果无法将任务加入BlockingQueue（队列已满），则在非corePool中创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。
如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。
ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。
```

* 如果线上机器突然宕机,线程池的阻塞队列中的请求怎么...

```
机器宕机，必然会导致线程池里的积压的任务丢失

如何解决？

    在提交一个任务到线程池里去，提交之前，将这个任务信息持久化到数据库里，此时的状态为 未提交，提交成功之后，更新任务信息的状态为 
提交成功，当任务完成的时候，更新任务信息的状态为 已完成当宕机的机器重启的时候，可以开启一个后台线程，扫描数据库里 未提交和已提交
的任务，可以把任务读取出来，重新提交到线程池中，继续进行执行，被调用的方法一定做好幂等操作，防止请求重复执行。
```

* 谈谈你对Java内存模型的理解可以吗?

* 你知道Java内存模型中的原子性,有序性,可见性是什么...

```
* 可见性:是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的，也就是一个线程修改的结果。另一个线程马上就能看到
    如：用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其
他线程是可见的volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。在 Java 中 volatile、synchronized 和 
final 实现可见性

* 原子性:原子是世界上的最小单位，具有不可分割性
    在 Java 中 synchronized 和在 lock、unlock 中操作保证原子性。

* 有序性:Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性
    volatile 是因为其本身包含“禁止指令重排序”的语义，synchronized 是由“一个变量在同一个时刻只允许一条线程对其进行 lock
操作”这条规则获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。

volatile关键字用法
public class Counter { 
    public volatile static int count = 0; 
    public static void inc() { 
        //这里延迟1毫秒，使得结果明显 
        try { 
            Thread.sleep(1); 
        } catch (InterruptedException e) { 
        } 
        count++; 
    } 
    public static void main(String[] args) { 
        //同时启动1000个线程，去进行i++计算，看看实际结果 
        for (int i = 0; i < 1000; i++) { 
            new Thread(new Runnable() { 
                @Override
                public void run() { 
                    Counter.inc(); 
                } 
            }).start(); 
        } 
        //这里每次运行的值都有可能不同,可能为1000 
        System.out.println("运行结果:Counter.count=" + Counter.count); 
    } 
}

由于volatile具有可见性，在不并发的情况下是1000，实际输出只有994，由于并发原因
```

* 能聊聊volatile关键字的原理吗?

```
(1) 禁止指令重排序
(2) 内存可见性
```

* 深入讲解volatile关键字的说明[深入到硬件级别]

* 你知道指令重排以及happens-before原则是什么吗?

```
* 指令重排
    (1) 定义:
    Java 语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序
化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重
排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器
指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。
    (2) 背景:
    我们知道现代CPU的主频越来越高，与cache的交互次数也越来越多。当CPU的计算速度远远超过访问cache时，
会产生cache wait，过多的cache wait就会造成性能瓶颈。针对这种情况，多数架构（包括X86）采用了一种将
cache分片的解决方案，即将一块cache划分成互不关联地多个 slots (逻辑存储单元，又名 Memory Bank 或 
Cache Bank)，CPU可以自行选择在多个 idle bank 中进行存取。这种 SMP 的设计，显著提高了CPU的并行处
理能力，也回避了cache访问瓶颈。
    一般 Memory bank 是按cache address来划分的。比如 偶数adress 0×12345000 分到 bank 0, 奇数address 0×12345100 分到 bank1
    (3) 种类:
    (a) 编译期重排。编译源代码时，编译器依据对上下文的分析，对指令进行重排序，以之更适合于CPU的并行执行。
    (b) 运行期重排，CPU在执行过程中，动态分析依赖部件的效能，对指令做重排序优化。
    
* happens-before原则
    (1) 定义:
    Java存储模型有一个happens-before原则，就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程里面执行），
那么A/B就需要满足happens-before关系。
    (2) 要求:
    (a) 同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。
    (b) 对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。
    (c) 对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。
    (d) Thread.start()的调用会happens-before于启动线程里面的动作。
    (e) Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。
    (f) 一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。
    (g) 一个对象构造函数的结束happens-before与该对象的finalizer的开始
    (h) 如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。
    (3) 理解:
    happens-before规则是用来判断一个动作对另一个动作是否可见的法则，它只是用来判断可见性的，而不是决定执行顺序的，就是说动作A
和动作B 的执行顺序是可以通过指令重排发生变化的，而如果你要保证A和B的可见性关系，就必须采用其他控制手段（比如volatile修饰属性）
来保证AB的执行顺序不被打乱，这样就能用happens-before规则来判断AB两个动作的可见性。
```

* volatile底层是如何基于内存屏障保证可见性和有序性的?

* 说说你对Spring的IOC机制的理解可以吗?

```
    在平时的java应用开发中，我们要实现某一个功能或者说是完成某个业务逻辑时至少需要两个或以上的对象来协作完成，在没有使用Spring
的时候，每个对象在需要使用他的合作对象时，自己均要使用像new object() 这样的语法来将合作对象创建出来，这个合作对象是由自己主动创
建出来的，创建合作对象的主动权在自己手上，自己需要哪个合作对象，就主动去创建，创建合作对象的主动权和创建时机是由自己把控的，而这
样就会使得对象间的耦合度高了，A对象需要使用合作对象B来共同完成一件事，A要使用B，那么A就对B产生了依赖，也就是A和B之间存在一种耦
合关系，并且是紧密耦合在一起，而使用了Spring之后就不一样了，创建合作对象B的工作是由Spring来做的，Spring创建好B对象，然后存储到
一个容器里面，当A对象需要使用B对象时，Spring就从存放对象的那个容器里面取出A要使用的那个B对象，然后交给A对象使用，至于Spring是如
何创建那个对象，以及什么时候创建好对象的，A对象不需要关心这些细节问题(你是什么时候生的，怎么生出来的我可不关心，能帮我干活就行)，
A得到Spring给我们的对象之后，两个人一起协作完成要完成的工作即可。所以控制反转IoC(Inversion of Control)是说创建对象的控制权进行
转移，以前创建对象的主动权和创建时机是由自己把控的，而现在这种权力转移到第三方，比如转移交给了IoC容器，它就是一个专门用来创建对象
的工厂，你要什么对象，它就给你什么对象，有了 IoC容器，依赖关系就变了，原先的依赖关系就没了，它们都依赖IoC容器了，通过IoC容器来建
立它们之间的关系。
```

* 说说你对Spring的AOP机制的理解可以吗?

```
    AOP（Aspect Orient Programming），一般称为面向切面编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务
管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态
代理则以Spring AOP为代表。静态代理是编译期实现，动态代理是运行期实现，可想而知前者拥有更好的性能。
    静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对
象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。
    Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个
接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB
(Code Generation Library)，是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某
个类被标记为final，那么它是无法使用CGLIB做动态代理的，诸如private的方法也是不可以作为切面的。
```

* 了解过cglib动态代理吗?他和jdk动态代理的区别什么?

```
* jdk动态代理
    需要有顶层接口才能使用，但是在只有顶层接口的时候也可以使用，常见是mybatis的mapper文件是代理。使用反射完成。使用了动态生成字节码技术。
* cglib动态代理
    可以直接代理类，使用字节码技术，不能对 final 类进行继承。使用了动态生成字节码技术。
```

* 能说说Spring中的Bean是线程安全的吗?

```
* singleton
    单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例
* prototype
    原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例
* request
    对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作用域才有效
* session
    对于每次HTTP Session，使用session定义的Bean豆浆产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效
* globalsession
    每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中使用Spring时，
该作用域才有效

    其中比较常用的是singleton和prototype两种作用域。对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护
Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring
容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。如果不指定Bean的作用域，Spring默认使用singleton作用域。
Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。
而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。

    spring 管理的 bean 的线程安全跟 bean 的创建作用域和 bean 所在的使用环境是否存在竞态条件有关，spring 并不能保证 bean 的线程安全。

```

* Spring的事务实现原理是什么?能聊聊你对事物传播机制的...

    <https://blog.csdn.net/qq_26323323/article/details/81908955>
```
* @Transactional(propagation=Propagation.REQUIRED) (默认)
    如果有事务则加入事务，如果没有事务，则创建一个新的(默认值)
* @Transactional(propagation=Propagation.NOT_SUPPORTED)
    Spring不为当前方法开启事务，相当于没有事务,每条执行语句单独执行，单独提交
* @Transactional(propagation=Propagation.REQUIRES_NEW)
    不管是否存在事务，都创建一个新的事务，原来的方法挂起，新的方法执行完毕后，继续执行老的事务
* @Transactional(propagation=Propagation.MANDATORY)
    MANDATORY必须在已有事务下被调用，否则报错;NOT_SUPPORTED执行数据库层面的事务操作，故当前测试中，insert方法成功执行，delete方法的抛错并不影响insert方法的执行
* @Transactional(propagation=Propagation.SUPPORTS)
    SUPPORTS类型的事务传播机制，是否使用事务取决于调用方法是否有事务，如果有则直接用，如果没有则不使用事务
* @Transactional(propagation=Propagation.NESTED)
    如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与REQUIRED类似的操作
```

* 能画一张图说说Spring Boot的核心架构吗?

```
(1) 独立运行Spring项目
    Spring boot 可以以jar包形式独立运行，运行一个Spring Boot项目只需要通过java -jar xx.jar来运行。
(2) 内嵌servlet容器
    Spring Boot可以选择内嵌Tomcat、jetty或者Undertow,这样我们无须以war包形式部署项目。
(3) 提供starter简化Maven配置
    spring提供了一系列的start pom来简化Maven的依赖加载，例如，当你使用了spring-boot-starter-web，会自动加入依赖包。
(4) 自动装配Spring 
    SpringBoot会根据在类路径中的jar包，类、为jar包里面的类自动配置Bean，这样会极大地减少我们要使用的配置。当然，SpringBoot只考虑大多数的开发场景，
并不是所有的场景，若在实际开发中我们需要配置Bean，而SpringBoot灭有提供支持，则可以自定义自动配置。
(5) 准生产的应用监控
    SpringBoot提供基于http ssh telnet对运行时的项目进行监控。
(6) 无代码生产和xml配置
    SpringBoot不是借助与代码生成来实现的，而是通过条件注解来实现的，这是Spring4.x提供的新特性。
```

* 能画一张图说说Spring的核心架构吗?

```
(1) 实例化bean
(2) 设置对象属性(依赖注入)
(3) 处理Aware接口
(4) BeanPostProcessor
(5) InitalizingBean与init-method
(6) BeanPostProcessor
(7) DisposableBean
(8) destroy-method
```

* 能说说Spring中都使用了哪些设计模式吗?

* 能画一张图说说Spring Web MVC的核心架构吗?

* 能画一张图说说Spring Cloud的核心架构吗?

* JVM中有哪几块内存区域?Java8之后对内存做了什么...

```
* 物理内存Metaspace(除jvm占用的内存,剩余的内存空间都可以被Metaspace占用)
* 方法区(常量,即时编译后的代码)
* 年轻代(eden space, from survivor, to survivor)
* 老年代
* 程序计数器PC
* 虚拟机栈(局部变量表, 操作数栈, 方法返回地址, 动态链接, 额外附加信息)
* 本地方法栈

```

* 你知道JVM是如何运行起来的吗?我们的对象是如何分配...

* 说说JVM在哪些情况下会触发垃圾回收可以吗?

```
(1) 对象没有引用
(2) 作用域发生未捕获异常
(3) 程序在作用域正常执行完毕
(4) 程序执行了System.exit()
(5) 程序发生意外终止(被杀进程等)
```

* 说说JVM的年轻代垃圾回收算法?对象什么时候转移到老年...

* 说说老年代的垃圾回收算法?常用的垃圾回收器都有什...

* 你们生产环境中的Tomcat是如何设置JVM参数的?如何检查...

* 你在实际项目中是否做过JVM GC优化,怎么做的?

* 你知道发生OOM之后,应该如何排查和处理线上系统的OO...

```
* 年老代堆空间被占满
    异常: java.lang.OutOfMemoryError：java  heap space
    说明: 这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机再也无法分配新空间
    解决: 这种方式解决起来比较简单，一般就是根据垃圾回收前后的情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。

* 持久代被占满
    异常: java.lang.OutOfMemoryError：PermGen space
    说明: Perm 空间被占满，无法为新的 class 分配存储空间而引发的异常。这个异常以前是没有的，但是在 java 大量使用反射的今天这个异常就比较常见了。
主要原因是大量动态反射生成的类不断被加载，最终导致 Perm 区被占满。更可怕的是，不同的 classLoader 即便使用相同的类，但是都会对其进行加载，相当于
同一个东西，如果有 N 个classLoader 那么它将会被加载 N 次。因此，在某些情况下，这个问题基本视为无解，当然，存在大量 classLoader 和大量反射类的情
况并不多
    解决: 增加持久代内存 ，例如：-XX：MaxPermSize=16M
```

* 你能聊聊TCP/IP四种网络模型吗?OSI七层网络模型也说一下...

    <https://blog.csdn.net/qq_22343483/article/details/104165180>

* 浏览器请求www.baidu.com的全过程大概是怎样的?...

```
    同上
```

* 画一下TCP三次握手流程图?为啥是三次而不是二次或者...

* 聊聊HTTP协议的工作原理!

* 聊聊HTTPS的工作原理?为啥用HTTPS就可以加密通信?

* 聊聊http的长连接的工作原理到底是啥?

    <https://www.cnblogs.com/fyql/p/12272918.html>
```
    http本身没什么所谓的长连接短连接之说，其实说白了都是http下层的tcp连接是长连接还是短连接，tcp连接保持长连接，那么多个http请求和
响应都可以通过一个链接来走。其实http 1.1之后，默认都是走长连接了，就是底层都是一个网页一个tcp连接，一个网页的所有图片、css、js的资源
加载，都走底层一个tcp连接，来多次http请求即可。http 1.0的时候，底层的tcp是短连接，一个网页发起的请求，每个请求都是先tcp三次握手，然
后发送请求，获取响应，然后tcp四次挥手断开连接；每个请求，都会先连接再断开。短连接，建立连接之后，发送个请求，直接连接就给断开了。http 1.1，
tcp长连接，tcp三次握手，建立了连接，无论有多少次请求都是走一个tcp连接的，走了n多次请求之后，然后tcp连接被释放掉了。
```

* MYSQL,MyISAM和InnoDB存储引擎的区别是啥?

* 聊聊MySQL的索引实现原理?各种索引你们平时都怎么用...

* 你能说说事务的几个特性是啥?有哪几种隔离级别?

* 你能说说MySQL数据库锁的实现原理吗?如果死锁了咋办?

* MySQL的SQL调优一般都有哪些手段?你们一般怎么做?

    <https://blog.csdn.net/zhangbijun1230/article/details/81608252>

* 聊聊Socket的工作原理?Socket和TCP IP之间是啥关系?

    <https://blog.csdn.net/klp098/article/details/51182721>

* 进程之间是如何通信的?线程间又如何切换的?

* 你能聊聊BIO,NIO,AIO分别都是啥?有什么区别?

    <https://www.cnblogs.com/blackjoyful/p/11534985.html>

* 线上服务CPU100%了!该怎么排查,定位和解决?

    <https://blog.csdn.net/weixin_38827340/article/details/85311247>

* 线上机器的一个进程用kill命令杀不死该怎么办?磁盘空间快...

* 关于后续深入硬件级讲解volatile,synchronized,CAS底...

* 再谈原子性: Java规范规定所有变量写操作都是原子的

* 32位Java虚拟机中的long和double变量写操作为何不是原子...

* volatile原来还可以保证long和double变量写操作的原子性

* 到底有哪些操作在Java规范中是不保证原子性的呢?

* 可见性涉及的底层硬件概念: 寄存器,高速缓存,写缓存...

* 深入探秘有序性: Java程序运行过程中发生指令重排的几个...

* JIT编译器对创建对象的指令重排以及double check单例实践

* 现代处理器为了提升性能的指令乱序和猜测执行的机制!

* 高速缓存和写缓存器的内存重排造成的视觉假象

* synchronized锁同时对原子性,可见性，以及有序性的保证

* 深入分析synchronized是如何通过加锁保证原子性的?

* synchronized是如何使用内存屏障保证可见性和有序性的?

* 再看volatile关键字对原子性,可见性以及有序性的保证

* 高速缓存的数据结构: 拉链散列表,缓存条目以及地址解码...

* 结合硬件级别的缓存数据结构深入分析缓存一致性协议...

* 采用写缓冲器和无效队列优化MESI协议的实现性能

* 硬件层面的MESI协议会如何引发有序性和可见性的问题?

* 内存屏障在硬件层面的实现原理以及如何解决各种问题

* 在复杂的硬件模型之上的Java内存模型是如何大幅简化...

* 面试的时候是如何从内存屏障,硬件层面的原理来震慑面试...

* Java虚拟机对锁的优化: 锁消除,锁粗化,偏向锁,自旋锁...

* 再来看看CAS是如何基于MESI协议在底层硬件层面实现...

* 能不能说说一般黑客常用的XSS网络攻击的原理是什么?

* 能不能说说我们经常听到的SQL注入攻击背后的原理是什...

* 听说过CSRF攻击吗?你知道他背后的原理是什么吗?

* 如果你们的系统允许用户上传文件,可能会遭到什么样的黑...

* 让所有工程师闻风色变的DDoS攻击到底是什么东西?

```
    DDoS(英文Distributed Denial of Service，即分布式拒绝服务)，这是一种网络攻击方式，主要目的是以分布式攻击来让指定目标无法提供正
常服务，甚至从互联网上消失。说白了就是一定时间内增大访问量，使其无法正常提供服务。看过最形象也最好笑的比喻是，春运抢火车票导致12306网
站瘫痪，就是DDOS攻击。DDOS只不过是一个概称，其下有各种攻击方式，比如“CC攻击、SYN攻击、NTP攻击、TCP攻击、DNS攻击等等”
    攻击者利用大量“肉鸡”对攻击目标发动大量的正常或非正常请求、耗尽目标主机资源或网络资源，从而使被攻击的主机不能为合法用户提供服务。大
家应该还听过DoS攻击。DoS（拒绝服务，Denial of Service）就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。
这是早期非常基本的网络攻击方式。
```

* 基于SYN Flood模式的DDoS攻击,背后的原理是什么呢?

* 再来看看基于DNS Query Flood和HTTP Flood的DDoS攻击

* 在分布式架构中, Zuul网关是如何防止网络攻击的?

* 一个对技术有追求的面试官,是怎么深挖网络与IO的面试...

* Netty的架构原理图能画一下吗,他是如何体现Reactor架...

* 能说说你对堆外内存的理解吗?堆外内存的优势在哪里?

* JDK是如何对堆外内存进行分配和回收的?会发生堆外内存...

* 如何不使用零拷贝技术,普通的IO操作在OS层面是如何执...

* 听说过mmap吗?内存映射技术为什么可以提升IO性能?

* 零拷贝技术到底是什么,他是如何提升IO性能的?

* 你们的分布式系统是如何进行链路监控的?都监控什么?

* 对分布式系统进行核心链路追踪的时候,链路id是怎么管理...

* 聊过两阶段提交了,那么分布式事务三阶段提交的思想能说...

* 唯一id生成机制中的snowflake算法的时钟回拨问题...

* 实现灰度发布的时候,网关是可以灰度了,可是Dubbo服务...

```
* 定义
    灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，
一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，
在初始灰度的时候就可以发现、调整问题，以保证其影响度。
```

* 除了常见服务注册中心之外,你觉得Redis能作为服务注...

```
    redis 作为dubbo的注册中心，实现的功能跟 zk相同，但是内部的实现机制大相径庭，因为zk 有临时节点，服务端在zk 中创建临时节点会一直
保持连接，如果服务器出现崩溃，自动断连，而redis 则要考主服务器 进行定时轮询
```

* 我们一般到底用Zookeeper来干什么事儿?

* 有哪些开源的分布式系统中使用了Zookeeper?

```
    Hadoop、HBase、Kafka
```

* 为什么我们在分布式系统架构中需要使用Zookeeper集群?

* Zookeeper为了满足分布式系统的需求要有哪些特点?

```
* 构造高可用集群
    zookeeper的选举模式保证了集群的相对稳定性，从而使得集群是高可用的。

* 集群全局配置文件管理
    即统一资源配置，在一个偌大的集群环境中，假设你需要对该集群的配置文件作修改，假设集群很庞大，手动去修改是一件不太现实的事，不但费
时费力，还极有可能造成差错，zookeeper可以自动帮我们完成配置文件的分发，既高效又准确。

* 发布与订阅
     支持服务发布与状态监听。

* 分布式锁
    在集群环境下，同样会存在对资源的竞争，zookeeper提供了分布式锁实现了同步。

* 保证数据强一致性
    在集群环境下，对集群中某个节点的数据的改变，会被zookeeper同步到其他机器上。

* 额外补充
    cversion: 子节点版本号 
    ephemeralOwner: 用于判断节点是持久的还是临时的
```

* 为了满足分布式系统的需求,Zookeeper的架构设计有哪...

* Zookeeper集群的三种角色: Leader,Follower,...

* 客户端与Zookeeper之间的长连接和会话是什么?

    <https://blog.csdn.net/zhangjikuan/article/details/72059124>


