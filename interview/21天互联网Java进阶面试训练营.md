#### 谈谈你对Java内存模型的理解可以吗?

*** Java内存模型8个指令: lock、unlock、read、load、use、assign、store、write两个线程同时执行data++;操作时，Java内存工作流程:...

#### 你知道Java内存模型中的原子性,有序性,可见性是什么?

* 可见性:是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的，也就是一个线程修改的结果。另一个线程马上就能看到。线程1操作i++
后，强制线程2操作i时，必须从主内存中刷新更新后的i的值。
    e.g: 用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其
他线程是可见的volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。在 Java 中 volatile、synchronized 和 
final 实现可见性

* 原子性:原子是世界上的最小单位，具有不可分割性
    在 Java 中 synchronized 和在 lock、unlock 中操作保证原子性。线程1对i++时，线程2不能对i++同时进行。同时刻只有一个线程对一个值
进行操作。i++必须独立执行，但默认时线程不安全的。

* 有序性:Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性
    volatile 是因为其本身包含“禁止指令重排序”的语义，synchronized 是由“一个变量在同一个时刻只允许一条线程对其进行 lock操作”这条规则
获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。对于代码，还有一个问题时指令重排序，编译器和指令器，有时候为了提高代码执行
效率，会将指令重排序。具备有序性，不会发生指令重排导致代码异常；不具有有序性，会发生指令重排，导致代码可能会出现一些问题。

volatile关键字用法
```
public class Counter { 
    public volatile static int count = 0; 
    public static void inc() { 
        //这里延迟1毫秒，使得结果明显 
        try { 
            Thread.sleep(1); 
        } catch (InterruptedException e) { 
        } 
        count++; 
    } 
    public static void main(String[] args) { 
        //同时启动1000个线程，去进行i++计算，看看实际结果 
        for (int i = 0; i < 1000; i++) { 
            new Thread(new Runnable() { 
                @Override
                public void run() { 
                    Counter.inc(); 
                } 
            }).start(); 
        } 
        //这里每次运行的值都有可能不同,可能为1000 
        System.out.println("运行结果:Counter.count=" + Counter.count); 
    } 
}
```
由于volatile具有可见性，在不并发的情况下是1000，实际输出只有994，由于并发原因

#### 能能从Java底层角度聊聊volatile关键字的原理吗?

*** volatile用来解决可见性和有序性，在有些罕见条件下，可以有限保证原则性，但主要不是保证原则性的。讲volatile要从内存模型开始讲起，还有原
子性，可见性，有序性。使其他工作线程内存中的值缓存失效，强制从主内存中读取新值，即可见性。在很多开源中间件系统源码里都有多线程并发，大
量使用volatile关键字。


#### 深入讲解volatile关键字的说明[深入到硬件级别]

#### 你知道指令重排以及happens-before原则是什么吗?

* 指令重排
    (1) 定义:
    Java 语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序
化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重
排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器
指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。
    (2) 背景:
    我们知道现代CPU的主频越来越高，与cache的交互次数也越来越多。当CPU的计算速度远远超过访问cache时，
会产生cache wait，过多的cache wait就会造成性能瓶颈。针对这种情况，多数架构（包括X86）采用了一种将
cache分片的解决方案，即将一块cache划分成互不关联地多个 slots (逻辑存储单元，又名 Memory Bank 或 
Cache Bank)，CPU可以自行选择在多个 idle bank 中进行存取。这种 SMP 的设计，显著提高了CPU的并行处
理能力，也回避了cache访问瓶颈。
    一般 Memory bank 是按cache address来划分的。比如 偶数adress 0×12345000 分到 bank 0, 奇数address 0×12345100 分到 bank1
    (3) 种类:
    (a) 编译期重排。编译源代码时，编译器依据对上下文的分析，对指令进行重排序，以之更适合于CPU的并行执行。
    (b) 运行期重排，CPU在执行过程中，动态分析依赖部件的效能，对指令做重排序优化。
    
* happens-before原则
    (1) 定义:
    Java存储模型有一个happens-before原则，就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程里面执行），
那么A/B就需要满足happens-before关系。
    (2) 要求:
    (a) 同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。
    (b) 对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。
    (c) 对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。
    (d) Thread.start()的调用会happens-before于启动线程里面的动作。
    (e) Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。
    (f) 一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。
    (g) 一个对象构造函数的结束happens-before与该对象的finalizer的开始
    (h) 如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。
    (3) 理解:
    happens-before规则是用来判断一个动作对另一个动作是否可见的法则，它只是用来判断可见性的，而不是决定执行顺序的，就是说动作A
和动作B 的执行顺序是可以通过指令重排发生变化的，而如果你要保证A和B的可见性关系，就必须采用其他控制手段（比如volatile修饰属性）
来保证AB的执行顺序不被打乱，这样就能用happens-before规则来判断AB两个动作的可见性。

#### volatile底层是如何基于内存屏障保证可见性和有序性的?

#### 说说你对Spring的IOC机制的理解可以吗?

* 没有Spring之前
    写一套系统，web服务器，tomcat，一旦启动之后，他就可以监听一个端口号的http请求，然后可以把请求转交给你的servlet，jsp，配合起来使用
的，servlet处理请求。比如在我们的一个tomcat + servlet的这样的一个系统里，有几十个地方，都是直接用MyService myService = new MyServiceImpl()，
直接创建、引用和依赖了一个MyServiceImpl这样的一个类的对象。这个系统里，有几十个地方，都跟MyServiceImpl类直接耦合在一起了。如果我现在不想要
用MyServiceImpl了，我们希望用的是NewServiceManagerImpl，implements MyService这个接口的，所有的实现逻辑都不同了，此时我们很麻烦，我们需要
在系统里，几十个地方，都去修改对应的MyServiceImpl这个类，切换为NewServiceManagerImpl这个类。改动代码成本很大，改动完以后的测试的成本很大，
改动的过程中可能很复杂，出现一些bug，此时就会很痛苦。归根结底，代码里，各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，
重新测试，可能还会有bug。

* 有Spring之后
    Spring IoC, Spring容器，根据XML配置或注解，去实例化你的一些bean对象，然后根据XML或注解，去对bean对象之间的引用关系，去进行依赖注入。
底层核心技术是反射。通过反射技术，直接根据你的类去自己构建对应的对象出来。

#### 说说你对Spring的AOP机制的理解可以吗?

*** AOP（Aspect Orient Programming），一般称为面向切面编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务
管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态
代理则以Spring AOP为代表。静态代理是编译期实现，动态代理是运行期实现，可想而知前者拥有更好的性能。
    静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对
象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。
    Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个
接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB
(Code Generation Library)，是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某
个类被标记为final，那么它是无法使用CGLIB做动态代理的，诸如private的方法也是不可以作为切面的。

#### 了解过cglib动态代理吗?他和jdk动态代理的区别什么?

* jdk动态代理
    需要有顶层接口才能使用，但是在只有顶层接口的时候也可以使用，常见是mybatis的mapper文件是代理。使用反射完成。使用了动态生成字节码技术。
* cglib动态代理
    可以直接代理类，使用字节码技术，不能对 final 类进行继承。使用了动态生成字节码技术。

    动态代理就是动态的创建一个代理类出来，创建这个代理类的实例对象，在这个里面引用你真正自己写的类，所有的方法的调用，都是先走代理类的对
象，他负责做一些代码上的增强，再去调用你写的那个类。Spring里使用aop，比如说你对一批类和他们的方法做了一个切面，定义好了要在这些类的方法
里增强的代码，Spring必然要对那些类生成动态代理，在动态代理中去执行你定义的一些增强代码。如果你的类是实现了某个接口的，spring aop会使用
jdk动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，jdk动态代理，他其实是在你的类有接口的时候，就会来使用。很多时候
我们可能某个类是没有实现接口的，spring aop会改用cglib来生成动态代理，他是生成你的类的一个子类，他可以动态生成字节码，覆盖你的一些方法，
在方法里加入增强的代码。

#### 能说说Spring中的Bean是线程安全的吗?

* singleton(默认)
    单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例。
* prototype
    原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例，一般来说下面几种作用域，在开发的时候一般都
不会用，99.99%的时候都是用singleton单例作用域。
* request
    对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作
用域才有效，在请求完成以后，bean会失效并被垃圾回收器回收。
* session
    对于每次HTTP Session，使用session定义的Bean豆浆产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效，在session过期后，
bean会随之失效。
* globalsession
    每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中
使用Spring时，该作用域才有效。

    其中比较常用的是singleton和prototype两种作用域。对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护
Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring
容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。如果不指定Bean的作用域，Spring默认使用singleton作用域。
Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。
而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。

    spring 管理的 bean 的线程安全跟 bean 的创建作用域和 bean 所在的使用环境是否存在竞态条件有关，spring 并不能保证 bean 的线程安全。

#### Spring的事务实现原理是什么?能聊聊你对事物传播机制的...

[测试用例]<https://blog.csdn.net/qq_26323323/article/details/81908955>
* 实现原理
    加一个@Transactional注解，Spring会使用AOP，对这个方法在执行前，先开启事务，在执行完毕后，根据方法是否报错，来决定是回滚还是提交事务。
* 传播机制
    (1) @Transactional(propagation=Propagation.REQUIRED) (默认)
        如果有事务则加入事务，如果没有事务，则创建一个新的(默认值)
    (2) @Transactional(propagation=Propagation.NOT_SUPPORTED)
        Spring不为当前方法开启事务，相当于没有事务,每条执行语句单独执行，单独提交
    (3) @Transactional(propagation=Propagation.REQUIRES_NEW)
        不管是否存在事务，都创建一个新的事务，原来的方法挂起，新的方法执行完毕后，继续执行老的事务
    (4) @Transactional(propagation=Propagation.MANDATORY)
        MANDATORY必须在已有事务下被调用，否则报错;NOT_SUPPORTED执行数据库层面的事务操作，故当前测试中，insert方法成功执行，delete方
    法的抛错并不影响insert方法的执行
    (5) @Transactional(propagation=Propagation.SUPPORTS)
        SUPPORTS类型的事务传播机制，是否使用事务取决于调用方法是否有事务，如果有则直接用，如果没有则不使用事务
    (6) @Transactional(propagation=Propagation.NESTED)
        如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与REQUIRED类似的操作

#### 能画一张图说说Spring Boot的核心架构吗?

[](/interview/link/SpringBoot的核心架构.png)
(1) 独立运行Spring项目
    Spring boot 可以以jar包形式独立运行，运行一个Spring Boot项目只需要通过java -jar xx.jar来运行。
(2) 内嵌servlet容器
    Spring Boot可以选择内嵌Tomcat、jetty或者Undertow,这样我们无须以war包形式部署项目。
(3) 提供starter简化Maven配置
    spring提供了一系列的start pom来简化Maven的依赖加载，例如，当你使用了spring-boot-starter-web，会自动加入依赖包。
(4) 自动装配Spring 
    SpringBoot会根据在类路径中的jar包，类、为jar包里面的类自动配置Bean，这样会极大地减少我们要使用的配置。当然，SpringBoot只考虑大多数的开发场景，
并不是所有的场景，若在实际开发中我们需要配置Bean，而SpringBoot灭有提供支持，则可以自定义自动配置。
(5) 准生产的应用监控
    SpringBoot提供基于http ssh telnet对运行时的项目进行监控。
(6) 无代码生产和xml配置
    SpringBoot不是借助与代码生成来实现的，而是通过条件注解来实现的，这是Spring4.x提供的新特性。

#### 能画一张图说说Spring的核心架构吗?

* Spring生命周期: 创建 -> 使用 -> 销毁
* 用xml或注解，定义一堆bean
* 流程
    (1) 实例化bean
        通过反射创建bean对象实例。
    (2) 设置对象属性(依赖注入)
        实例化后的对象被封装在BeanWrapper对象中，Spring根据BeanDefinition中的信息以及通过BeanWrapper提供的设置属性接口完成依赖注入。
    这个bean依赖了谁，把依赖的bean也创建出阿里，给你进行一个注入，比如通过构造函数或setter方法。
    (3) 处理Aware接口
        Spring检查该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean。
        如果这个Bean实现了BeanNameAware接口，则调用它的实现setBeanName(String beanid)方法，传递就是Spring配置文件中的Bean的id值；
        如果这个Bean实现了BeanFactoryAware接口，则调用它实现的setBeanFactory()方法，传递的是Spring工厂自身；
        如果这个Bean实现了ApplicationContextAware接口，则调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；
    (4) BeanPostProcessor
        如果想在bean实例构建之后，在这个时间点对bean进行自定义处理，则可以让bean实现BeanPostProcessor接口，会调用
    postProcessBeforeInitialiazation(Object obj, String s)方法。
    (5) InitalizingBean与init-method
        如果bean在Spring配置文件中配置了init-method属性，则会自动调用其配置的初始化方法。
    (6) BeanPostProcessor
        在bean初始化完成后，如果这个bean实现了BeanPostProcessor接口，会调用postProcessAfterInitialization(Object obj, String s)方法。
    (7) DisposableBean
        当bean不再需要时，如果bean实现了DisposableBean接口，会调用其他实现的destroy()方法。
    (8) destroy-method
        如果配置了destroy-method属性，会调用配置的销毁方法。

#### 能说说Spring中都使用了哪些设计模式吗?

* 工厂模式(把一个对象的创建过程放入一个具体工厂类中,当需要使用时通过工厂把这个对象实例取出来)
    Spring ioc核心的设计模式的思想提现，他自己就是一个大的工厂，把所有的bean实例都给放在了spring容器里（大工厂），如果你要使用bean，
就找spring容器就可以了，你自己不用创建对象了。
* 单例模式
    Spring默认来说，对每个bean走的都是一个单例模式，确保说你的一个类在系统运行期间只有一个实例对象，只有一个bean，用到了一个单例模式的
思想，保证了每个bean都是单例的。
* 代理模式
    如果说你要对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先
做一些增强的代码，调用你的目标对象。

#### 能画一张图说说Spring Web MVC的核心架构吗?

[](/interview/link/SpringWebMVC的核心架构.png)
(1) Tomcat的工作线程将请求转交给spring mvc框架的DispatcherServlet
(2) DispatcherServlet查找@Controller注解的controller，我们一般会给controller加上你@RequestMapping的注解，标注说哪些controller
用来处理哪些请求，此时根据请求的uri，去定位到哪个controller来进行处理。
(3) 根据@RequestMapping去查找，使用这个controller内的哪个方法来进行请求的处理，对每个方法一般也会加@RequestMapping的注解。
(4) 会直接调用我们的controller里面的某个方法来进行请求的处理。
(5) 我们的controller的方法会有一个返回值，以前的时候，一般来说还是走jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面
模板的名字，spring mvc的框架使用模板技术，对html页面做一个渲染(现在一般返回一个json串，前后端分离，可能前端发送一个请求过来，我们只要
返回json数据。)

#### 能画一张图说说Spring Cloud的核心架构吗?

[](/interview/link/SpringCloud微服务系统图.png)
[](/interview/link/SpringCloud基本流程图.jpg)
* 基本组件
    (1) Eureka
        首先，我们需要一个注册中心 Eureka ，主要负责每个服务的注册和发现。每个微服务中都有一个Euraka client组件，专门负责将这个服务
的服务id（serviceId）、ip、端口等信息注册到Eureka server中。Euraka Server是一个注册中心，该组件内部维护了一个注册表，保存了各个服
务所在的机器ip和端口号等信息。
    (2) Feign
        其次每个服务还需要一个远程服务调用的组件 Feign ，他主要负责与其他服务建立连接，构造请求，然后发起请求来调用其他服务来获取数据。
    (3) Ribbon
        然后我们一个服务可能会部署很多台机器，那么我们使用Feign 去调用这个服务的时候，到底把请求发送到哪台机器上去呢？此时我们就需要
    一个组件来根据一定的策略来选择一台机器。不管怎么选的，总之得选一台机器给 Feign 去调用就好了。这个组件就是 Ribbon，Ribbon 主要负
    责就是负载均衡。Ribbon 会定期去从Eureka 注册中心拉取注册中心，缓存到本地，每次发起远程调用的时候，Ribbon 就会从 Eureka 注册表拉
    取下来的数据中挑选一个机器让 Feign 来发起远程调用。
    (3) Zuul
        我们这么多的微服务，如果一个服务一个IP，使用方都需要进行调用的话，是不是得知道每一个服务的IP地址才行呢？那得记住多少才行呀，
    多不好管理。如果有一个统一的地址，然后根据不同的请求路径来跟我进行转发多少是不，比如 /user/* 是转发到用户服务 ，/product/* 是转
    向到商品服务等等。我使用的时候，只需要访问同一个IP ，只是路径不一样，就行了。Spring Cloud 也给我们提供了一个组件，那就是 Zuul ，
    他是一个网关，就是负责网络的路由的。每个请求都经过这个网关，我们还可以做统一鉴权等等很多事情。
    (4) Hystrix
        还有一个东西也得说一下，就是 Hystrix，它是一个隔离、熔断以及降级的一个框架 。在微服务的相互调用过程中，可能会出现被调用服务错
    误或者超时的情况，从而导致整个系统崩溃不可用，也就是我们常说的服务雪崩问题，Hystrix 的存在就是为了解决这种问题的。
* 调用流程
    (1) 首先每个服务启动的时候都需要往注册中心进行注册。
    (2) 用户先对网关发起下单请求，网关收到请求后发现呃，是下单操作，要到订单系统，然后把请求路由到订单系统。
    (3) 订单系统啪啦啪啦一顿操作，然后通过 Feign 去调用 库存系统减库存，通知仓储服务发货，调用积分系统加积分。
    (4) 在发起调用之前，订单系统还得通过Ribbon 去注册中心去拉取各系统的注册表信息，并且挑一台机器给 Feign 来发起网络调用。

#### JVM中有哪几块内存区域?Java8之后对内存做了什么改进?

[](/interview/link/JVM内存区域.png)
* 物理内存Metaspace(除jvm占用的内存,剩余的内存空间都可以被Metaspace占用)
* 方法区(常量,即时编译后的代码)
* 年轻代(eden space, from survivor, to survivor)
* 老年代
* 程序计数器PC
* 虚拟机栈(局部变量表, 操作数栈, 方法返回地址, 动态链接, 额外附加信息)
* 本地方法栈

    Java 8以后的内存分代的改进，永久代里放了一些常量池+类信息，常量池 -> 堆里面，类信息 -> metaspace（元区域）。

#### 你知道JVM是如何运行起来的吗?我们的对象是如何分配的?

[](/interview/link/JVM运行.png)
    有一个类里面包含了一个main方法，你去执行这个main方法，此时会启动一个jvm进程，他会默认就会有一个main线程，这个main线程就负责执行
这个main方法的代码，进而创建各种对象。一般tomcat，类都会加载到jvm里去，spring容器而言都会对我们的类进行实例化成bean，有工作线程会来
执行我们的bean实例对象里的方法和代码，进而也会创建其他的各种对象，实现业务逻辑。


#### 说说JVM在哪些情况下会触发垃圾回收可以吗?

[](/interview/link/JVM在哪些情况下会触发垃圾回收.png)
(1) 对象没有引用
(2) 作用域发生未捕获异常
(3) 程序在作用域正常执行完毕
(4) 程序执行了System.exit()
(5) 程序发生意外终止(被杀进程等)
    JVM的内存其实是有限制的，不可能是无限的，昂贵的资源，2核4G的机器，堆内存也就2GB左右，4核8G的机器，堆内存可能也就4G左右，栈内存也
需要空间，metaspace区域放类信息也需要空间。在jvm里必然是有一个内存分代模型，年轻代和老年代。给年轻代一共是2GB内存，给老年代是2GB内存，
默认情况下eden和2个s的比例：8:1:1，eden是1.6GB，S是0.2GB。如果说eden区域满了，此时必然触发垃圾回收，young gc(ygc)，没有人引用的对
象就是垃圾对象。


#### 说说JVM的年轻代垃圾回收算法?对象什么时候转移到老年代?

[](/interview/link/年轻代垃圾回收.png)
    年轻代，大部分情况下，对象生存周期是很短的，可能在0.01ms之内，线程执行了3个方法，创建了几个对象，0.01ms之后就方法都执行结束了，
此时那几个对象就会在0.01ms之内变成垃圾，可以回收的100个对象，可能90个对象都是垃圾对象，10个对象是存活的对象，5个复制算法，一次young 
gc，年轻代的垃圾回收。有的对象在年轻代里熬过了很多次垃圾回收，15次垃圾回收，此时会认为这个对象是要长期存活的对象，移到老年代。


#### 说说老年代的垃圾回收算法?常用的垃圾回收器都有什么?

对老年代而言，他里面垃圾对象可能是没有那么多的。
* 标记-清理: 找出来那些垃圾对象，然后直接把垃圾对象在老年代里清理掉。
* 标记-整理: 把老年代里的存活对象标记出来，移动到一起，存活对象压缩到一片内存空间里去。剩余的空间都是垃圾对象整个给清理掉，剩余的都是
连续的可用的内存空间，解决了内存碎片的一个问题。
* parnew+cms的组合: g1直接分代回收，新版本，慢慢的就是主推g1垃圾回收器了，以后会淘汰掉parnew+cms的组合，jdk 8~jdk 9比较居多一些，
parnew+cms的组合比较多一些。
* CMS: 分成好几个阶段，刚开始用标记-清理，标记出垃圾对象，并发清理一些垃圾对象，整理，把存活的对象压缩到一起，避免内存碎片的产生。
执行一个比较慢的垃圾回收，会stop the world，需要100mb，此时会导致系统停顿100ms，不能处理任何请求，应该尽可能垃圾回收和工作线程的运行，并发执行。


#### 你们生产环境中的Tomcat是如何设置JVM参数的?如何检查JVM运行情况?

* 你们线上系统jvm参数是怎么配置的，为什么要这样配置，在这个配置参数之下，线上系统jvm运行情况如何?
    一般web系统部署到tomcat，系统仅仅在tomcat的jvm进程来执行。tomcat有一个配置脚本，catalina对应有启动的一些jvm参数设置。主要是内存
区域大小的分配，每个线程的栈大小，metaspace的大小，堆内存大小，年轻代和老年代分别大小，eden和survivor区域的大小分别是多少，如果没有设
置，会有一个默认值。垃圾回收器，年轻代，老年代分别使用哪种垃圾回收器，每种垃圾回收器是否有对应的一些特殊参数设置，这些设置都是用来干什么的。

* 为什么要这样设置?jvm表现如何?
    在一定业务背景下，进行系统运行时的对象数量的预估，对内存压力进行预估，对整个jvm运行状况进行预估，预估完毕之后，根据预估情况，可以
去设置一些jvm参数，然后进行压测，压测时候，需要观察Jvm运行情况，jstat工具去分析jvm运行情况，年轻代的eden区域的对象增长情况，ygc的频
率，每次ygc过后多少对象存活，survivor区能否放的下，老年代对象增加速率，老年代多久会触发一次fgc。可以根据压测的情况进行一定的jvm参数
的调优。压测主要两点：一个系统QPS，一个是系统的接口性能。压测到一定程度时，了解机器的cpu, 内存，io, 磁盘的负载情况，jvm的表现等，由
此需要对一些代码进行优化，比如优化性能，或减轻cpu, io磁盘负担等，如果发现jvm的gc过于频繁，内存泄漏，需要对jvm各内存区域的大小以及一
些参数进行调优。在线上生产环境时，也需要基于一些监控工具，或者jstat，观察系统的QPS和性能，接口可用性，调用成功率，机器负载，jvm表现，
gc频率，耗时，内存消耗等等。

#### 你在实际项目中是否做过JVM GC优化,怎么做的?

上一讲是如何通过预估+压测，做一份生产环境的jvm参数，去观察jvm运行情况。
如果jvm出频繁full gc，有没有尝试过生产环境的系统去进行gc优化，对于这个问题，需要结合具体业务来分析。
如何一步一步去分析系统的jvm的性能问题，如何去进行jvm gc调优?
分不同情况：
(1) 自己做过jvm gc的生产调优，恭喜你了，直接实话实说，你当时怎么调优，你们的问题如何暴露出来的，你如何一步一步定位问题的，如何进行调优，
最后的结果是什么?
(2) 你看了jvm专栏，在过程中，或者看完以后，在自己生产环境中根据专栏学习到的知识，去调优过jvm，这个时候，你可以专栏里学习到的知识，去讲。
最好对自己系统的生产环境的jvm，进行一个分析，gc频繁的问题，尽可能的去调优一下参数。
(3) 发现分析了一下生产环境的jvm的运行情况，非常好，并发量很低，几十分钟才一次young gc，存活的对象特别少，几乎都在s区域，老年代几乎没
什么对象，几天或者几周才发生一次full gc，在自己本地单机部署，测试环境里，去压测，每秒单机有500并发请求，去观察jvm的运行情况，这个时候他
会不会存在频繁gc的问题，你就去调优一下，你就可以基于这个压测的例子去讲解。


#### 你知道发生OOM之后,应该如何排查和处理线上系统的OO...

* 年老代堆空间被占满
    异常: java.lang.OutOfMemoryError：java  heap space
    说明: 这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机再也无法分配新空间
    解决: 这种方式解决起来比较简单，一般就是根据垃圾回收前后的情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。

* 持久代被占满
    异常: java.lang.OutOfMemoryError：PermGen space
    说明: Perm 空间被占满，无法为新的 class 分配存储空间而引发的异常。这个异常以前是没有的，但是在 java 大量使用反射的今天这个异常就比较常见了。
主要原因是大量动态反射生成的类不断被加载，最终导致 Perm 区被占满。更可怕的是，不同的 classLoader 即便使用相同的类，但是都会对其进行加载，相当于
同一个东西，如果有 N 个classLoader 那么它将会被加载 N 次。因此，在某些情况下，这个问题基本视为无解，当然，存在大量 classLoader 和大量反射类的情
况并不多
    解决: 增加持久代内存 ，例如：-XX：MaxPermSize=16M

    思考oom可能发生在哪几个区域。解决思路，在jvm里设置几个参数，一旦发生oom之后，就会导出一份内存快照，就会有当时线上内存里对象的一个情况，
可以用MAT（eclipse的一个插件(MAT也可以单独使用)）这样的工具进行分析。无非就是找出来当时占用内存最大的对象，找出来这些对象在代码中哪些地方
创建出来的，一般来说就是可能会对内存做一个调优。从业务背景出发，一步一步的说明，在什么样的业务背景下，为什么会产生oom的问题？当某个系统崩溃
时，找到自动导出的内存快照，分析XX 对象，直接定位代码，修改代码。你一定要把案例的业务、背景和思想给吸收了，就得融入到自己的业务里去，我负责
的业务系统，在什么样的情况下，可能说会出现一大批的对象卡在内存里，无法回收，导致我系统没法放更多的对象了。oom不是你自己的代码，可能是你依赖
的第三方的组件，结合自己的项目去一步一步的分析，oom问题的产生，和解决的过程。


#### 你能聊聊TCP/IP四种网络模型吗?OSI七层网络模型也说一下!

[](/interview/link/网络模型.png)
* 数据链路层(以太网协议)
    一堆0/1电路信号，封装成数据包，包含头(head)和数据(data)，head里包含从哪儿来到哪儿去，从一台电脑的一个网卡，发送到另外一台电脑的
一个网卡，以太网发送的数据包指定目标电脑网卡的mac地址。
* 网络层(IP协议)
    IPv4和IPv6，IPv4由32个二进制组成，一般用4个十进制数字表示，从0.0.0.0到255.255.255.255之间。IP地址前24位(前3个十进制数字)代表
网络，后8位(最后一个十进制数字)代表主机。前3个十进制数字相同表示同一个子网的。子网掩码：用于判断两个IP地址是不是同一个子网。判断方法
就是分别把两个IP地址和自己的子网掩码进行二进制与运算，比较代表网络那部分是否相同。
    (1) 路由器
        负载将多个子网进行连接，实际就是配置了多个网卡的设备，可以通过不同网卡接入不同的网络。网关，其实是路由器的一种，运作在网络层。
    可以就把路由器上的ip地址认为是网关，路由器上每个网卡都有mac地址和对应的ip地址。路由器虽然有mac地址，但是不能通过mac地址寻址的，
    必须通过ip地址寻址，所以路由器其实是工作在网络层的设备。
    (2) 网络交换机
        通过mac地址来寻址和传输数据包的；但是路由器是通过ip地址寻址和传输数据包的。网络交换机主要用在局域网的通信，一般你架设一个局域
    网，里面的电脑通信是通过数据链路层发送数据包，通过mac地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其
    他机器上去的。
    一个子网内的机器之间通信，就是在数据包里写上对方的mac地址，然后交换机广播出去ok了；但是如果是跨子网的通信，就是写上对方的ip地址，
然后先通过mac地址广播到路由器，让路由器再根据另外一个子网的ip地址转换为mac地址，通过另外一个子网的交换机广播过去。
* 传输层(TCP协议)
    端口，发送数据包到某个机器的一个网卡的某个端口上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的
数据。端口号是0~65536的范围内，0~1023被系统占用了，别的应用程序就用1024以上的端口。网络层，是基于ip协议，进行主机和主机间的寻址和通信
的，然后传输层，其实是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。这个通信，就是通过socket来实现的，通过socket就可
以基于tcp/ip协议完成刚才上面说的一系列的比如基于ip地址和mac地址转换和寻址啊，通过路由器通信啊之类的，而且会建立一个端口到另外一个端口
的连接。
* 应用层(HTTP协议)
    针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。比如最常见的，应用层的协议就是http协议，进行网络通信。电子邮件协
议，SMTP、POP3、IMAP4等。GET http://localhost:8080/   http/1.1    key:value


#### 浏览器请求www.baidu.com的全过程大概是怎样的?...

[](/interview/link/浏览器请求过程.png)
* 假设我们电脑设置了几个东西如下:
    ip地址：192.168.31.37
    子网掩码：255.255.255.0
    网关地址：192.168.31.1
    DNS地址：8.8.8.8
(1) 请求www.baidu.com地址，这个时候找DNS服务器，DNS服务器解析域名之后，返回一个ip地址，比如172.194.26.108。
(2) 判断本机和访问的IP是不是同一个子网，用子网掩码坐与运算。通常不在一个子网，就发送数据包给网关，也就是路由器。 通过浏览器访问网站，
走应用层的http协议，把浏览器发出的请求打包为数据包。把http协议请求，有请求头，空行，请求数据，就构成http请求报文，封装到一个应用
层数据包里。
(3) 接下来走到传输层，按照TCP协议，TCP协议会让你设置端口，发送方端口随机选择，接收端一般默认80端口。这时会把应用层数据包封装到TCP数
据包，再加一个TCP头，TCP头放了端口信息。
(4) 走网络层，会把TCP头和TCP数据包，放到IP数据包里，再做了一个IP头，IP头包括本机和目标机器的IP地址。通过IP 协议，判断两个IP不在一个
子网内，则将数据包通过以太网协议广播到网关，通过网关在发生出去。
(5) 最后走到数据链路层，把IP头和IP数据包封装到以太网数据包，再增加一个以太网数据包头，头里放了本机网卡MAC地址和网关MAC地址。但以太网
数据包有1500字节的限制，超过要切分为多个数据包，每个数据包包含以太网头、IP头和切割后的IP数据包。以太网数据包通过交换机发送到网关，然
后通过路由器转发到别的子网或者别的路由器，以此类推，通过N个路由器或网关转发，最终到达目标服务器，比如172.194.26.108。目标服务器接收到
以太网数据包后，从IP数据包，拿出TCP数据包，再从TCP数据包取出HTTP数据包，读取出HTTP数据包里各种协议内容，比如html页面，或者业务处理，
然后再把响应结果封装成http响应报文，封装到http数据包里，再封装TCP数据包，封装IP数据包，封装以太网数据包，再通过网关发送回去，完成整个
请求过程。


#### 画一下TCP三次握手流程图?为啥是三次而不是二次或者四次呢?

[](/interview/link/TCP三次握手流程图.png)
* 三次握手
    建立三次握手的时候，TCP报头用到了下面几个东西，ACK、SYN、FIN。第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，这就是说这是
个连接请求，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1，
SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1
* 二次握手
    假设两次握手就ok了，要是客户端第一次握手过去，结果卡在某个地方了，没到服务端；完了客户端再次重试发送了第一次握手过去，服务端收到了，
ok了，大家来回来去，三次握手建立了连接。结果，尴尬的是，后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手，
这个时候服务器开辟了资源准备客户端发送数据啥的，结果呢？客户端根本就不会理睬这个发回去的二次握手，因为之前都通信过了。但是如果是三次握手，
那个二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器撤销开辟的资源，别等着了。
* 四次挥手
    第一次挥手，客户端发送报文，FIN=1，seq=u，此时进入FIN-WAIT-1状态。第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文，
ACK=1，ack=u+1，seq=v。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。第三次挥手，服务端发送连接释放报
文，FIN=1，ack=u+1，seq=w，服务端进入LAST-ACK状态。第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，seq=u+1，进入
TIME_WAIT状态，等待一会儿客户端进入CLOSED状态，服务端收到报文之后就进入CLOSED状态。


#### 聊聊HTTP协议的工作原理!

* http的工作流程
    http请求封装到应用层数据包，封装在tcp数据包，封装在ip数据包，封装在以太网数据包，如果过大，可能会拆成几个包，走以太网协议+交换机 
-> 广播 -> 网关 -> 多个网关 -> 目标的机器 -> 一层一层拆包 -> http请求报文 -> 传递给tomcat -> spring mvc -> http响应 -> 一样的路
径会去。浏览器 -> 网站，互相之间是先要通过tcp三次握手，建立一个连接，浏览器和网站互相都给对方留出一份资源，浏览器发起http请求 -> tcp 
-> ip -> 以太网，网站上面去，网站返回一个响应，连接关闭，tcp四次挥手。释放掉浏览器和网站各自给对方保持的一份资源。

* http1.0、http1.1、http2.0具体有哪些区别?
    http 1.0要指定keep-alive来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次tcp连接，完事儿了就释放tcp连接。早期的
网页都很low，没啥东西，就一点文字，就用这个没问题。2000年之前，那个时候网页，都很low，当时你打开一个网页，就是说现场底层tcp三次握手，
跟网站建立一个tcp连接，然后通过这个tcp连接，发送一次http请求，网站返回一个http响应（网页的html，里面有一大段文字），浏览器收到html渲
染成网页，浏览器就走tcp四次挥手，跟网站断开连接了。2000之后，2010之后更不用说了，网页发展很迅猛，一个网页包含着大量的css、js、图片等
资源。比如你请求一个网页，这个网页的html先过来，过来之后，浏览器再次发起大量的请求去加载css、js、图片，打开一个网页可能浏览器要对网站
服务器发送几十次请求。再频繁建立和释放tcp连接，会很慢很慢。
    http 1.1默认支持长连接，就是说，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于
这个tcp连接来走。http 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。浏览器，第一次请求去一个网站的一个页面的时候，就会
打开一个tcp连接，接着就在一段时间内都不关闭了，然后接下来这个网页加载css、js、图片大量的请求全部走同一个tcp连接，频繁的发送请求获取响
应，最后过了一段时间，这些事儿都完了，然后才会去释放那一个tcp连接。大幅度的提升复杂网页的打开的速度，性能。
    未来http 2.0，支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。
二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐。


#### 聊聊HTTPS的工作原理?为啥用HTTPS就可以加密通信?

[](/interview/link/HTTPS的工作原理.png)
* 浏览器把自己支持的加密规则发送给网站。
* 网站从这套加密规则里选出来一套加密算法和hash算法，然后把自己的身份信息用证书的方式发回给浏览器，证书里有网站地址、加密公钥、证书颁发机构。
* 浏览器验证证书的合法性，然后浏览器地址栏上会出现一把小锁；浏览器接着生成一串随机数密码，然后用证书里的公钥进行加密，这块走的非对称加密；
用约定好的hash算法生成握手消息的hash值，然后用密码对消息进行加密，然后把所有东西都发给网站，这块走的是对称加密。
* 网站，从消息里面可以取出来公钥加密后的随机密码，用本地的私钥对消息解密取出来密码，然后用密码解密浏览器发来的握手消息，计算消息的hash值，
并验证与浏览器发送过来的hash值是否一致，最后用密码加密一段握手消息，发给浏览器。
* 浏览器解密握手消息，然后计算消息的hash值，如果跟网站发来的hash一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，然后用
对称加密来进行进行加密。(常用的非对称加密是RSA算法，对称加密是AES、RC4等，hash算法就是MD5。)


#### 聊聊http的长连接的工作原理到底是啥?

    http本身没什么所谓的长连接短连接之说，其实说白了都是http下层的tcp连接是长连接还是短连接，tcp连接保持长连接，那么多个http请求和
响应都可以通过一个链接来走。其实http 1.1之后，默认都是走长连接了，就是底层都是一个网页一个tcp连接，一个网页的所有图片、css、js的资源
加载，都走底层一个tcp连接，来多次http请求即可。http 1.0的时候，底层的tcp是短连接，一个网页发起的请求，每个请求都是先tcp三次握手，然
后发送请求，获取响应，然后tcp四次挥手断开连接；每个请求，都会先连接再断开。短连接，建立连接之后，发送个请求，直接连接就给断开了。http 1.1，
tcp长连接，tcp三次握手，建立了连接，无论有多少次请求都是走一个tcp连接的，走了n多次请求之后，然后tcp连接被释放掉了。


#### MYSQL,MyISAM和InnoDB存储引擎的区别是啥?

#### 聊聊MySQL的索引实现原理?各种索引你们平时都怎么用...

#### 你能说说事务的几个特性是啥?有哪几种隔离级别?

#### 你能说说MySQL数据库锁的实现原理吗?如果死锁了咋办?

#### MySQL的SQL调优一般都有哪些手段?你们一般怎么做?

<https://blog.csdn.net/zhangbijun1230/article/details/81608252>

#### 聊聊Socket的工作原理?Socket和TCP IP之间是啥关系?

*** socket属于传输层的一个编程规范。socket就是在传输层把tcp/ip协议给封装了，Java原生支持socket网络编程。一般都是面试socket来编程。

#### 进程之间是如何通信的?线程间又如何切换的?

#### 你能聊聊BIO,NIO,AIO分别都是啥?有什么区别?

[](/interview/link/BIO.png)
[](/interview/link/NIO.png)
* BIO: 同步阻塞式IO
    服务端创建一个ServerSocket，客户端用一个Socket去连接那个ServerSocket，然后ServerSocket接收到Socket连接请求就创建一个Socket和
一个线程去和客户端Socket通信。
    缺陷: 客户端socket发送一个请求，服务端socket进行处理后返回响应，响应必须是等处理完成之后才能返回，这期间不能做其他事，只能等待(卡
住)...而且每一个客户端接入，服务端就需要创建一个线程来服务，会导致客户端大量增加时，服务端线程会负责过高(可能几千几万个线程。。)，最
后服务端崩溃。
    优化: 可以用线程池，固定线程来处理客户端请求，但是高并发时，会导致大量排队和延时。
* NIO: 同步非阻塞IO,基于Reactor模型
    (1) Channel
        表示为一个已经建立好的支持I/O操作的实体（如文件和网络）的连接，在此连接上进行数据的读写操作，使用的是缓冲区来实现读写。
    (2) Buffer
        在内存中预留指定大小的存储空间用来对输入/输出(I/O)的数据作临时存储。
        好处:  减少实际的物理读写次数缓冲区在创建时就被分配内存，这块内存区域一直被重用，可以减少动态分配和回收内存的次数好比从A工地搬
        1w块砖到B工地，路途远(IO性能消耗大)，没有工具时(缓冲区)，一次搬1块，要搬1w次(IO读写1w次)。用卡车(缓冲区)，一次运送5K块，2次
        就运完了，性能大大提高了。
    (3) Selector(多路复用器)
        selector会不断轮询注册的channel，如果某个channel上发生了读写事件，selector就会将这些channel获取出来，我们通过SelectionKey
        获取有读写事件的channel，就可以进行IO操作。一个Selector就通过一个线程，就可以轮询成千上万的channel，这就意味着你的服务端可以
        接入成千上万的客户端。
    核心就是非阻塞，selector一个线程可以不停轮询channel，所有客户端都不会阻塞，最多排队。只有某个客户端发送了一个请求，才会启动一个线
程来处理。客户端接入不会耗费一个线程，只会创建一个channel连接，然后注册到selector上，一个selector线程不断轮询所有的socket连接(channel)，
发现有事件就通知，启动工作线程处理一个请求。工作线程，从channel-buffer读数据，如果数据没有读完卡住，等待，然后处理后往buffer-channel里
写数据，也是自己做，写数据时数据没有写完，也卡住等待，是同步的。
* AIO(基于Proactor模型的,就是异步非阻塞模型)
    每个请求会绑定一个buffer，通知操作系统去异步完成读写，此时工作线程可以做别的事情（异步），等操作系统完成之后，回调接口，把操作系统
完成的数据给工作线程。


#### 线上服务CPU100%了!该怎么排查,定位和解决?

<https://blog.csdn.net/weixin_38827340/article/details/85311247>

#### 线上机器的一个进程用kill命令杀不死该怎么办?磁盘空间快...

#### 关于后续深入硬件级讲解volatile,synchronized,CAS底...

#### 再谈原子性: Java规范规定所有变量写操作都是原子的

#### 32位Java虚拟机中的long和double变量写操作为何不是原子...

#### volatile原来还可以保证long和double变量写操作的原子性

#### 到底有哪些操作在Java规范中是不保证原子性的呢?

#### 可见性涉及的底层硬件概念: 寄存器,高速缓存,写缓存...

#### 深入探秘有序性: Java程序运行过程中发生指令重排的几个...

#### JIT编译器对创建对象的指令重排以及double check单例实践

#### 现代处理器为了提升性能的指令乱序和猜测执行的机制!

#### 高速缓存和写缓存器的内存重排造成的视觉假象

#### synchronized锁同时对原子性,可见性，以及有序性的保证

#### 深入分析synchronized是如何通过加锁保证原子性的?

#### synchronized是如何使用内存屏障保证可见性和有序性的?

#### 再看volatile关键字对原子性,可见性以及有序性的保证

#### 高速缓存的数据结构: 拉链散列表,缓存条目以及地址解码...

#### 结合硬件级别的缓存数据结构深入分析缓存一致性协议...

#### 采用写缓冲器和无效队列优化MESI协议的实现性能

#### 硬件层面的MESI协议会如何引发有序性和可见性的问题?

#### 内存屏障在硬件层面的实现原理以及如何解决各种问题

#### 在复杂的硬件模型之上的Java内存模型是如何大幅简化...

#### 面试的时候是如何从内存屏障,硬件层面的原理来震慑面试...

#### Java虚拟机对锁的优化: 锁消除,锁粗化,偏向锁,自旋锁...

#### 再来看看CAS是如何基于MESI协议在底层硬件层面实现...

#### 能不能说说一般黑客常用的XSS网络攻击的原理是什么?

#### 能不能说说我们经常听到的SQL注入攻击背后的原理是什...

#### 听说过CSRF攻击吗?你知道他背后的原理是什么吗?

#### 如果你们的系统允许用户上传文件,可能会遭到什么样的黑...

#### 让所有工程师闻风色变的DDoS攻击到底是什么东西?

*** DDoS(英文Distributed Denial of Service，即分布式拒绝服务)，这是一种网络攻击方式，主要目的是以分布式攻击来让指定目标无法提供正
常服务，甚至从互联网上消失。说白了就是一定时间内增大访问量，使其无法正常提供服务。看过最形象也最好笑的比喻是，春运抢火车票导致12306网
站瘫痪，就是DDOS攻击。DDOS只不过是一个概称，其下有各种攻击方式，比如“CC攻击、SYN攻击、NTP攻击、TCP攻击、DNS攻击等等”
    攻击者利用大量“肉鸡”对攻击目标发动大量的正常或非正常请求、耗尽目标主机资源或网络资源，从而使被攻击的主机不能为合法用户提供服务。大
家应该还听过DoS攻击。DoS（拒绝服务，Denial of Service）就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。
这是早期非常基本的网络攻击方式。


#### 基于SYN Flood模式的DDoS攻击,背后的原理是什么呢?

#### 再来看看基于DNS Query Flood和HTTP Flood的DDoS攻击

#### 在分布式架构中, Zuul网关是如何防止网络攻击的?

#### 一个对技术有追求的面试官,是怎么深挖网络与IO的面试...

#### Netty的架构原理图能画一下吗,他是如何体现Reactor架...

#### 能说说你对堆外内存的理解吗?堆外内存的优势在哪里?

#### JDK是如何对堆外内存进行分配和回收的?会发生堆外内存...

#### 如何不使用零拷贝技术,普通的IO操作在OS层面是如何执...

#### 听说过mmap吗?内存映射技术为什么可以提升IO性能?

#### 零拷贝技术到底是什么,他是如何提升IO性能的?

#### 你们的分布式系统是如何进行链路监控的?都监控什么?

#### 对分布式系统进行核心链路追踪的时候,链路id是怎么管理...

* 背景
    通过增加应用层的标记对服务化中的请求和响应建立联系，例如通过HTTP协议头携带标记信息，标记信息包括标示调用链的唯一ID，这里叫作TraceID，
以及标示调用层次和顺序的SpanID和ParentSpanID。
* 调用信息
    调用端或者被调用端的ID、系统ID；本次请求的TraceID、SpanID和ParentSpanID；时间戳、调用的方法名称及远程调用信息的类型，等等。
* 过程
    前端接收用户请求后会为用户分配一个TraceID，在内部服务调用时，会通过应用层的协议将TraceID传递到下层服务，直到整个调用链的每个节点
都拥有TraceID，这样在系统出现问题时，可以使用这个唯一TraceID迅速问题发生的节点。
    TraceID解决了系统串联的问题，但是我们无法标识和恢复这些请求和响应调用时的顺序和层级关系。因此我们需要附加的信息在系统之间的请求和
响应消息中传递，它就是SpanID，这里SpanID包含SpanID和ParentSpanIDSpanID和ParentSpanID组合在一起就可以表示一个树形的调用关系，SpanID
表示当前为一个调用节点，ParentSpanID表示这个调用节点的父节点。
* 当系统出现故障时
    (1) 通过TraceID把一整条调用链的所有调用信息收集到一个集合中，包括请求和响应
    (2) 通过SpanID和ParentSpanID恢复树形的调用树，ParentSpanID为-1的节点为根节点
    (3) 识别调用链中出错或超时的节点，做出标记
    (4) 把恢复的调用树和出错的节点信息通过某种图形显示到UI界面上。
* 如何产生SpanID
    (1) 使用随机数产生SpanID，理论上有可能重复，但是由于64位长整型，重复的可能性微乎其微，并且本地生成随机数的效率高于其他方法。
    (2) 使用分布式的全局唯一的流水号生成方式，可参考互联网发好器Vesta。
    (3) 每个SpanID包含所有父亲及前辈节点的SpanID，使用圆点符号作为分隔符，不再需要ParentSpanID字段，如下图，这种方案实现起来简单，
    但是如果调用链有太多的节点和层次时，SpanID会携带太多的冗余信息，导致服务间调用的性能下降。


#### 聊过两阶段提交了,那么分布式事务三阶段提交的思想能说...

#### 唯一id生成机制中的snowflake算法的时钟回拨问题...

* 定义
    SnowFlake算法生成id的结果是一个64bit大小的整数, 其中的41位时间戳部分依赖服务器的时间, 当服务器发生时钟回拨时, 在开源的实现中不
可避免的会出现报错. 关于解决时钟回拨的问题, 网上已有各种方案, 比如适当等待直到时间被追回, 在内存中保存一段时间内使用过的最大序列号
* 方案
    首先, SnowFlake的末尾12位是序列号, 用来记录同一毫秒内产生的不同id, 同一毫秒总共可以产生4096个id, 每一毫秒的序列号都是从0这个基
础序列号开始递增假设我们的业务系统在单机上的QPS为3w/s, 那么其实平均每毫秒只需要产生30个id即可, 远没有达到设计的4096, 也就是说通常情况
下序列号的使用都是处在一个低水位, 当发生时钟回拨的时候, 这些尚未被使用的序号就可以派上用场了.因此, 可以对给定的基础序列号稍加修改, 后
面每发生一次时钟回拨就将基础序列号加上指定的步长, 例如开始时是从0递增, 发生一次时钟回拨后从1024开始递增, 再发生一次时钟回拨则从2048递
增, 这样还能够满足3次的时钟回拨到同一时间点(发生这种操作就有点扯了)。


#### 实现灰度发布的时候,网关是可以灰度了,可是Dubbo服务...

*** Dubbo提供的Router，在进行负载均衡前，根据路由规则对服务提供者列表进行筛选。
* 定义
    灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，
一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，
在初始灰度的时候就可以发现、调整问题，以保证其影响度。


#### 除了常见服务注册中心之外,你觉得Redis能作为服务注...

*** redis 作为dubbo的注册中心，实现的功能跟 zk相同，但是内部的实现机制大相径庭，因为zk 有临时节点，服务端在zk 中创建临时节点会一直
保持连接，如果服务器出现崩溃，自动断连，而redis 则要靠主服务器进行定时轮询


#### 我们一般到底用Zookeeper来干什么事儿?

* 数据发布与订阅
    (1) 典型场景描述
        发布与订阅即所谓的配置管理，顾名思义就是将数据发布到zk节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如
    全局的配置信息，地址列表等就非常适合使用。
    (2) 应用中的具体使用
        (a) 索引信息和集群中机器节点状态存放在zk的一些指定节点，供各个客户端订阅使用。
        (b) 系统日志（经过处理后的）存储，这些日志通常2-3天后被清除。
        (c) 应用中用到的一些配置信息集中管理，在应用启动的时候主动来获取一次，并且在节点上注册一个Watcher，以后每次配置有更新，实时
        通知到应用，获取最新配置信息。
        (d) 业务逻辑中需要用到的一些全局变量，比如一些消息中间件的消息队列通常有个offset，这个offset存放在zk上，这样集群中每个发送
        者都能知道当前的发送进度。
        (e) 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息。以前通常是暴露出接口，例如JMX接口，有了zk后，只要将这些
        信息存放到zk节点上即可。
* Name Service(命名服务)
    (1) 典型场景描述
        这个主要是作为分布式命名服务，通过调用zk的create node api，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。
* 分布通知/协调
    (1) 典型场景描述
        ZooKeeper 中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使
    用方法通常是不同系统都对 ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那
    么另一个系统能 够收到通知，并作出相应处理。
    (2) 应用中的具体使用
        (a) 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。
        (b) 另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作
        的一些操作，实际上是修改 了ZK上某些节点的状态，而zk就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。
        (c) 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写
        回这个临时节点），这样任务管理者就能够实时知道任务进度。总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合。
* 分布式锁
    (1) 典型场景描述
        分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk集群中任意节点（一个zk server）
    上的相同znode的数据是一定是相同的。锁服务可以分为两类，一个是保持独占，另一个是控制时序。所谓保持独占，就是所有试图来获取这个锁的客户
    端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 
    /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，
    只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属
    性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指 定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也
    形成了每个客户端的全局时序。
* 分布式队列
    (1) 典型场景描述
        队列方面，我目前感觉有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第二种先进先出队列，和分
    布式锁服务中的控制时序场景基本原理一致，这里不再赘述。第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预
    先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，
    决定是否可以开始执行 了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个
    时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 
    发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。
* 集群管理
    (1) 典型场景描述
        (a) 集群机器监控：这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，
        往往有一个监控系统，实时检测集群 机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机
        器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：1. 集群中机器有变动的时候，牵连修改的东西比较
        多。2. 有一定的延时。利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：a. 客户端在节点 x 上注册一个Watcher，
        那么如果 x 的子节点变化了，会通知该客户端。b. 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。
        例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类
        型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。
        (b) Master选举(zookeeper中最为经典的使用场景)
        在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某
        一台机器进行执行， 其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要
        问题。利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 
        节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。另外，这种场景演化一下，
        就是动态Master选举。这就要用到 EPHEMERAL_SEQUENTIAL类型节点的特性了。上文中提到，所有客户端创建请求，最终只有一个能够创建成功。
        在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终 在ZK上创建结果的一种可能情况是这样： 
        /currentMaster/{sessionId}-1 , /currentMaster/{sessionId}-2 , /currentMaster/{sessionId}-3 ….. 每次选取序列号最小的
        那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。
    (2) 应用中的具体使用
        (a) 在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行
        全量索引的生成， 然后同步到集群中其它机器。
        (b) 另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向
        一个地方获取master。


#### 有哪些开源的分布式系统中使用了Zookeeper?

*** Hadoop、HBase、Kafka

#### 为什么我们在分布式系统架构中需要使用Zookeeper集群?

* 单点问题
    单点问题是分布式环境中最常见也是最经典的问题之一，在很多分布式系统中都会存在这样的单点问题。具体地说，单点问题是指在一个分布式系统
中，如果某一个组件出现故障就会引起整个系统的可用性大大下降甚至是处于瘫痪状态，那么我们就认为该组件存在单点问题。ZooKeeper 确实已经很好
地解决了单点问题。我们已经了解到，基于“过半”设计原则，ZooKeeper 在运行期间，集群中至少有过半的机器保存了最新的数据。因此，只要集群中超
过半数的机器还能够正常工作，整个集群就能够对外提供服务。
* 容灾
    在进行 ZooKeeper 的容灾方案设计过程中，我们要充分考虑到“过半原则”。也就是说，无论发生什么情况，我们必须保证 ZooKeeper 集群中有超
过半数的机器能够正常工作。


#### Zookeeper为了满足分布式系统的需求要有哪些特点?

* 构造高可用集群
    zookeeper的选举模式保证了集群的相对稳定性，从而使得集群是高可用的。

* 集群全局配置文件管理
    即统一资源配置，在一个偌大的集群环境中，假设你需要对该集群的配置文件作修改，假设集群很庞大，手动去修改是一件不太现实的事，不但费
时费力，还极有可能造成差错，zookeeper可以自动帮我们完成配置文件的分发，既高效又准确。

* 发布与订阅
     支持服务发布与状态监听。

* 分布式锁
    在集群环境下，同样会存在对资源的竞争，zookeeper提供了分布式锁实现了同步。

* 保证数据强一致性
    在集群环境下，对集群中某个节点的数据的改变，会被zookeeper同步到其他机器上。

* 额外补充
    cversion: 子节点版本号 
    ephemeralOwner: 用于判断节点是持久的还是临时的


#### 为了满足分布式系统的需求,Zookeeper的架构设计有哪...

#### Zookeeper集群的三种角色: Leader,Follower,Observer

* Zookeeper服务器的三种节点类型
    群首(leader)，追随者(follower)，观察者(observer)
* Leader
     Leader作为整个ZooKeeper集群的主节点，负责响应所有对ZooKeeper状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个
集群内部消息处理的FIFO。
* Follower
      Follower的逻辑就比较简单了。除了响应本服务器上的读请求外，follower还要处理leader的提议，并在leader提交该提议时在本地也进行提交。
* Observer
    如果ZooKeeper集群的读取负载很高，或者客户端多到跨机房，可以设置一些observer服务器，以提高读取的吞吐量。Observer和Follower比较相
似，只有一些小区别：首先observer不属于法定人数，即不参加选举也不响应提议；其次是observer不需要将事务持久化到磁盘，一旦observer被重启，
需要从leader重新同步整个名字空间。


#### 客户端与Zookeeper之间的长连接和会话是什么?

* 会话概述
    在ZooKeeper中，客户端和服务端建立连接后，会话随之建立，生成一个全局唯一的会话ID(Session ID)。服务器和客户端之间维持的是一个长连接，
在SESSION_TIMEOUT时间内，服务器会确定客户端是否正常连接(客户端会定时向服务器发送heart_beat，服务器重置下次SESSION_TIMEOUT时间)。因此，
在正常情况下，Session一直有效，并且ZK集群所有机器上都保存这个Session信息。在出现网络或其它问题情况下（例如客户端所连接的那台ZK机器挂了，
或是其它原因的网络闪断），客户端与当前连接的那台服务器之间连接断了，这个时候客户端会主动在地址列表（实例化ZK对象的时候传入构造方法的那个
参数connectString）中选择新的地址进行连接。



